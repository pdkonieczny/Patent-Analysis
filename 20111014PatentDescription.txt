PatentNumber=5802043,FIELD OF INVENTION



This invention relates generally to efficient transfer of digital information among nodes. In particular, it is directed to a novel digital transport architecture in which digital information is exchanged among nodes in a network in multiplex frames which carry one or more containers.



BACKGROUND OF INVENTION



Communication networks have been primarily used for voice communications but support limited data and computer communications. In recognition of the predominance of voice traffic, a circuit switched, channelized architecture emerged and was optimized for telephony. Data and computer communications access and transport have been provided as an overlay on this channelized infrastructure.



Although many data technologies have been developed over the past twenty years, the advent and subsequent popularity of the Internet, coupled with its ability to support multimedia services, including telephony (voice), has changed the way people communicate and do business. Bandwidth required for many services, including voice, is shrinking as a result of great improvements in compression technologies and platforms. Consequently today, telecommunications networks are shifting from specialized networks toward multipurpose, multi-functional networks. The requirement for 64 Kb/s for voice is no longer state of the art, hence networks based on this channelized technology will have limited application and no advantage in the future. Supporting infrastructure for this channelized architecture, including signalling and control, network design and management, access, transport, switching, and service vehicles, will all be replaced by simpler, more robust, and open alternatives.



For connecting many end users, a typical network is created by interconnecting them to a networking device which can provide interconnections between the users. In an IP data network this would be a router; in a voice telephony network this would be a voice switch; in an ATM data network this would be an ATM switch. In order for users attached to one networking device to exchange information with users attached to another remote networking device, the networking devices must be interconnected to each other via a transport system. Assuming that every user in the world wants to be able to exchange information with every other user in the world, it must be possible to interconnect every networking device with every other networking device. The simplest approach is for every networking device to have a physical connection to every other networking device, however, as the network size grows, this approach rapidly becomes impractical. A large number of physical connections would be required (n(n-1)/2 where n is the number of networking devices) and each networking device would have a large number of relatively low capacity interfaces, inefficiently utilizing the port capacity of the device. Thus it is common for the interconnection between two remote networking devices to tandem through one or more other networking devices. Often, a special tandem networking device is dedicated to this function, such that a number of networking devices have one connection to the tandem networking device resulting in a star topology. This allows efficient utilization of the network device interfaces, at the cost of the tandem networking device. In addition to cost, the tandem device can cause service degradation such as additional delay, delay variation, and traffic loss due to congestion.



Traditional transport systems can provide an alternative solution by providing logical layer virtual mesh interconnections between the networking devices. However, these connections are based on time division multiplexing (channelization), meaning that the bandwidth allocated to a connection is fixed and dedicated to that connection. Although the connection between two devices may be inactive for some period of time, the transport bandwidth is still reserved so that it cannot be utilized by other active connections. Thus the networking device interfaces may not be as efficiently utilized as in the tandem approach which allows interconnections from many networking devices to share the interface to a given device. Although the cost of tandeming is avoided, there is cost associated with this inefficiency.



U.S. Pat. No. 5,293,376, issued Mar. 8, 1994 (White), describes an upgradable telecommunication network which comprises a plurality of interconnected nodes or central offices, such as a SONET ring network. In its network, a unique controller enables a subscriber to change the central office or node in the network to which it is connected without changing the telephone number of the subscriber location.



U.S. Pat. No. 5,247,518, issued Sep. 21, 1993 (Takiyasu et al), teaches a high speed ring LAN system in which SONET subframes flow in a time-divisional n-multiplexed format. The respective node devices inserted in the transmission path have one or more ports to accommodate sub-LANs or public networks. Information is exchanged in units of a fixed-length packet between a received SONET subframe and an asynchronous port, whereas information is exchanged in units of a byte between the SONET subframe and a synchronous port.



The invention described in this patent application allows many networking devices to be interconnected with efficiently utilized interfaces, without incurring the cost and service degradation of a tandem device. A domain is defined where every networking device within the domain is connected to every other networking device within the domain with fixed or variable capacity. All the connections within the domain share a common pool of capacity, maximizing the utilization of the device interfaces. Since this new function is integrated into the transport network, the cost and service degradation associated with tandem networking devices is avoided. Various networking devices which use different protocols, such as ATM or IP, are accomodated by defining a container structure which carries digital information in its native form between them. The containers are carried on a digital facility with a defined bit rate that circulates on a ring or virtual ring past every networking device in the domain.



OBJECTS OF INVENTION



It is therefore an object of the invention to provide a new network architecture in which digital information is exchanged in a multiplex frame format.



It is yet another object of the invention to provide a new network architecture in which full mesh connectivity is achieved among nodes in a domain.



It is a further object of the invention to provide a new network architecture in which containers in a multiplex frame carry digital information in its native form or forms.



SUMMARY OF INVENTION



Briefly stated, the invention resides in a communications network including a domain containing a plurality of nodes connected in a ring or in a virtual ring. According to one aspect, the invention is directed to a method of providing a virtual mesh connectivity of digital information between source nodes and destination nodes among the nodes. The method comprises a step of transmitting into the domain a multiplex frame of digital information from a domain controller node. The multiplex frame consists of containers which are respectively allocated to the destination nodes, each container having partitions which are respectively allocated to source nodes. The method further comprises steps of loading the digital information at a source node into the respective partition of the container which is allocated to a destination node, and unloading the digital information at the destination node from the container.



According to another aspect, the invention is directed to a communications network for providing virtual mesh connectivity of digital information between source nodes and destination nodes. The network comprises the nodes being connected in a ring or in a virtual ring, one node being a domain controller node and the domain controller node including a transmitter for transmitting a multiplex frame of digital information into the ring. The multiplex frame consists of containers which are respectively allocated to the destination nodes, each container having partitions which are respectively allocated to the source nodes. Each source node has a container packer for loading the digital information into the partition allocated to it, of the container allocated to the destination node to which the digital information is destined, and each destination node has a container unpacker for unloading the digital information from the container allocated to it.



BRIEF DESCRIPTION OF THE DRAWINGS



FIG. 1 shows a domain encompassing two rings forming a network;



FIG. 2 shows the structure of a multiplex frame including containers and variable partitions according to one embodiment;



FIG. 3 depicts domain node functionality according to one embodiment;



FIG. 4 illustrates a container packer/unpacker serving multiple networking units;



FIG. 5 shows inter-domain networking;



FIG. 6 illustrates the master-slave relationship of container packers/unpackers;



FIG. 7 shows a single domain in a network including modified nodes and stevedores;



FIG. 8 shows the structure of a container, multiplex frame and partitions;



FIG. 9 illustrates a hierarchical addressing/routing arrangement; and



FIG. 10 shows the structure of a container according to a further embodiment of the invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS OF THE INVENTION



Referring to FIG. 1, according to the invention, information is exchanged among nodes in fully meshed connectivity. In this description, as mentioned earlier, the domain is a digital facility with a defined bit rate consisting of a continuous series of fixed size frames. Thus, in the figure, there are two domains: domain 1 and domain 2, which are formed by domain nodes in a ring or in a virtual ring. Node C participates in the both domains.



According to one embodiment, the continuous series of the fixed sized frames are organized into multiplex frames where each frame within the multiplex frame is a container that is destined to one of the domain nodes. Thus the domain carries a continuous train of containers that pass by each domain node. As a given container travels around the domain, all domain nodes can load information into partitions that have been allocated to them within the container. When the container reaches the destination node, the node unloads the payloads loaded into it by the other nodes. FIG. 2 illustrates this frame structure in which a series of containers is shown travelling in one direction. Each container is set aside for a particular node, e.g. containers for nodes A, B, C, etc. A certain number of containers (in this example, five containers) are organized into a multiplex frame which is identified as such by a multiplex frame identifier which also shows which container is set aside for which node. The figure further shows partitions within a container. Thus the container for node A has partitions for nodes B, C, D and E, whose sizes are relatively shown in the figure. The partition for node B within the container for node A is the bandwidth exclusively set aside for use by the traffic from node B to node A.



One of the domain nodes within the domain generates the multiplex frame and indicates the length and alignment of the multiplex frame by generating a multiplex frame identifier. This node is referred to as the domain controller. Other domain nodes can assume this responsibility in the event of failure of the original domain controller.



There are several parameters that impact the amount of bandwidth available between two domain nodes: the bandwidth of the domain, the length of the multiplex frame, the number of containers per multiplex frame allocated to the destination node, and the size of the partition within the container into which the source node is allowed to load its payload destined to the destination node. The allocated bandwidth of the domain determines the total capacity to be shared across the domain. The length of the multiplex frame and the number of containers per multiplex frame allocated to a domain node determines the throughput to that node. For example, the minimum bandwidth that can be allocated to a destination node is one container per multiplex frame. If the domain bandwidth is 50 Mb/s, and the multiplex frame is 10 frames long, then this bandwidth is 5 Mb/s. This bandwidth can be increased to 15 Mb/s either by increasing the domain bandwidth to 150 Mb/s or by allocating 3 containers per multiplex frame to that particular domain node. Finally, the partition of a container allocated to a given source node determines how much bandwidth the source node can send to that destination node.



These parameters can be fixed at provisioning time, or they can be adjusted dynamically to respond to changing traffic demands. For example, if the bandwidth of the domain with 5 nodes is fixed at 50 Mb/s, and a 10 frame multiplex frame is allocated with two containers per domain node, then each destination node can receive a maximum of 10 Mb/s. If each of the other nodes were only allowed to fill one quarter of each container, then the bandwidth between any two nodes is 2.5 Mb/s. An access protocol operating between all the nodes would allow partitions within a container to be adjusted dynamically. For example, one node could be given 5 Mb/s if two other nodes only require 1.25 Mb/s. Similarly, if a destination node requires more than 10 Mb/s, it could be allocated 3 containers per multiplex frame (15 Mb/s) if another destination node only requires one container (5 Mb/s). The granularity of this adjustment (5 Mb/s in this example) can be changed by going to a longer multiplex frame. This adjustment can also be made dynamically. Finally, all of the numbers in this example could be tripled by going to a 150 Mb/s domain. A cost/performance trade-off determines which parameters should be adjusted dynamically and how fast this adjustment needs to be.



The domain nodes receive incoming data streams in any format. The information is encapsulated into frames. A routing function determines the domain node to which the frame is forwarded. The frames are buffered until a container with the appropriate destination node comes by and are then inserted into the appropriate container partition.



FIG. 3 illustrates schematically functions of the domain node 10. In the figure, three major functional boxes are shown: the adaptation unit 12, networking unit 14, and container packing/unpacking unit 16. Adaptation unit 12 takes in, from peripherals, whatever information is to be transported across the network and puts it into a form appropriate for insertion into a container. Networking unit 14 looks at the destination of the information, either by looking at addressing within the service information itself, or via provisioning, and decides which domain node to forward the information to, and therefore, in which container to put the information. The network unit has a set of container buffers 18, each of which is assigned to each possible destination domain node. Once the networking unit 14 has determined the next domain node to forward the information to, it stores it in the buffer associated with the container allocated to the destination node.



Networking unit 14 is responsible for sending the buffer contents to the container packing/unpacking unit 16 (or container packer for short). The container packer will indicate what buffers contents it wants, when and how much, via a control interface 20. This minimizes buffering in the container packer and allows the networking unit to be located remotely from the container packing function. It allows the container packer to service multiple adaptation/networking units simultaneously, as shown in FIG. 4, and it also allows given networking units to interface with other container packers operating in other domains, as shown in FIG. 5. More importantly, traffic which is of no interest to the local node passes directly through the container packer, minimizing the traffic that transits the networking unit. The networking unit will indicate to the container packer the state of its buffers so that the container packer can adjust the partitions allocated within outgoing containers.



The container packer receives the incoming containers. The containers that are destined for the domain node that contains the container packer are unloaded and sent to the networking unit. As containers destined for other domain nodes arrive, the container packer will request the appropriate buffer contents, via the control interface 20, from the networking unit and load it into the container partition allocated to this source node. With this information also comes an indication of buffer status that the container packer can use to request more or less space in subsequent outbound containers.



Referring to FIG. 6, container packers operate in a master/slave mode, with every packer being the master for the containers destined to the local domain node, and slave for each of the other containers. The master sources a container with partitions allocated to each of the other packers to fill in. The master can dynamically adjust the partitions in subsequent containers based on traffic demands. In the figure, therefore, the master packer (node A) sends out containers with the partitions defined for the slaves (nodes B, C and D) to fill in their information. In a further embodiment, rather than sending out empty containers, which would be wasteful of capacity, this bandwidth is utilized for additional capacity from the master to each of the slaves.



Referring to FIG. 7, an example of the invention is illustrated. This example uses an STS-1 or STS-Nc path within a SONET/SDH transport to provide the domain 40. The SONET/SDH network itself may consist of linear, hubbed and ring structures at the line (physical) layer. In the Figure, the network is made up of a few individual SONET/SDH rings 42. Some or all of the domain node functions may be integrated into a SONET/SDH node which is modified to perform the above described functions of the invention. In this embodiment, however, the container packer function is integrated into this modified SONET/SDH node 44 and the adaptation and networking functions are combined into a device referred to as a stevedore 46. One SONET/SDH node-stevedore pair 48 is assigned as the domain controller node.



The stevedore therefore performs following functions:



a) interfaces to a variety of services;



b) adapts the incoming information by encapsulating into a data frame addressing and frame length information; performs corresponding de-encapsulating function in the opposite direction;



c) reads addresses of incoming frames from the adaptation function and determines from a routing table (established in shared memory) the next network hop and thus the appropriate container;



d) routes each packet to a stack in the appropriate buffer in shared memory for an outbound container; the stack may be FIFO or alternatively may use a service-based priority queuing algorithm;



e) transfers each cell to its associated container packer;



f) dialogs with other networking functions to establish optimum routes based on distance, congestion, failures, etc.



e) indicates buffer status to container packer or, alternatively, requests increases or decreases in outgoing capacity; and



f) reads all packet addresses arriving on inbound cells within the container for its node and either terminates on local service interfaces or forwards to another networking function via an outgoing container.



The modified SONET/SDH node performs the following functions:



a) receives payloads for outgoing containers from one or more networking functions;



b) packs payloads into appropriate outbound containers;



c) unloads containers allocated to the local stevedore;



d) controls the partitioning of the containers allocated to the local stevedore, responds to requests (implicit or explicit) for more or less capacity; and



e) container packer in the domain controller node sources the multiplex frame; other container packers may request more or fewer containers per multiplex frame.



It should be noted, of course, that all of these functions can be integrated into one unit.



The frames of the STS-1/Nc path forming the domain are organized into multiplex frames where each STS-1/Nc frame within the multiplex frame is a container. FIG. 8 shows the structure of multiplex frames. The alignment of the multiplex frame is indicated using the multiframe indicator (H4) byte in the SONET path overhead. This byte contains a continuous binary modulo n count where n is the number of frames in the multiplex frame. The path layer ring can be assigned to operate bidirectionally, thus providing two physically diverse paths between any two stevedores.



In many applications, it is not necessary for all the networking functions in a domain to be fully mesh interconnected. Often, it is desirable to have all the nodes but one connected to the one remaining node, creating a logical star topology. In this case, the domain node associated with the hub of the star would be allocated all of the containers. Traffic flowing from the hub to all of the other nodes would be carried in the partitions that the master container packer generates on the ring. Each slave would empty the partition allocated to it and then refill the partition with traffic flowing to the hub. Thus the master resizes each partition based on the capacity requirements of the traffic flowing from the hub to the node associated with that partition as well as on the needs of the traffic flowing back to the hub. This means that the same capacity is allocated in both directions.



It is also possible that the stevedores can be organized hierarchically, either to limit routing table size in lower layer stevedores, or to take advantage of hierarchical addressing, as seen in FIG. 9. The stevedores on a single path ring can be part of a single addressing domain. A set of path rings, and consequently all the stevedores attached to them, can have a peer relationship. A higher level path backbone ring can be used to interconnect the path rings at the lower level. If the addressing used by the networking functions is hierarchical, then the networking functions on the backbone ring only need look at the portion of the address identifying the lower layer domain to get across the backbone path ring. Similarly, networking functions on the lower layer rings simply forward traffic to the networking function on the backbone ring if they do not recognize the portion of the address that specifies the lower layer domain. Otherwise, they use the portion of the address that specifies the individual networking function to get across the lower layer ring.



In this embodiment, as each slave packer fills in the current container, it requests an increment, a decrement, or an absolute size for subsequent partitions. This request would be based on the status of container buffers indicated by the networking unit in the slave node. The master sees the requests from all slaves and repartitions subsequent containers to try to fairly meet all their requests.



In a further embodiment, the master node decides to increment or decrement subsequent partitions based on the fill of previous incoming partitions. For example, all full partitions could be incremented at the expense of non-full partitions until all partitions were either full or reduced to near zero. Then, smaller full partitions would be incremented at the expense of bigger full partitions until all full partitions are equal in size.



If the master cannot meet the demands of the slaves, then it can request more containers per multiplex frame from the domain controller node. If this does not solve the problem, then the path loop bandwidth will have to be increased.



As seen in the above description, this embodiment provides a means for SONET-based transport networks to provide connections at virtually any bandwidth, and to allow that bandwidth to vary in real-time according to instantaneous traffic demands. It also allows many such connections to share transport capacity on a statistical basis. This increases the efficiency of bandwidth utilization on the transport network. Telecommunications transport networks based on traditional SONET only allow point-to-point path layer connections at one of three granularities, 1.7 Mb/s, 50 Mb/s, or n.times.150 Mb/s. These bandwidths are reserved across the entire network regardless of instantaneous traffic demands.



Referring to FIG. 10, another example of the container concept is illustrated. In this embodiment, the networking function uses ATM cells as the traffic element that is routed. The container structure can be as in FIG. 2, where each partition carries ATM cells. In the further embodiment of FIG. 10, however, it may be more efficient to have the containers interleaved with each other at the cell level. Thus the multiplex frame now consists of cells. The cells that make up a container are allocated based on their position within the multiplex frame. The capacity associated with a container depends on the number of cells within a frame that are allocated to that container. Within the container, cells are allocated to a partition under the control of the master container packer for that container.



While the SONET environment discussed above is the main area of application, the present invention provides, in other similar networks, a novel and efficient way of establishing mesh connectivity among nodes which may be, for example, IP Routers or ATM switches with enhanced interfaces to container packers. The nodes in such networks do not have to dedicate a separate port for each connection to another node, and thus port utilization is increased. Furthermore, since many networking nodes can be directly interconnected on a path ring and the path ring can be organized into a hierarchy, the number of networking nodes that a given traffic flow will have to tandem through is minimized. This has many beneficial effects, including lower delay, lower delay variation, and higher throughput.



This invention further provides the capability of sharing a multipurpose SONET/SDH network, where some paths of the network carry conventional traffic (circuit-based), while other paths are used in conjunction with the adaptive multiplex frame concept to provide facilities for multi-service transport in the manner described above. Thus, using this invention, both circuit switched services and packet services are carried on the same SONET/SDH physical layer facilities.

PatentNumber=5878228,RELATED APPLICATIONS



This application is related to copending U.S. patent applications (1) Ser. No. 08/749,688 entitled "STATELESS DATA TRANSFER PROTOCOL WITH CLIENT CONTROLLED TRANSFER UNIT SIZE", and (2) Ser. No. 08/749,689, entitled "STATELESS RATE-CONTROLLED DATA TRANSFER PROTOCOL", which were filed concurrently herewith and are incorporated herein by reference.



FIELD OF THE INVENTION



The present invention relates generally to data transfer protocols and, in particular, to a binary large asset stateless transfer (BLAST) protocol for transferring data files in a client-server environment.



BACKGROUND OF THE INVENTION



Referring to FIG. 1, as is well known, computer systems attached to data networks 10 are often connected in a client-server fashion, with a single server 12 servicing requests from multiple clients 14. The number of clients 14 that can be serviced by a single server 12, and thus the cost-effectiveness of the system, is dependent on how efficiently each transaction can be processed.



There are two chief costs to be considered in the design of such a system. One is the computational efficiency of the transfer protocol itself, and the other is the effective utilization of the network 10 between the client 14 and the server 12.



The computational efficiency of the protocol is a measure of the amount of work to be performed by the endpoints, namely the client 14 and server 12, in order to reliably transfer a given amount of information. The focus of attention is on the work required by the server 12, since it is processing requests from a potentially very large number of clients 14. The less work that needs to be performed by the server 12, the lower the cost to the system for providing the service.



From the point of view of the server 12, there are two components to the computational cost of a data transfer protocol. The first is the cost of actually transferring the desired data, and the second is the protocol overhead, which includes every CPU cycle executed which is not directly involved with transmitting the data. This may include connection setup, acknowledgement processing, retransmission, and connection teardown. It also includes the cost of processing (e.g., interrupts and protocol stack overhead) each unique incoming and outgoing PDU (protocol data unit) and any associated header.



While there is a minimum cost of the data transfer itself that cannot be avoided, the protocol overhead associated with the transfer can be reduced.



An independent problem from computational efficiency is network efficiency, which is a measure of how much useful data is carried through the network 10 to the destination as compared to how much was offered to it. Data loss, typically caused by network congestion, is a factor in any network 10 with shared components, where it is possible for instantaneous network load to exceed capacity. In a reasonably engineered network 10, congestion is typically bursty, corresponding to burstiness in the offered data traffic.



There are several approaches to increasing protocol efficiency, particularly be decreasing the protocol overhead. One way to decrease protocol overhead is to increase the size of outgoing PDUs. This amortizes the per-PDU cost over a larger amount of data and requires fewer PDUs to complete the transfer, reducing the total cost of the transfer. Trivial File Transfer Protocol (TFTP), which is based on the well known User Datagram Protocol over the Internet Protocol or UDP/IP, is an example of a protocol that allows an increase in its PDU size to gain efficiency.



Another way to decrease protocol overhead is to reduce the number of incoming PDUs. For example, a TFTP file transfer requires one incoming acknowledgement PDU for each outgoing data PDU. This results in a high transfer cost to the server. In contrast, the TCP-based FTP uses a windowing scheme, where multiple outgoing PDUs may be acknowledged by a single incoming PDU.



Yet another way involves selective retransmission. Windowed protocols that use a go-back-n retransmission scheme can cause successfully received data to be discarded and retransmitted. By causing only the lost data to be retransmitted, unnecessary work at the server can be avoided. Protocols such as XTP implement selective retransmission.



Some transport mechanisms, such as a connectionless transport mechanism, are inherently simpler and more efficient than others. A connectionless, non-guaranteed service like UDP/IP, (as used by TFTP) may be considerably more efficient than reliable, connection-oriented TCP or ISO TP4 for data movement. However, since UDP does not provide the same traffic integrity guarantees as TCP, the responsibility for ensuring reliable transfer lies with the file transfer mechanism itself rather than the underlying system.



All else being equal, increasing either the PDU size or the acknowledgement window increases the chance of network congestion. More data is being sent in each burst to the network. Unless there is some sort of way to limit this traffic, network congestion will increase, leading to data loss and more retransmission, leading back to more work for the server. Unfortunately, most solutions which increase network efficiency tend to increase the computational cost of moving data.



Though designed as an end-to-end mechanism to prevent message loss due to buffer depletion, modified flow control mechanisms can be used to aid network stability. TCP takes an approach that dynamically varies the acknowledgement window based on end-to-end message loss. This can detect and recover from network congestion, but at the cost of considerable overhead on the part of the sender, and at the cost of needing to induce network congestion before it can be detected.



Another solution to network congestion is explicit peer-to-peer rate/flow control, as exemplified in the ATM ABR (available bit rate) scheme. In this scheme, the instantaneously available network bandwidth is advertised to the endpoints, which are expected to limit output accordingly. Unfortunately, this capability is not widely available and is computationally expensive both for the server and the network.



SUMMARY OF THE INVENTION



It is an object of the present invention to provide a new and improved data transfer protocol and, in particular, a data transfer server implementing the protocol.



The invention, therefore, according to a first broad aspect provides a method of operating a data transfer server, comprising the steps of: defining a circular ordering of individual scheduling timeslots having zero or more download records, each of which includes information of remaining data to transfer from identified data, a transfer rate and a destination address; selecting in sequence, at a predetermined rate, the individual scheduling timeslots; and servicing, responsive to the selected timeslot having at least one download record, each record therein by: (i) sending, to the destination address, a download message which includes a block of data extracted from the identified data, based on the remaining data information; (ii) updating the remaining data information to reflect the block of data that was sent; and (iii) resheduling, based on the transfer rate and the predetermined rate, the download record into an appropriate one of the scheduling timeslots; whereby, in the servicing of each download record, successive download messages having respective blocks of data extracted from the identified data are sent at a rate less than or substantially equal to the transfer rate in that record.



In accordance with a second broad aspect of the invention, there is provided a data transfer server, comprising: means for defining a circular ordering of individual scheduling timeslots having zero or more download records, each of which includes information of remaining data to transfer from identified data, a transfer rate and a destination address; means for selecting in sequence, at a predetermined rate, the individual scheduling timeslots; and means for servicing, responsive to the selected timeslot having at least one download record, each record therein, the means for servicing including: (i) means for sending, to the destination address, a download message which includes a block of data extracted from the identified data, based on the remaining data information; (ii) means for updating the remaining data information to reflect the block of data that was sent; and (iii) means for resheduling, based on the transfer rate and the predetermined rate, the download record into an appropriate one of the scheduling timeslots; whereby, in the servicing of each download record, successive download messages having respective blocks of data extracted from the identified data are sent at a rate less than or substantially equal to the transfer rate in that record.



A binary large asset stateless transfer (BLAST) data communications protocol, embodying the present invention, provides a simple, reliable and highly scaleable data transfer facility in a digital data network, interconnecting a file server and a client. A connectionless, unacknowledged data transfer protocol minimizes resource utilization at the data server and is combined with source rate control to reduce congestion in the intervening network.



The BLAST protocol is focused on making the function of the file server as simple as possible. To that end, a system was designed with the following features.



A connectionless transport mechanism is used, to eliminate any overhead in connection establishment and maintenance.



PDU traffic to the server is reduced by using an unacknowledged transfer protocol requiring, in most cases, only a single request to initiate the transfer of all of the data. Transfer time is made largely independent of network end-to-end delay.



Network congestion is limited by regulating the data transfer based on a rate-control parameter. In order to accommodate widely varying capabilities of clients, the requesting client specifies the maximum PDU size and PDU rate in the data request. The server may further reduce these maximums according to its own requirements.



The loss of data is detected by the client and selectively re-requested by the client. The re-requests are completely unique data requests to the server, eliminating any need for client state information to be kept or correlated at the server.



The client has the responsibility to correlate re-requested segments with the original request, and verifying the data is still current.



Client heuristics may be applied to adjust PDU size and rate for requests if patterns of message loss indicate there is network congestion.



The basic rate-control scheme of BLAST is applicable to any data transfer, not just reliable file transfer. This includes the area of streaming video or voice protocols.



BLAST combines an unacknowledged, stateless protocol to increase server scalability; rate control to minimize potential of network congestion; and responsibility for reliable transfer residing in the client.



BRIEF DESCRIPTION OF THE DRAWINGS



The invention will be better understood from the following description of a binary large asset stateless transfer (BLAST) protocol, together with reference to the accompanying drawings in which:



FIG. 1 is a schematic representation of a prior art client-server environment;



FIG. 2 is a structural representation of a message header in the BLAST protocol;



FIG. 3 is a structural representation of a GetFilesize message in the BLAST protocol;



FIG. 4 is a structural representation of a FilesizeData message in the BLAST protocol;



FIG. 5 is a structural representation of a DownloadStart message in the BLAST protocol;



FIG. 6 is a structural representation of a DownloadData message in the BLAST protocol;



FIG. 7 is a timing graph illustrating protocol behaviour during successful transfer;



FIG. 8 is a timing graph illustrating protocol behaviour during errored transfer;



FIGS. 9A, 9B, 9C, 9D, and 9E, illustrate client processing of downloaded data PDUs;



FIG. 10 is a schematic representation of an implementation of the BLAST server;



FIG. 11 illustrates exemplary pseudocode whereby a Request Handler task may be implemented in the BLAST server; and



FIG. 12 illustrates exemplary pseudocode whereby a PDU Scheduler task may be implemented in the BLAST server.



DETAILED DESCRIPTION



Having regard to FIG. 1, a binary large asset stateless transfer (BLAST) protocol, in accordance with the invention, provides a mechanism for transferring data files from a server 12 to any of a plurality of clients 14 which communicate through signalling carried by a data network 10. The server 12 and clients 14 are representative of typical data processing platforms suitable for the stated purposes. The data network 10 may be any conventional data communications technology, examples for which include frame relay or asynchronous transfer mode packet switched networks, and an Ethernet local area network running over which is the Internet protocol (IP). The BLAST protocol may be stacked on the network particular protocol(s) to effect the signalling exchanges between the server 12 and each client 14.



The BLAST protocol characterizes a stateless, rate-controlled request/response file transfer protocol. A request for one or many files, in whole or in part, is sent from a particular client 14 to the server 12. The request is identified by a client-unique transaction ID.



The request specifies not only the file(s) to be downloaded, but also includes information that tells the server 12 how the file is to be delivered. This includes the maximum size of an individual data packet and the maximum rate at which the packets can be processed. This is to accommodate a wide range of client configurations. The server 12, upon receiving a request, may further reduce the size and rate of data packets that will be used for the transfer, depending on the current loads of both the server 12 and the network 10. The server 12 then schedules the request and begins transmitting sequential data packets, containing the client-unique transaction ID, at the appropriate rate.



The regular stream of data packets arrives at the client 14 and are assembled into the original file. Each packet identifies its position in the file, and so can be handled independently of any other. There are no acknowledgements of any kind. The server 12 does not know or care whether the individual packets arrive at the client 14. Since the server 12 may be responsible for servicing requests from a very large number of clients 14, the reduction in message load greatly improves the scalability of the protocol. When the data specified in the original request has been sent, the transaction is completed from the server's point of view.



Data integrity is managed by the client 14. The client 14 must examine the received data and decide how to proceed. If there are `gaps` in the received data, as will be the case where there is message loss, the client 14 must initiate a new request for the missing data. There are many possible heuristic algorithms that can be used by the client 14 to get the missing data. It may wait until the original request is completed before rerequesting the data, or it may rerequest as soon as it notices a gap in the file. It might do a request for each gap, it might group gaps together, or it might simply rerequest the whole file. If the missing data exceeds a certain threshold, then network congestion can be assumed, and the rerequests can be made with a lower rate and/or a smaller data size specified. At the server 12, each rerequest by the client 14 is seen as a completely new request. There is no relationship known at the server 12 between any two past, present, or future requests. This further reduces the complexity, and improves the scalability of the server 12.



Signalling between the server 12 and each client 14 to effect the BLAST protocol is implemented by various messages which are transmitted therebetween, via the network 10. Particular embodiments of these BLAST protocol messages are described below and illustrated in FIGS. 2 to 6. Though the messages described pertain to a specific UDP/IP-based implementation of the BLAST protocol, it should be understood that nothing restricts this from being implemented over any other protocol stack, or in other operating environments. Similarly, PDU data field sizes are shown as present in this implementation, but are not necessarily restricted to the indicated size which may be adapted to satisfy requirements of the particular application.



Referring to FIG. 2, every BLAST protocol message shares a common header, identified herein as messageHeader, to simplify message interpretation. The messageHeader defines a set of parameters at the start of each message sent between the BLAST server and client. Fields forming part of the messageHeader include:



version--Parameter identifies a protocol version number which is used to ensure compatibility of messages.



messageID--A message type identifier parameter.



messageLength--Parameter indicates the total length of the entire message in bytes, including the message header 20.



transactionID--An arbitrary client assigned parameter used to associate data blocks with their respective requests.



Referring to FIG. 3, a GetFilesize message is illustrated. This message requests that the server reply with the size of the requested file, so that the client can ensure sufficient resources are available and allocated to receive it. Fields forming part of the GetFilesize message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F5 Hex by which value the GetFilesize message is identified.



destinationAddress--Parameter identifies the IP address of the client.



destinationport--Parameter identifies the UDP port of the client.



fileDescriptorLength--Parameter indicates the length of the fileDescriptor in bytes.



fileDescriptor--Parameter identifies the requested file by providing a null-terminated full pathname of the file to be transferred.



Referring to FIG. 4, a FilesizeData message is illustrated. This message is a reply sent from the server to the client to satisfy the GetFileSize request message. Fields forming part of the FilesizeData message include:



messageHeader--Includes parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F6 Hex by which value the FilesizeData message is identified.



filesize--The size of the file, specified in the GetFilesize message, in bytes. If the file could not be found in the BLAST filesystem, the filesize will be 0 .



Referring to FIG. 5, a DownloadStart message is illustrated. This message is sent from the client to the server to initiate the data transfer for a requested file. Fields forming part of the DownloadStart message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F3 Hex by which value the DownloadStart message is identified.



blockSize--Parameter indicates a maximum PDU (i.e., data block or packet) size for the server to use.



startByte--Parameter provides an offset within the file at which byte of data transfer is to begin (i.e., the first byte to send). The beginning of the file has an offset value of 0.



numBytes--Parameter indicates the total number of bytes of the file to send. A value of 0 indicates the entire file, or remainder of the file starting from the offset byte position when the offset parameter is greater than 0.



destinationAddress--Parameter identifies the IP address of the download client.



destinationport--Parameter identifies the UDP port of the download client.



delay--Parameter indicates a minimum delay in micro-seconds between sending successive data PDUs.



fileDescriptorLength--Parameter indicates the length of the fileDescriptor in bytes.



fileDescriptor--Parameter identifies the requested file by providing a null-terminated full pathname of the file to be transferred.



Referring to FIG. 6, a DownloadData message is illustrated. This message contains the actual data for the file transfer. The blocks of data are divided into the blocksize bytes of data, as specified in the DownloadStart message, and sent in order to the client. Fields forming part of the DownloadData message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F4 Hex by which value the DownloadData message is identified.



firstByte--Parameter provides an offset into the file for the first byte of this data block. An offset value of 0 corresponds to the first byte in the file.



numBytes--Parameter indicates the number of data bytes in this block.



edition--Parameter identifies a version number of the file being downloaded. This allows the client to ensure that rerequests are being made from the same file as an initial request.



data--This parameter is the block of data payload being carried by this message.



Operation of the BLAST protocol will now be described with reference to FIG. 7 which illustrates protocol behaviour during a successful transfer.



The BLAST client is invoked when a data transfer from the server is required. At any time, but typically before a transfer request, the client may optionally make a request to the BLAST server for data file size information. An appropriate GetFilesize message is constructed and sent. In reply, the server sends a FilesizeData message providing the size information in respect of the file identified in the GetFilesize message. Depending on the implementation environment, this size information may be required for buffer allocation in order to ensure sufficient memory is available before a transfer or to return the information directly to the ultimate user.



To initiate a data transfer, the client sends a request, specifically the DownloadStart message, to the server containing the desired file name, the bytes of the file that are to be transferred, and the maximum PDU size and rate that are to be used in the transmission. A timer is then set by the client to await the arrival of the first incoming data PDU, specifically a first DownloadData message. The value of the timer should be relatively large, on the order of seconds, in order to avoid prematurely giving up on the request. If the timer times out, there are three possibilities. Either the original request was lost in the network, the request was discarded by the server due to overload, or the data PDUs are in transit. In the first two cases, the behaviour of the client will be to retry the request anyway, increasing the timeout with each retry. The consequences of waiting too little outweigh the cost of waiting too long.



If the request was successful, data PDUs will begin arriving in successive DownloadData messages which the server sends periodically until the transfer is finished. Each DownloadData message identifies its position in the file, and the respective data blocks may be placed directly into a buffer by the client. A record of the data PDUs received is maintained by the client. The mechanism for detection of the end of the transfer is left to the client. This can be detected by the arrival of the last requested byte of the file, or by the failure to receive data for a certain interval.



With reference to FIG. 8, detection of any data loss and a re-request strategy is up to the client. An implementation might have the client watching for gaps in the received data, and re-requesting the missing data either before the initial transfer is even complete or wait until the initial transfer is finished. The cumulative transfer rates of running initial requests and re-requests concurrently must of course be within the bounds of the clients PDU processing capabilities and the capacity of the intervening network. The re-request involves the client sending another DownloadStart message which requests the same data file as in the initial request but indicates that the server only transfer the data starting at an offset from the first byte of that file, corresponding to the missing block of data. In the exemplary scenario depicted by FIG. 8, the DownloadStart message requests the remainder of the file (beginning with the missing block), responsive to which the server sends two successive DownloadData messages, the first of which containing the data block that was previously missing.



When re-requested data is received, the client must examine the edition code of the file. This is used to ensure that the file did not change between the original request and the re-request. If the edition code has changed, the client assumes that the entire transfer has been invalidated and must begin anew.



Detection of data loss by the client will be explained in more detail, with reference to FIG. 9. In FIG. 9A, three successive data PDUs (i.e., DownloadData messages) have been successfully received, which contained the first to N bytes of the data file being transferred. As described above, each data PDU, for the block of data therein, specifies the offset into the data file of the first byte of that data block and also the size of that data block. The client can then determine whether the next received data PDU is contiguous based on the offset and size parameters from the prior (last received) PDU. For example, such may simply involve calculating from the start byte offset and the size parameters, an offset value for the end byte of the received data block, in terms of the end byte position within the data file, and comparing the calculated end byte offset with the offset parameter for the start byte taken from the next received data PDU. If the new start byte is contiguous with the previous end byte, the two ranges are coalesced. As illustrated in FIG. 9B, the next PDU (N+1..M) having N+1 to M bytes of data payload arrives and, its payload is inserted into the correct position of the buffer. If the new start byte is not contiguous with the previous end byte, we have identified a missing range of bytes. In FIG. 9C, data PDU (P..Q) arrives. Missing data (M+1..P-1) is detected. If desired, a new download request can be generated immediately for the missing range, or the client can wait until all frames have arrived and decide what needs to be re-requested. In the simplest case, the whole file could be requested again. For example, in FIG. 9D, three more data PDUs arrive, including the last byte of the requested transfer. The missing data is re-requested, and in FIG. 9E, data PDU (M+1..P-1) is received. The transfer is now complete.



With regard to FIG. 10, a particular implementation for the functionality of the BLAST server 12 is illustrated. The BLAST server 12 may be implemented by a conventional data processing platform, having a configuration that includes a primary storage 20 on which data files are maintained and a secondary storage as a file cache 22 which provides faster access to files during transfer. A Protocol Stack 24 provides both a physical network interface and stacked on which may be various levels of communications protocols to effectively communicate through the network (10 in FIG. 1), whereby the various BLAST protocol messages, in accordance with this invention, are exchanged with clients of the server 12. A Request Handler 26 is responsible for processing any received client requests, and may be implemented as a software task for which exemplary pseudocode is illustrated in FIG. 11. A PDU Scheduler 28 functions to effect delivery of the processed requests, and includes a timer 30 and scheduling queue 32. The PDU Scheduler 28 may also be implemented as a software task for which exemplary pseudocode is illustrated in FIG. 12.



In operation, the BLAST server 12 is idle until either a filesize request or download request, respectively embodied by a GetFilesize message and a StartDownload message, is received via the Protocol Stack 24, by the Request Handler 26. If the server 12 is overloaded, the determination of which is left to the Request Handler 26, then the request is silently discarded.



If the request is for a filesize, the available filesystem on the primary storage 20 is searched for the file. If the file is found, a filesize response is constructed by the Request Handler 26 and sent, containing the size of the file. If the file is not found, a filesize response is still constructed and sent, but contains a filesize of zero. It is noted that a file of size zero is not downloadable.



If the request is for a file download, and the file exists, then the Request Handler 26 begins preparation for download. The server 12 must have ready access to the download data during the transfer, and therefore, files are first loaded into the cache 22 to ensure such. The file cache 22 is not required, but is consistent with the overall goal of minimizing server workload and the preferred implementation encompasses a cache. If the most recent version of the file is not already present in the cache 22, it is preloaded into the cache 22 before the transfer begins. If an older version of the file is in the cache 22 and it is not in use, it will be replaced. If an older version of the file is in the cache 22 and is in use, that file will be tagged for discard as soon as the current download is completed.



If the cache 22 is full, and there are cache entries not currently being used, determination of the file to replace is done using a least-recently used algorithm. The size of the cache 22 may also be varied to accommodate more files. However, if the cache 22 is full, incoming requests for files not in the cache must be discarded. If an application environment consists of large numbers of homogeneous clients which tend to request the same set of files, cache replacement should be infrequent even with a fairly small cache 22.



The Request Handler 26 of the BLAST server 12 generates a unique edition number every time a file is loaded into the cache 22 and stores this edition number with the cached file, so that it is consistent for the lifetime of that cached file. During the transfer, this edition number is placed by the PDU Scheduler 28 into each data PDU, embodied by a DownloadData message, to allow the client to ensure that original requests and re-requests were serviced from the same underlying data. If a cache system is not used, then some other value must be provided for an edition number, such as, a file timestamp to ensure that the client can differentiate between different vintages of files with the same name.



The download request contains a client-specified maximum PDU size and minimum inter-PDU arrival time. These values are examined by the BLAST server 12, and may be adjusted downwards, based on server or network capabilities or conditions. The maximum PDU size may be adjusted downwards, and the minimum inter-PDU arrival time may be adjusted upwards. The PDU inter-arrival time is adjusted to an appropriate value for the configuration of the server platform. For instance, if the server 12 cannot reliably schedule PDUs at the requested intervals, then the value may be adjusted accordingly. These values may also be subject to some server-defined valid range of values, for example, multiple predetermined rates from which a particular rate may be selected by a client.



In the preferred implementation, the server 12 also has some knowledge of the capabilities and current condition of the server platform and of the capability and topology of the intervening network, and can further discard requests based on these. For example, servicing a large number of concurrent requests from one region of the network could overload that part of the network, even if each individual download is rate controlled, and cause the network congestion that the rate control scheme tries to prevent. Ideally, situations like this may be predicted by the server 12 and requests can be discarded appropriately. It is noted that filtering download requests or even maintaining a count of concurrent transfers requires some internal server state information to be maintained. However, the BLAST transfer protocol is still stateless with respect to individual clients and individual requests.



When the file is prepared for transmission, a record containing the particulars of the requested download is created and placed into the PDU scheduling queue 32 by the Request Handler 26. Individual download record entries in the PDU scheduling queue 32 are identified by reference 36.



The PDU scheduling queue 32 may be constructed as a circular queue of scheduling timeslots 34, each of which is a data structure formatted as a list of download records 36. However, a timeslot 34 may have a list which is empty when there are no download records to process. The download records 36 represents downloads in progress and each record 36 contains the file identifier, the PDU size and interval, the destination client address and port, the client unique transaction ID, and the remaining bytes to be sent for that download.



The minimum size of the PDU scheduling queue 32 is determined by granularity of the timer 30 (i.e., interval between timer ticks) and a maximum inter-PDU delay allowed by the server 12. There must be more scheduling timeslots 34 than results from dividing the maximum inter-PDU delay by the slot granularity, in order to ensure that rescheduling a download record 36 for the maximum inter-PDU delay does not result in it wrapping around the circular queue 32.



At periodic intervals, according to the minimum granularity of the timer 30 used by the PDU Scheduler 28, each timeslot 34 in the PDU scheduling queue 32 is checked, in sequence, for any download records 36 to be serviced. If there are no download records 36 present in a particular timeslot 34, there is no work to be done and the PDU scheduler 28 sleeps until the next timer tick, responsive to which the following timeslot 34 is checked.



If there are download records 36 present, each download record 36 in turn is retrieved and serviced. Servicing each download record 36 consists of taking a block of data, according to the PDU size and remaining bytes information in that record 36, from the identified file and sending the data block as the next data PDU for that download. If the last PDU for a download has been sent (i.e., transfer of all data in the identified file has been completed), the download record 36 is discarded. If the download is not complete, the download record 36 is updated and rescheduled into the next appropriate timeslot 34 in the PDU scheduling queue 32, determined from the PDU rate contained in the download record 36.



Depending on the number of downloads allowed to proceed at once and the granularity of the timer 30 (i.e., time interval between successive ticks), it may be possible that processing all the download records 36 attached to a particular PDU scheduler timeslot 34 takes longer than the time available. For example, the server 12 is still processing download records 36 at timeslot N when the timer 30 ticks whereby it is time to process slot N+1. This can be considered an instantaneous overload of the server 12, and repeated occurrances of this condition may be used to adjust the request discard policy for future requests. When this occurs, the server 12 should finish processing slot N and move immediately to slot N+1, until it has caught up.



Even though the server rate controls individual downloads, since multiple download records 36 can be processed in each iteration, it may still be presenting extremely bursty traffic to the underlying protocol stack and to the attached network, which may cause a local failure. If this is detectable to the server 12, for example by a return code from a message sending primitive, then the server 12 should defer further work in that scheduling timeslot 34 and reschedule all remaining download requests 36 until the next available timeslot 34.



The preferred implementation of the PDU Scheduler 28 should have a tick granularity for the timer 30 (corresponding to timeslot granularity for the PDU scheduling queue 32) that is considerably smaller than the minimum inter-PDU delay. As long as download requests arrive relatively randomly, distribution of outstanding requests within the scheduler timeslots 34 will be improved, and the chance of server overloads will be reduced.



It is acceptable for the server 12 to service a download at a lower rate than requested, and this may occur during periods of overload, but care must be taken that the inter-PDU delay for a particular download is never less than the client specified time.



Those skilled in the art will recognize that various modifications and changes could be made to the invention without departing from the spirit and scope thereof. It should therefore be understood that the claims are not to be considered as being limited to the precise embodiments of the BLAST protocol and server set forth above, in the absence of specific limitations directed to each embodiment.

PatentNumber=6014707,FIELD OF THE INVENTION



The present invention relates generally to data transfer protocols and, in particular, to a binary large asset stateless transfer (BLAST) protocol for transferring data files in a client-server environment.



BACKGROUND OF THE INVENTION



Referring to FIG. 1, as is well known, computer systems attached to data networks 10 are often connected in a client-server fashion, with a single server 12 servicing requests from multiple clients 14. The number of clients 14 that can be serviced by a single server 12, and thus the cost-effectiveness of the system, is dependent on how efficiently each transaction can be processed.



There are two chief costs to be considered in the design of such a system. One is the computational efficiency of the transfer protocol itself, and the other is the effective utilization of the network 10 between the client 14 and the server 12.



The computational efficiency of the protocol is a measure of the amount of work to be performed by the endpoints, namely the client 14 and server 12, in order to reliably transfer a given amount of information. The focus of attention is on the work required by the server 12, since it is processing requests from a potentially very large number of clients 14. The less work that needs to be performed by the server 12, the lower the cost to the system for providing the service.



From the point of view of the server 12, there are two components to the computational cost of a data transfer protocol. The first is the cost of actually transferring the desired data, and the second is the protocol overhead, which includes every CPU cycle executed which is not directly involved with transmitting the data. This may include connection setup, acknowledgement processing, retransmission, and connection teardown. It also includes the cost of processing (e.g., interrupts and protocol stack overhead) each unique incoming and outgoing PDU (protocol data unit) and any associated header.



While there is a minimum cost of the data transfer itself that cannot be avoided, the protocol overhead associated with the transfer can be reduced.



An independent problem from computational efficiency is network efficiency, which is a measure of how much useful data is carried through the network 10 to the destination as compared to how much was offered to it. Data loss, typically caused by network congestion, is a factor in any network 10 with shared components, where it is possible for instantaneous network load to exceed capacity. In a reasonably engineered network 10, congestion is typically bursty, corresponding to burstiness in the offered data traffic.



There are several approaches to increasing protocol efficiency, particularly be decreasing the protocol overhead. One way to decrease protocol overhead is to increase the size of outgoing PDUs. This amortizes the per-PDU cost over a larger amount of data and requires fewer PDUs to complete the transfer, reducing the total cost of the transfer. Trivial File Transfer Protocol (TFTP), which is based on the well known User Datagram Protocol over the Internet Protocol or UDP/IP, is an example of a protocol that allows an increase in its PDU size to gain efficiency.



Another way to decrease protocol overhead is to reduce the number of incoming PDUs. For example, a TFTP file transfer requires one incoming acknowledgement PDU for each outgoing data PDU. This results in a high transfer cost to the server. In contrast, the TCP-based FTP uses a windowing scheme, where multiple outgoing PDUs may be acknowledged by a single incoming PDU.



Yet another way involves selective retransmission. Windowed protocols that use a go-back-n retransmission scheme can cause successfully received data to be discarded and retransmitted. By causing only the lost data to be retransmitted, unnecessary work at the server can be avoided. Protocols such as XTP implement selective retransmission.



Some transport mechanisms, such as a connectionless transport mechanism, are inherently simpler and more efficient than others. A connectionless, non-guaranteed service like UDP/IP, (as used by TFTP) may be considerably more efficient than reliable, connection-oriented TCP or ISO TP4 for data movement. However, since UDP does not provide the same traffic integrity guarantees as TCP, the responsibility for ensuring reliable transfer lies with the file transfer mechanism itself rather than the underlying system.



All else being equal, increasing either the PDU size or the acknowledgement window increases the chance of network congestion. More data is being sent in each burst to the network. Unless there is some sort of way to limit this traffic, network congestion will increase, leading to data loss and more retransmission, leading back to more work for the server. Unfortunately, most solutions which increase network efficiency tend to increase the computational cost of moving data.



Though designed as an end-to-end mechanism to prevent message loss due to buffer depletion, modified flow control mechanisms can be used to aid network stability. TCP takes an approach that dynamically varies the acknowledgement window based on end-to-end message loss. This can detect and recover from network congestion, but at the cost of considerable overhead on the part of the sender, and at the cost of needing to induce network congestion before it can be detected.



Another solution to network congestion is explicit peer-to-peer rate/flow control, as exemplified in the ATM ABR (available bit rate) scheme. In this scheme, the instantaneously available network bandwidth is advertised to the endpoints, which are expected to limit output accordingly. Unfortunately, this capability is not widely available and is computationally expensive both for the server and the network.



SUMMARY OF THE INVENTION



It is an object of the present invention to provide a new and improved data transfer protocol.



The invention, therefore, according to a first broad aspect provides in communication a server and a client within a data processing system, a method of transferring data from the server to the client comprising the steps of: requesting, by the client, transfer of the data in accordance with a transfer unit size specified by the client; transmitting, by the server, the data in successive blocks having a size based on the client specified transfer unit size, till all the data has been transferred; and delaying at least a predetermined time period between transmission of successive blocks.



In accordance with a second broad aspect of the invention, there is provided a method of controlling a client, adapted to communicate with a server for transferring data from the server, comprising the steps of: sending a transfer request message to the server, the transfer request message including an identification of the data and an indication of a transfer unit size; receiving successive download messages having respective blocks of data from the identified data; and combining the respective blocks whereby the identified data is reconstructed at the client.



In accordance with a third broad aspect of the invention, there is provided a method of controlling a server, adapted to communicate with a client for transferring data to the client, comprising the steps of: receiving a transfer request message from the client, the transfer request message including an identification of the data and an indication of a transfer unit size; transmitting successive download messages having respective blocks of data from the identified data, the blocks having a size based on the indicated transfer unit size; and delaying at least a predetermined time period between transmission of successive download messages.



In accordance with a fourth broad aspect of the invention, there is provided a data processing platform, adapted to communicate with a server for transferring data from the server, comprising: means for sending a transfer request message to the server, the transfer request message including an identification of the data and an indication of a transfer unit size; means for receiving successive download messages having respective blocks of data from the identified data; and means for combining the respective blocks whereby the identified data is reconstructed at the client.



In accordance with a fifth broad aspect of the invention, there is provided a data processing platform, adapted to communicate with a client for transferring data to the client, comprising: means for receiving a transfer request message from the client, the transfer request message including an identification of the data and an indication of a transfer unit size; means for transmitting successive download messages having respective blocks of data from the identified data, the blocks having a size based on the indicated transfer unit size; and means for delaying at least a predetermined time period between transmission of successive download messages.



In accordance with a sixth broad aspect of the invention, there is provided a method of transferring data from a first data processing platform to a second data processing platform, which is communicatively coupled to the first data processing platform, comprising the steps of: specifying, by the second data processing platform, a transfer unit size; and transferring, by the first data processing platform, the data in successive blocks which have a size less than or substantially equal to the specified transfer unit size and which are transmitted less than or substantially at a predetermined rate.



In accordance with a seventh broad aspect of the invention, there is provided in communication a server and a client within a data processing system, a method of transferring data from the server to the client comprising the steps of: sending, by the client, a transfer request message to the server, the transfer request message identifying the data to transfer; transmitting, by the server, successive download messages having respective blocks of data from the identified data, each download message including an indication of position for its block within the identified data; and combining, by the client, the respective blocks of data in sequence according to the position indications, whereby the identified data is reconstructed at the client.



A binary large asset stateless transfer (BLAST) data communications protocol, embodying the present invention, provides a simple, reliable and highly scaleable data transfer facility in a digital data network, interconnecting a file server and a client. A connectionless, unacknowledged data transfer protocol minimizes resource utilization at the data server and is combined with source rate control to reduce congestion in the intervening network.



The BLAST protocol is focused on making the function of the file server as simple as possible. To that end, a system was designed with the following features.



A connectionless transport mechanism is used, to eliminate any overhead in connection establishment and maintenance.



PDU traffic to the server is reduced by using an unacknowledged transfer protocol requiring, in most cases, only a single request to initiate the transfer of all of the data. Transfer time is made largely independent of network end-to-end delay.



Network congestion is limited by regulating the data transfer based on a rate-control parameter. In order to accommodate widely varying capabilities of clients, the requesting client specifies the maximum PDU size and PDU rate in the data request. The server may further reduce these maximums according to its own requirements.



The loss of data is detected by the client and selectively re-requested by the client. The re-requests are completely unique data requests to the server, eliminating any need for client state information to be kept or correlated at the server.



The client has the responsibility to correlate rerequested segments with the original request, and verifying the data is still current.



Client heuristics may be applied to adjust PDU size and rate for requests if patterns of message loss indicate there is network congestion.



The basic rate-control scheme of BLAST is applicable to any data transfer, not just reliable file transfer. This includes the area of streaming video or voice protocols.



BLAST combines an unacknowledged, stateless protocol to increase server scalability; rate control to minimize potential of network congestion; and responsibility for reliable transfer residing in the client.



BRIEF DESCRIPTION OF THE DRAWINGS



The invention will be better understood from the following description of a binary large asset stateless transfer (BLAST) protocol, together with reference to the accompanying drawings in which:



FIG. 1 is a schematic representation of a prior art client-server environment;



FIG. 2 is a structural representation of a message header in the BLAST protocol;



FIG. 3 is a structural representation of a GetFilesize message in the BLAST protocol;



FIG. 4 is a structural representation of a FilesizeData message in the BLAST protocol;



FIG. 5 is a structural representation of a DownloadStart message in the BLAST protocol;



FIG. 6 is a structural representation of a DownloadData message in the BLAST protocol;



FIG. 7 is a timing graph illustrating protocol behaviour during successful transfer;



FIG. 8 is a timing graph illustrating protocol behaviour during errored transfer;



FIG. 9 illustrates client processing of downloaded data PDUs;



FIG. 10 is a schematic representation of an implementation of the BLAST server;



FIG. 11 illustrates exemplary pseudocode whereby a Request Handler task may be implemented in the BLAST server; and



FIG. 12 illustrates exemplary pseudocode whereby a PDU Scheduler task may be implemented in the BLAST server.



DETAILED DESCRIPTION



Having regard to FIG. 1, a binary large asset stateless transfer (BLAST) protocol, in accordance with the invention, provides a mechanism for transferring data files from a server 12 to any of a plurality of clients 14 which communicate through signalling carried by a data network 10. The server 12 and clients 14 are representative of typical data processing platforms suitable for the stated purposes. The data network 10 may be any conventional data communications technology, examples for which include frame relay or asynchronous transfer mode packet switched networks, and an Ethernet local area network running over which is the Internet protocol (IP). The BLAST protocol may be stacked on the network particular protocol(s) to effect the signalling exchanges between the server 12 and each client 14.



The BLAST protocol characterizes a stateless, rate-controlled request/response file transfer protocol. A request for one or many files, in whole or in part, is sent from a particular client 14 to the server 12. The request is identified by a client-unique transaction ID.



The request specifies not only the file(s) to be downloaded, but also includes information that tells the server 12 how the file is to be delivered. This includes the maximum size of an individual data packet and the maximum rate at which the packets can be processed. This is to accommodate a wide range of client configurations. The server 12, upon receiving a request, may further reduce the size and rate of data packets that will be used for the transfer, depending on the current loads of both the server 12 and the network 10. The server 12 then schedules the request and begins transmitting sequential data packets, containing the client-unique transaction ID, at the appropriate rate.



The regular stream of data packets arrives at the client 14 and are assembled into the original file. Each packet identifies its position in the file, and so can be handled independently of any other. There are no acknowledgements of any kind. The server 12 does not know or care whether the individual packets arrive at the client 14. Since the server 12 may be responsible for servicing requests from a very large number of clients 14, the reduction in message load greatly improves the scalability of the protocol. When the data specified in the original request has been sent, the transaction is completed from the server's point of view.



Data integrity is managed by the client 14. The client 14 must examine the received data and decide how to proceed. If there are `gaps` in the received data, as will be the case where there is message loss, the client 14 must initiate a new request for the missing data. There are many possible heuristic algorithms that can be used by the client 14 to get the missing data. It may wait until the original request is completed before rerequesting the data, or it may rerequest as soon as it notices a gap in the file. It might do a request for each gap, it might group gaps together, or it might simply rerequest the whole file. If the missing data exceeds a certain threshold, then network congestion can be assumed, and the rerequests can be made with a lower rate and/or a smaller data size specified. At the server 12, each rerequest by the client 14 is seen as a completely new request. There is no relationship known at the server 12 between any two past, present, or future requests. This further reduces the complexity, and improves the scalability of the server 12.



Signalling between the server 12 and each client 14 to effect the BLAST protocol is implemented by various messages which are transmitted therebetween, via the network 10. Particular embodiments of these BLAST protocol messages are described below and illustrated in FIGS. 2 to 6. Though the messages described pertain to a specific UDP/IP-based implementation of the BLAST protocol, it should be understood that nothing restricts this from being implemented over any other protocol stack, or in other operating environments. Similarly, PDU data field sizes are shown as present in this implementation, but are not necessarily restricted to the indicated size which may be adapted to satisfy requirements of the particular application.



Referring to FIG. 2, every BLAST protocol message shares a common header, identified herein as messageHeader, to simplify message interpretation. The messageHeader defines a set of parameters at the start of each message sent between the BLAST server and client. Fields forming part of the messageHeader include:



version--Parameter identifies a protocol version number which is used to ensure compatibility of messages.



messageID--A message type identifier parameter.



messageLength--Parameter indicates the total length of the entire message in bytes, including the message header 20.



transactionID--An arbitrary client assigned parameter used to associate data blocks with their respective requests.



Referring to FIG. 3, a GetFilesize message is illustrated. This message requests that the server reply with the size of the requested file, so that the client can ensure sufficient resources are available and allocated to receive it. Fields forming part of the GetFilesize message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F5 Hex by which value the GetFilesize message is identified.



destinationAddress--Parameter identifies the IP address of the client.



destinationPort--Parameter identifies the UDP port of the client.



fileDescriptorLength--Parameter indicates the length of the fileDescriptor in bytes.



fileDescriptor--Parameter identifies the requested file by providing a null-terminated full pathname of the file to be transferred.



Referring to FIG. 4, a FilesizeData message is illustrated. This message is a reply sent from the server to the client to satisfy the GetFileSize request message. Fields forming part of the FilesizeData message include:



messageHeader--Includes parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F6 Hex by which value the FilesizeData message is identified.



filesize--The size of the file, specified in the GetFilesize message, in bytes. If the file could not be found in the BLAST filesystem, the filesize will be 0.



Referring to FIG. 5, a DownloadStart message is illustrated. This message is sent from the client to the server to initiate the data transfer for a requested file. Fields forming part of the DownloadStart message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F3 Hex by which value the DownloadStart message is identified.



blockSize--Parameter indicates a maximum PDU (i.e., data block or packet) size for the server to use.



startByte--Parameter provides an offset within the file at which byte of data transfer is to begin (i.e., the first byte to send). The beginning of the file has an offset value of 0.



numBytes--Parameter indicates the total number of bytes of the file to send. A value of 0 indicates the entire file, or remainder of the file starting from the offset byte position when the offset parameter is greater than 0.



destinationAddress--Parameter identifies the IP address of the download client.



destinationPort--Parameter identifies the UDP port of the download client.



delay--Parameter indicates a minimum delay in micro-seconds between sending successive data PDUs.



fileDescriptorLength--Parameter indicates the length of the fileDescriptor in bytes.



fileDescriptor--Parameter identifies the requested file by providing a null-terminated full pathname of the file to be transferred.



Referring to FIG. 6, a DownloadData message is illustrated. This message contains the actual data for the file transfer. The blocks of data are divided into the blockSize bytes of data, as specified in the DownloadStart message, and sent in order to the client. Fields forming part of the DownloadData message include:



messageHeader--Contains parameters as described above in connection with FIG. 2. In particular, the messageID parameter, for example, equals 00F4 Hex by which value the DownloadData message is identified.



firstByte--Parameter provides an offset into the file for the first byte of this data block. An offset value of 0 corresponds to the first byte in the file.



data bytes--Parameter indicates the number of data bytes in this block.



edition--Parameter identifies a version number of the file being downloaded. This allows the client to ensure that rerequests are being made from the same file as an initial request.



data--This parameter is the block of data payload being carried by this message.



Operation of the BLAST protocol will now be described with reference to FIG. 7 which illustrates protocol behaviour during a successful transfer.



The BLAST client is invoked when a data transfer from the server is required. At any time, but typically before a transfer request, the client may optionally make a request to the BLAST server for data file size information. An appropriate GetFilesize message is constructed and sent. In reply, the server sends a FilesizeData message providing the size information in respect of the file identified in the GetFilesize message. Depending on the implementation environment, this size information may be required for buffer allocation in order to ensure sufficient memory is available before a transfer or to return the information directly to the ultimate user.



To initiate a data transfer, the client sends a request, specifically the DownloadStart message, to the server containing the desired file name, the bytes of the file that are to be transferred, and the maximum PDU size and rate that are to be used in the transmission. A timer is then set by the client to await the arrival of the first incoming data PDU, specifically a first DownloadData message. The value of the timer should be relatively large, on the order of seconds, in order to avoid prematurely giving up on the request. If the timer times out, there are three possibilities. Either the original request was lost in the network, the request was discarded by the server due to overload, or the data PDUs are in transit. In the first two cases, the behaviour of the client will be to retry the request anyway, increasing the timeout with each retry. The consequences of waiting too little outweigh the cost of waiting too long.



If the request was successful, data PDUs will begin arriving in successive DownloadData messages which the server sends periodically until the transfer is finished. Each DownloadData message identifies its position in the file, and the respective data blocks may be placed directly into a buffer by the client. A record of the data PDUs received is maintained by the client. The mechanism for detection of the end of the transfer is left to the client. This can be detected by the arrival of the last requested byte of the file, or by the failure to receive data for a certain interval.



With reference to FIG. 8, detection of any data loss and a re-request strategy is up to the client. An implementation might have the client watching for gaps in the received data, and re-requesting the missing data either before the initial transfer is even complete or wait until the initial transfer is finished. The cumulative transfer rates of running initial requests and re-requests concurrently must of course be within the bounds of the clients PDU processing capabilities and the capacity of the intervening network. The re-request involves the client sending another DownloadStart message which requests the same data file as in the initial request but indicates that the server only transfer the data starting at an offset from the first byte of that file, corresponding to the missing block of data. In the exemplary scenario depicted by FIG. 8, the DownloadStart message requests the remainder of the file (beginning with the missing block), responsive to which the server sends two successive DownloadData messages, the first of which containing the data block that was previously missing.



When re-requested data is received, the client must examine the edition code of the file. This is used to ensure that the file did not change between the original request and the re-request. If the edition code has changed, the client assumes that the entire transfer has been invalidated and must begin anew.



Detection of data loss by the client will be explained in more detail, with reference to FIG. 9. In FIG. 9A, three successive data PDUs (i.e., DownloadData messages) have been successfully received, which contained the first to N bytes of the data file being transferred. As described above, each data PDU, for the block of data therein, specifies the offset into the data file of the first byte of that data block and also the size of that data block. The client can then determine whether the next received data PDU is contiguous based on the offset and size parameters from the prior (last received) PDU. For example, such may simply involve calculating from the start byte offset and the size parameters, an offset value for the end byte of the received data block, in terms of the end byte position within the data file, and comparing the calculated end byte offset with the offset parameter for the start byte taken from the next received data PDU. If the new start byte is contiguous with the previous end byte, the two ranges are coalesced. As illustrated in FIG. 9B, the next PDU (N+1 . . . M) having N+1 to M bytes of data payload arrives and, its payload is inserted into the correct position of the buffer. If the new start byte is not contiguous with the previous end byte, we have identified a missing range of bytes. In FIG. 9C, data PDU (P . . . Q) arrives. Missing data (M+1 . . . P-1) is detected. If desired, a new download request can be generated immediately for the missing range, or the client can wait until all frames have arrived and decide what needs to be re-requested. In the simplest case, the whole file could be requested again. For example, in FIG. 9D, three more data PDUs arrive, including the last byte of the requested transfer. The missing data is re-requested, and in FIG. 9E, data PDU (M+1 . . . P-1) is received. The transfer is now complete.



With regard to FIG. 10, a particular implementation for the functionality of the BLAST server 12 is illustrated. The BLAST server 12 may be implemented by a conventional data processing platform, having a configuration that includes a primary storage 20 on which data files are maintained and a secondary storage as a file cache 22 which provides faster access to files during transfer. A Protocol Stack 24 provides both a physical network interface and stacked on which may be various levels of communications protocols to effectively communicate through the network (10 in FIG. 1), whereby the various BLAST protocol messages, in accordance with this invention, are exchanged with clients of the server 12. A Request Handler 26 is responsible for processing any received client requests, and may be implemented as a software task for which exemplary pseudocode is illustrated in FIG. 11. A PDU Scheduler 28 functions to effect delivery of the processed requests, and includes a timer 30 and scheduling queue 32. The PDU Scheduler 28 may also be implemented as a software task for which exemplary pseudocode is illustrated in FIG. 12.



In operation, the BLAST server 12 is idle until either a filesize request or download request, respectively embodied by a GetFilesize message and a StartDownload message, is received via the Protocol Stack 24, by the Request Handler 26. If the server 12 is overloaded, the determination of which is left to the Request Handler 26, then the request is silently discarded.



If the request is for a filesize, the available filesystem on the primary storage 20 is searched for the file. If the file is found, a filesize response is constructed by the Request Handler 26 and sent, containing the size of the file. If the file is not found, a filesize response is still constructed and sent, but contains a filesize of zero. It is noted that a file of size zero is not downloadable.



If the request is for a file download, and the file exists, then the Request Handler 26 begins preparation for download. The server 12 must have ready access to the download data during the transfer, and therefore, files are first loaded into the cache 22 to ensure such. The file cache 22 is not required, but is consistent with the overall goal of minimizing server workload and the preferred implementation encompasses a cache. If the most recent version of the file is not already present in the cache 22, it is preloaded into the cache 22 before the transfer begins. If an older version of the file is in the cache 22 and it is not inuse, it will be replaced. If an older version of the file is in the cache 22 and is inuse, that file will be tagged for discard as soon as the current download is completed.



If the cache 22 is full, and there are cache entries not currently being used, determination of the file to replace is done using a least-recently used algorithm. The size of the cache 22 may also be varied to accommodate more files. However, if the cache 22 is full, incoming requests for files not in the cache must be discarded. If an application environment consists of large numbers of homogeneous clients which tend to request the same set of files, cache replacement should be infrequent even with a fairly small cache 22.



The Request Handler 26 of the BLAST server 12 generates a unique edition number every time a file is loaded into the cache 22 and stores this edition number with the cached file, so that it is consistent for the lifetime of that cached file. During the transfer, this edition number is placed by the PDU Scheduler 28 into each data PDU, embodied by a DownloadData message, to allow the client to ensure that original requests and re-requests were serviced from the same underlying data. If a cache system is not used, then some other value must be provided for an edition number, such as, a file timestamp to ensure that the client can differentiate between different vintages of files with the same name.



The download request contains a client-specified maximum PDU size and minimum inter-PDU arrival time. These values are examined by the BLAST server 12, and may be adjusted downwards, based on server or network capabilities or conditions. The maximum PDU size may be adjusted downwards, and the minimum inter-PDU arrival time may be adjusted upwards. The PDU inter-arrival time is adjusted to an appropriate value for the configuration of the server platform. For instance, if the server 12 cannot reliably schedule PDUs at the requested intervals, then the value may be adjusted accordingly. These values may also be subject to some server-defined valid range of values, for example, multiple predetermined rates from which a particular rate may be selected by a client.



In the preferred implementation, the server 12 also has some knowledge of the capabilities and current condition of the server platform and of the capability and topology of the intervening network, and can further discard requests based on these. For example, servicing a large number of concurrent requests from one region of the network could overload that part of the network, even if each individual download is rate controlled, and cause the network congestion that the rate control scheme tries to prevent. Ideally, situations like this may be predicted by the server 12 and requests can be discarded appropriately. It is noted that filtering download requests or even maintaining a count of concurrent transfers requires some internal server state information to be maintained. However, the BLAST transfer protocol is still stateless with respect to individual clients and individual requests.



When the file is prepared for transmission, a record containing the particulars of the requested download is created and placed into the PDU scheduling queue 32 by the Request Handler 26. Individual download record entries in the PDU scheduling queue 32 are identified by reference 36.



The PDU scheduling queue 32 may be constructed as a circular queue of scheduling timeslots 34, each of which is a data structure formatted as a list of download records 36. However, a timeslot 34 may have a list which is empty when there are no download records to process. The download records 36 represents downloads in progress and each record 36 contains the file identifier, the PDU size and interval, the destination client address and port, the client unique transaction ID, and the remaining bytes to be sent for that download.



The minimum size of the PDU scheduling queue 32 is determined by granularity of the timer 30 (i.e., interval between timer ticks) and a maximum inter-PDU delay allowed by the server 12. There must be more scheduling timeslots 34 than results from dividing the maximum inter-PDU delay by the slot granularity, in order to ensure that rescheduling a download record 36 for the maximum inter-PDU delay does not result in it wrapping around the circular queue 32.



At periodic intervals, according to the minimum granularity of the timer 30 used by the PDU Scheduler 28, each timeslot 34 in the PDU scheduling queue 32 is checked, in sequence, for any download records 36 to be serviced. If there are no download records 36 present in a particular timeslot 34, there is no work to be done and the PDU scheduler 28 sleeps until the next timer tick, responsive to which the following timeslot 34 is checked.



If there are download records 36 present, each download record 36 in turn is retrieved and serviced. Servicing each download record 36 consists of taking a block of data, according to the PDU size and remaining bytes information in that record 36, from the identified file and sending the data block as the next data PDU for that download. If the last PDU for a download has been sent (i.e., transfer of all data in the identified file has been completed), the download record 36 is discarded. If the download is not complete, the download record 36 is updated and rescheduled into the next appropriate timeslot 34 in the PDU scheduling queue 32, determined from the PDU rate contained in the download record 36.



Depending on the number of downloads allowed to proceed at once and the granularity of the timer 30 (i.e., time interval between successive ticks), it may be possible that processing all the download records 36 attached to a particular PDU scheduler timeslot 34 takes longer than the time available. For example, the server 12 is still processing download records 36 at timeslot N when the timer 30 ticks whereby it is time to process slot N+1. This can be considered an instantaneous overload of the server 12, and repeated occurrances of this condition may be used to adjust the request discard policy for future requests. When this occurs, the server 12 should finish processing slot N and move immediately to slot N+1, until it has caught up.



Even though the server rate controls individual downloads, since multiple download records 36 can be processed in each iteration, it may still be presenting extremely bursty traffic to the underlying protocol stack and to the attached network, which may cause a local failure. If this is detectable to the server 12, for example by a return code from a message sending primitive, then the server 12 should defer further work in that scheduling timeslot 34 and reschedule all remaining download requests 36 until the next available timeslot 34.



The preferred implementation of the PDU Scheduler 28 should have a tick granularity for the timer 30 (corresponding to timeslot granularity for the PDU scheduling queue 32) that is considerably smaller than the minimum inter-PDU delay. As long as download requests arrive relatively randomly, distribution of outstanding requests within the scheduler timeslots 34 will be improved, and the chance of server overloads will be reduced.



It is acceptable for the server 12 to service a download at a lower rate than requested, and this may occur during periods of overload, but care must be taken that the inter-PDU delay for a particular download is never less than the client specified time.



Those skilled in the art will recognize that various modifications and changes could be made to the invention without departing from the spirit and scope thereof. It should therefore be understood that the claims are not to be considered as being limited to the precise embodiment of the BLAST protocol set forth above, in the absence of specific limitations directed to each embodiment.

PatentNumber=6026375,BACKGROUND OF THE INVENTION



The present invention relates to methods and systems that enable service providers to expedite services to customers in a mobile environment, and more particularly, to methods and systems that enable service providers to receive an order from customers in a mobile environment and schedule the completion of the customer's order to coincide with the customer's arrival at a local facility able to satisfy the customer's order.



Busy people are constantly seeking ways to save time and are easily frustrated when they have to wait lengthy periods of time to receive goods or services from a service provider. Service providers recognize that shorter waiting periods increase customer satisfaction which ultimately results in increased sales. Accordingly, it is desirable for service providers to adopt methods of doing business that eliminate or greatly reduce the time the customer spends waiting to receive goods or services.



Many technological devices exist today that promise to reduce the amount of time people spend completing routine tasks. Computers, for example, increase productivity by automating routine tasks, freeing up time for people to do other things while waiting for the computer to complete the task. New mobile technologies, such as cellular phones, permit people to perform routine tasks, like shopping or ordering meals, while away from home or commuting. The popularity of "drive-thru" services further attests to people's increased mobility and desire to purchase goods and services from their cars.



Today's consumers are increasingly demanding that service providers deliver goods and services with a minimal amount of time spent waiting and often choose to patronize the service provider that promises the quickest response time. Customers traditionally have relied on two methods for reducing time spent waiting to pick up ordered goods: phone-in advance orders and "drive-thru" processes.



The traditional "drive-thru" process is inherently inefficient, however, because customers typically place their orders at the facility and then must wait for the goods to be produced. Efforts to reduce wait time by streamlining the drive-thru process have their own drawbacks and, in addition, only have reduced, but not eliminated, the amount of time the customer waits in line. The three window concept, or one window each for ordering, paying, and pick-up, for example, requires service providers to have more people involved in the ordering process and requires new building construction. Another disadvantage of this solution is that it is not readily adaptable to markets other than fast food meal processes.



Another approach by service providers to take advantage of waiting times by collocating their services with other processes that have unavoidable waiting periods. For example, people often experience lengthy wait times in airports, ski-lift lines or gas stations. Collocation is likewise unacceptable because it would require the service providers to build new facilities or obtain permits to operate in these other facilities. Furthermore, this solution offers the service provider only the opportunity to service customers whose primary mission is the other process and does not allow service providers to offer enhanced service to loyal customers who do not frequent the host facilities.



A system where the customer uses a conventional phone to call in orders to the service provider from the home or office also is flawed. Customers, for example, may have a number of errands to run and may not be able to predict accurately when they will arrive at the pick-up facility. Because service providers typically begin processing an order upon receipt, this system may mean that the order is available for pick-up well before the customer arrives which is unsatisfactory in many situations, particularly when the order is for prepared, perishable items. Customers also may lose time by placing an order with a provider that either does not have the capacity to fill their order, or is not the closest facility to their next errand.



Technology exists, however, that would allow a service provider to determine the exact location, speed and direction of a mobile customer that calls in to place an order and to schedule the order accordingly. The invention combines customer tracking capability with estimated arrival time-based scheduling techniques to allow service providers to manage their resources more efficiently and reduce customer waiting times to a minimum. The invention allows the time sequence for an order process to be superimposed onto the time sequence while customers are mobile en route to the supplier.



As is apparent from the above-described deficiencies with conventional systems, a need exists for a user-friendly method that reduces or eliminates the time a customer in a mobile environment waits to receive an order.



A further need exists for a method and system for receiving orders from mobile locations, determining the customer's location, and determining a local facility capable of completing the order based on the customer's location.



Yet another need exists for a method and system that allows service providers to schedule the completion of an order to coincide with the customer's arrival at the local facility.



A further need exists for a system that allows the service provider to offer the consumer individualized packages and specials specifically tailored to meet the individual needs of that consumer.



SUMMARY OF THE INVENTION



To address these concerns and limitations, methods and systems for processing an order from a mobile customer consistent with this invention allow a service provider to receive customer location information from a location determination system and schedule an order from the customer to be completed by a local facility so that the order will be ready when the customer arrives.



Specifically, a method of processing an order from a mobile customer comprises receiving an order from a mobile customer, wherein the order includes customer identifying information; receiving customer location information from a location determination system; identifying at least one facility capable of completing the order; determining an estimated time of arrival of the customer at each identified facility using the customer location information; determining an amount of time needed by each identified facility to complete the order; and determining which facility of the at least one identified facility is capable of completing the order prior to the customer's estimated time of arrival at the determined facility.



Additionally, a method of processing an order from a mobile customer comprises receiving an order from a mobile customer, wherein the order includes customer identifying information; receiving an order from a mobile customer, wherein the order includes customer identifying information; receiving customer location information from a location determination system; identifying at least one facility capable of completing the order; determining an estimated time of arrival of the customer at each identified facility using the customer location information; determining an amount of time needed by each identified facility to complete the order; and determining which facility of the at least one identified facility is capable of completing the order within a predetermined window of time coinciding with the customer's estimated time of arrival at the determined facility.



A method of processing an order from a mobile customer comprises receiving an order from a personal assistant agent acting on behalf of a customer, wherein the order includes customer identifying information; identifying at least one facility capable of completing the order; determining an estimated time of arrival of the customer at each identified facility; determining an amount of time needed by each identified facility to complete the order; and determining which one of the at least one identified facility is capable of completing the order within a predetermined window of time coinciding with the customer's estimated time of arrival at the determined facility.



A method of processing an order from a mobile customer comprises receiving an order from a personal assistant agent acting on behalf of a customer, wherein the order includes customer identifying information; identifying at least one facility capable of completing the order; determining a desired time of completion of the order; determining an amount of time needed by each identified facility to complete the order; and determining which one of the at least one identified facility is capable of completing the order within a predetermined window of time coinciding with the desired time of completion of the order.



A method of placing an order with a service provider comprises transmitting an order to a service provider; receiving location information from a location determination system; transmitting the location information to the service provider; and receiving local facility information identifying a local facility that is able to satisfy the order.



A system for processing an order from a mobile customer comprises a component for receiving an order from a mobile customer, wherein the order includes customer identifying information; a component for receiving customer location information from a location determination system; a component for identifying at least one facility capable of completing the order; a component for determining an estimated time of arrival of the customer at each identified facility using the customer location information; a component for determining an amount of time needed by each identified facility to complete the order; and a component for determining which facility of the at least one identified facility is capable of completing the order prior to the customer's estimated time of arrival at the determined facility.



Furthermore, a system for processing an order from a mobile customer comprises a component for receiving an order from a mobile customer, wherein the order includes customer identifying information; a component for receiving an order from a mobile customer, wherein the order includes customer identifying information; a component for receiving customer location information from a location determination system; a component for identifying at least one facility capable of completing the order; a component for determining an estimated time of arrival of the customer at each identified facility using the customer location information; a component for determining an amount of time needed by each identified facility to complete the order; and a component for determining which facility of the at least one identified facility is capable of completing the order within a predetermined window of time coinciding with the customer's estimated time of arrival at the determined facility.



A system for processing an order from a mobile customer comprises a component for receiving an order from a personal assistant agent acting on behalf of the customer, wherein the order includes customer identifying information; a component for identifying at least one facility capable of completing the order; a component for determining an estimated time of arrival of the customer at each identified facility; a component for determining an amount of time needed by each identified facility to complete the order; and a component for determining which one of the at least one identified facility is capable of completing the order prior to the customer's estimated time of arrival at the determined facility.



A system for processing an order from a mobile customer comprises a component for receiving an order from a personal assistant agent acting on behalf of the customer, wherein the order includes customer identifying information; a component for identifying at least one facility capable of completing the order; a component for determining a desired time of completion of the order; a component for determining an amount of time needed by each identified facility to complete the order; and a component for determining which one of the at least one identified facility is capable of completing the order within a predetermined window of time coinciding with the desired time of completion of the order.



Finally, a system for ordering from a service provider from a mobile location comprises transmitting an order to a service provider from a mobile location; receiving location information from a location determination system; transmitting the location information to the service provider; and receiving local facility information identifying the local facility closest to the mobile location that is able to satisfy the order.



Additional advantages of the invention will be set forth in part in the description that follows and in part will be obvious from the description or may be learned by practice of the invention. The advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the appended claims. Both the foregoing general description and the following detailed description are exemplary and explanatory only, and are not restrictive of the invention as claimed.



BRIEF DESCRIPTION OF THE DRAWINGS



The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate presently preferred embodiments of the invention and, together with the general description given above and the detailed description of a preferred embodiments given below, explain the principles of the invention.



FIG. 1 is a block diagram illustrating one embodiment of the system according to the present invention.



FIG. 2 is a block diagram illustrating Mobile Customer Premises Equipment ("MCPE") 105 of FIG. 1.



FIG. 3 is a block diagram illustrating Service Provider's System ("SPS") 150 of FIG. 1.



FIG. 4 is an illustration of Customer Database 374 shown in FIG. 3.



FIG. 5 is an illustration of Facilities Database 372 shown in FIG. 3.



FIGS. 6A-6C contain a flow diagram of a method for processing an order from a mobile customer according to the present invention.



DETAILED DESCRIPTION OF THE INVENTION



A. Introduction



Consistent with the present invention, a mobile customer uses a communications device, such as a cellular phone or laptop computer communicating in a wireless mode or over the Internet, to order goods or services from a service provider. The term "service provider" is used herein to mean any entity that receives orders from customers and, in response to the orders, provides goods or services. Service providers may be, for example, a restaurant, a plumbing parts distributor, or a pharmacy dispensing prescription drugs. The term "customer" is used herein to mean any entity that procures the goods or services of the service provider whether for free or in exchange for compensation.



A tracking device collocated with a mobile customer allows a mobile location determination system to determine the customer's location and transmit it to the service provider. The service provider uses the customer's location to identify a local facility that can satisfy the customer's order. The service provider transmits the order to the local facility and schedules the completion of the order to coincide with the customer's arrival at the local facility. To further expedite the order process, the service provider also can request and receive payment electronically.



Reference will now be made in detail to the preferred embodiments of the invention, examples of which are illustrated in the accompanying drawings. Wherever possible, the same reference numbers will be used throughout the drawings to refer to the same or like parts.



B. Basic System Components



FIG. 1 illustrates the basic components of a system consistent with the present invention. Generally, the system includes a Customer 100, mobile customer premises equipment ("MCPE") 105, a mobile location determination system ("MLDS") 145, service provider's system ("SPS") 150, and Financial System 158.



Customer 100 is a person or entity in a mobile environment that would like to place an order with the service provider. Customer 100 may be, for example, a person traveling in an automobile equipped with a MCPE 105.



MCPE 105 is a communications device preferably with software programming capabilities. MCPE 105 may be implemented, using a variety of devices such as a cellular phone, preferably with voice-activated dialing, a personal digital assistant ("PDA") having voice recognition and sound capabilities, or a special information device developed specifically for use in automobiles (such as a dashboard-mounted map and information display screen). In an alternative embodiment, MCPE 105 could be a system consisting of an ordinary cellular telephone and a home or laptop personal computer (PC). MCPE 105 preferably includes a receiver that could be used by MLDS 145 to determine the customer's geographic location. One example of a suitable receiver is one of the type currently used in automobile navigation systems to receive satellite signals from the Global Positioning System ("GPS"). MCPE 105 interacts with MLDS via connection 114, which is likely to be a satellite communications link.



MCPE 105 also is capable of communicating with Financial System 158 via connection 116, which comprises a conventional communication device or system, such as the Internet, wireless cellular communications, or a telephone line. Financial System 158 may be a bank or other financial institution capable of issuing payment to the service provider for the goods or services on behalf of customer 100.



SPS 150 is a conventional, commercially available including at least a processor 165 and memory 170. Memory 170 is a data storage device, such as a hard disk, magnetic or optical storage unit, or CD-ROM drive, and stores databases used in processing transactions consistent with the present invention. Processor 165 is any commercially available processor with sufficient memory and processing capability to perform the disclosed functionality. As shown in FIG. 1, in a preferred embodiment, SPS 150 is capable of communicating over a network with at least one computer at each participating facility that will receive orders from SPS 150. Local Facilities 172, 174, and 176, therefore, are preferably computers capable of receiving information from and transmitting information to SPS 150 on behalf of the local facility where they are located.



MLDS 145 provides information regarding the customer's position at the time of ordering and periodically may provide updated location information as the customer approaches the local facility. MLDS 145 may be, for example, any vehicle locator and communications system capable of receiving signals from a transmitting device collocated with Customer 100, either in the vehicle or contained within MCPE 105, and returning information that can be used to determine the approximate geographic location of the customer. One example may be a telephone system that can determine a customer's location from a telephone call. Another example of such a system is the Global Positioning System (GPS) operated by the United States Government. GPS is a satellite-based radio positioning system that can provide position, velocity and time information to users equipped with tracking devices and receivers. This technology already has been used by automotive manufacturers in commercial applications such as road-side assistance or automobile navigation systems but, to date, there has been no use of GPS systems to track arriving customers and allow scheduling of order preparation en route.



C. Agent System Components



Consistent with the present invention, the system shown in FIG. 1 may be implemented using intelligent software agents. The term "intelligent software agent" means a software program that is designed to act on a user's behalf to achieve a goal specified by the user. A software agent consistent with the present invention has the capability to autonomously initiate actions without the direct initiation of the user; to interact with the user or other humans through some form of user interface; to interact with other software agents via some kind of agent communication language; to react to events in the agent environment or in the real world (i.e., user actions) and respond in a timely fashion; and possibly to possess some type of "intelligence," such as learning about the habits and preferences of the user and adapt its own behavior accordingly.



FIG. 2 illustrates MCPE 105 of the present invention as shown in FIG. 1. Personal Agent System ("PAS") 210 is a software operating system containing a number of software programs. In alternative embodiments, PAS 210 may reside on one or more of MCPE 105, SPS 150, or a communications network linking MCPE 105 and SPS 150. Where PAS 210 resides on a home or laptop PC or PDA, the present invention could be activated through a control panel or wizard within a PC application, and used later in a mobile environment via voice recognition on a cellular telephone. PAS 210 is portable and can dynamically reside with its user as the user moves from fixed to mobile environments.



Consistent with this invention, PAS 210 contains Personal Assistant Agent ("PAA") 220, Network Agent 225, Scheduling Agent 230 and Financial Agent 235. These software agents are preferably independent of one another in that one software agent could be performing one function, such as communicating with the customer, while other software agents are performing other functions separately.



PAA 220 is a software agent that interacts directly with the customer, preferably through some type of natural dialog. A natural dialog is a means of communication between human and machine which does not require the human to know the communication requirements of the machine. Network Agent 225 is a software agent that communicates with other computers or agent systems through the appropriate types of protocols and agent communication languages in operations that are invisible to the user. Scheduling Agent 230 is a software agent that keeps track of the customer's location and the temporal information associated with activities of Customer 100 or PAS 210. Scheduling Agent 230 communicates with MLDS 145 to obtain information regarding the customer's position and transmits this information through Network Agent 225 to agents of SPS 150 that need this information.



Financial Agent 235 is the component of PAS 210 that performs financial transactions on behalf of the customer. For example, Financial Agent 235 communicates with Financial System 158 or any other financial institution at which the customer has established credit or debit accounts, and instructs the institution to transfer payment to SPS 150. Financial Agent 235 also will provide transaction confirmations via Network Agent 225 to the appropriate agent components within SPS 150.



FIG. 3 shows the SPS 150 of FIG. 1. Service Provider's Agent System ("SPAS") 365 is a software operating system containing a number of software programs. SPAS 365 preferably resides on SPS 150 as shown in FIG. 3 but, in alternative embodiments, may reside on one or more of SPS 150, MCPE 105 and the communications network linking SPS 150 and MCPE 105. SPAS 365 preferably comprises intelligent software agents, such as Customer Service Agent ("CSA") 355 and Systems Agent 360, that perform functions on behalf of the service provider. SPAS 365 is capable of accessing Facilities Database 372 and Customer Database 374. Facilities Database 372 and Customer Database 374 are described below.



CSA 355 is primarily responsible for obtaining orders from customers and transmitting order information via the System Agent 360 to the components of the local service providers. CSA 355 may communicate directly with customers through some type of user interface, such as a vocal-auditory interface employing voice recognition technologies. Alternatively, CSA 355 may obtain an order by communicating with PAS 210 through Network Agent 325 using some type of agent communication language.



Systems Agent 360 provides a communications link between CSA 355 and the various components of SPS 150. While CSA 355 interacts with customers (or their agents), Systems Agent 360 sends queries to the databases of SPS 150, transmits order information to Local Scheduler 376, and performs other internal system communication functions.



Local Scheduler 376 receives the order from System Agent 360 and schedules the order to be completed when the customer arrives at the local facility. If the order has multiple components, Local Scheduler 376 also may break down the order into executable instructions for Local Facilities 172, 174 and 176. In a fast food restaurant scenario, for example, an order may consist of a hamburger, french fries and a drink. Each component of the order has a different preparation time. Local Scheduler 376 uses the customer's ETA to schedule the completion of each component to coincide with the customer's arrival at the local facility. An additional example is an order for multiple prescription medicines where at least one of the prescriptions can be prepared quickly, such as by counting pills, but at least one prescription requires a longer preparation time, such as preparing serum or syrups.



Samples of the contents of databases 372 and 374 are shown in FIGS. 4 and 5 respectively. The specific data and field illustrated in these figures represent only one possible embodiment of the records stored in the databases of the invention. The data and fields of these data bases, as well as the number of databases, can be readily modified from the described embodiment.



Facilities Database 372 is a list of participating local facilities that can receive orders from SPS 150. The database may include information about the facility such as address, telephone number, type of orders it can process, capacity, stock on hand, and possibly, geographic location information for use with MLDS 145.



Customer Database 374 contains a list of the service provider's participating customers and other customer account information. Customer accounts preferably include information regarding the customer's usual orders, special preparation instructions, what types of specials they want to hear about, and other customer preferences. Customer accounts in Customer Database 374 either could be developed over time as the system interacts with the customer, or could be set up and maintained by the customer. Customer Database 374 also may contain information about the customer's preferred method of payment, such as debit card, credit card, smart card, or cash.



D. Process



FIGS. 6A through 6C include a flow chart for a method for processing an order in accordance with this invention. To begin, Customer 100 initiates an order. (Step 604). Customer 100 may contact SPS 150 directly by, for example, using a cellular phone to connect directly to CSA 355 (Step 606). In that case, the process resumes at Step 660.



If Customer 100 has a MCPE 105 with agent capability, Customer 100 may contact SPS 150 by activating Personal Assistant Agent ("PAA") 220 of PAS 210 and placing an order (Step 610). In a preferred embodiment, PAA 220 serves as the central control point of PAS 210 in that all requests, queries, and instructions given to PAS 210 by the customer or by other computer systems are initially handled by PAA 220. Depending on the type of request or instruction, PAA 220 will perform the appropriate action itself or activate the appropriate software agent to execute the operation. In alternative embodiments, PAA 220 may be preprogrammed to initiate orders without customer contact.



For example, if the service provider requires customer location information, PAA 220 will activate Scheduling Agent 230, which queries MLDS 145 for the customer's location (Step 620). MLDS 145 returns information indicating the customer's location to Scheduling Agent 230 which, in turn, provides the information to PAA 220 (Step 630). Scheduling Agent 230 also might transmit this information to other systems or applications used by the customer, such as a calendar application.



To communicate with SPS 150, PAA 220 activates Network Agent 225 which establishes a connection with CSA 355 (Step 640). Via Network Agent 225, PAA 220 provides the customer's order and location information to CSA 355 (Step 650). CSA 355 provides the customer's order and location information to System Agent 360 (Step 660). At this point, System Agent 360 may access the customer's account in Customer Database 374 and retrieve information regarding the customer's preferences (Step 662). System Agent 360, for example, may use the information in the customer's account to prepare the order in a preferred way. The information in Customer Database 374 may also be used to market other products or services to the customer that are similar to those previously ordered.



Next, System Agent 30 determines a local facility using the customer's location information and information from Facilities Database 372 (Step 664). Facilities Database 372 is a list of participating service provider facilities, location information, and other information about the facility, such as stock on hand or capability. In a preferred embodiment, System Agent 360 calculates the estimated time of arrival (ETA) of the customer to the local facility (Step 666). Preferably, the local facility is the facility nearest geographically to the customer's location at the time of the order or a facility that is convenient to the customer's planned travel route, such as on the way home from work. System Agent 360 then queries Local Scheduler 376 to determine whether the local facility can satisfy the order (Step 670).



In determining whether a local facility can satisfy an order, System Agent 360 may evaluate, for example, whether the local facility has the necessary stock on hand to fill the customer's order or whether the number of currently unsatisfied orders at the local facility would result in an unacceptable wait time for the consumer. If a local facility cannot satisfy the order, Systems Agent 360 determines another preferred local facility. This loop continues until all participating facilities in Facilities Database 372 are evaluated or it is determined that there are no participating facilities that would be acceptable. "Acceptable" is used herein to mean a facility that is convenient to the customer's current or projected location or that would be able to satisfy the order within the customer's needed time frame. If a local facility is capable of filling the order, the Local Scheduler 376 obtains a cost estimate for Systems Agent 360 (Step 670). System Agent 360 then transmits the local facility location information and order cost to CSA 355.



CSA 355 notifies Customer 100 of the local facility's location and order cost via connection 108 or indirectly via PAS 210 (Step 675). If Customer 100 (or PAS 210) rejects the arrangements offered by CSA 355, the process is terminated and the order is canceled (Step 680).



If Customer 100 (or PAS 210 on behalf of Customer 100) confirms the order with CSA 355, CSA 355 places the order by notifying System Agent 360 to send the order to Local Scheduler 376 (Step 684). Local Scheduler 376 then contacts the local facility and instructs it to prepare the order (Step 688).



CSA 355 also may initiate payment procedures if the customer opts to pay by an electronic transfer method. For example, if the customer elects to pay by credit or debit card, CSA 355 instructs PAA 220 via Network Agent 225 to charge the customer for the order (Step 682). PAA 220 contacts Financial Agent 235 and charges the order amount to the appropriate customer account on Financial System 158 (Step 286). If the customer elects to pay by smart card, the CSA 355 advises the PAA 220 to swipe smart card at customer location upon fulfillment.



The customer may terminate the connection with SPAS 365. In this case, the customer's ETA will be fixed. In an alternative embodiment, the customer may opt to maintain a connection with SPAS 365 in which case PAA 220 may continue to transmit customer location information to SPAS 365. This customer location information may be used to update periodically the customer's ETA (Step 690).



E. Conclusion



It will be apparent to those skilled in the art that various modifications and variations can be made in the system and processes of the present invention without departing from the spirit or scope of the invention. Besides being a fast food restaurant, the service provider may be, for example, any merchant or service provider who can accept orders and satisfy the order upon the customer's arrival at a particular location.



The present invention covers the modifications and variations of this invention provided they come within the scope of the appended claims and their equivalents. In this context, equivalents means each and every implementation for carrying out the functions recited in the claims, even those not explicitly described herein.

PatentNumber=6037937,BACKGROUND OF THE INVENTION



The present invention relates generally to graphical user interfaces (GUI), and more particularly to a navigation tool for graphical user interfaces.



Until relatively recently, software-based documents have been primarily viewed and manipulated on desktop or laptop computers with relatively large displays, typically 640-480 pixels or larger. These displays are often large enough to display a full page of standard size page or at least a significant portion of the page. Hence, on-screen graphical menus and controls displayed in window of an application did not greatly reduce the display area for the underlying document. Computers also have peripheral devices such as a keyboard or a mouse to control the display of content information. Thus, viewing and navigating around a single-page or multi-page document have not posed much difficulty.



Due to increasing focus on compactness of electronic devices, however, the displays especially in portable electronic devices are becoming smaller and smaller. Popular electronic devices with a smaller display area include electronic organizers, PDA's (personal digital assistants), and graphical display-based telephones. Also available today are communicators that facilitate various types of communication such as voice, faxes, SMS (Short Messaging Services) messages, e-mail, and Internet-related applications. These products can likewise only contain a small display area.



To enable users to navigate around a full page of content information, these devices typically provide hard-keys for arrows as shown in FIG. 1. The hard-keys, however, not only increase the size but also add to the cost of the devices. Also, hard-keys generally provide limited options for direction of movement, e.g., vertical or horizontal. They generally do not provide the freedom to move in any direction.



Some displays of these devices also require a separate stylus having peripheral technology that requires transmission of electromagnetic pulses or light to the display. These devices often require additional controllers such as buttons on the body or the tip of the stylus for activation. Furthermore, these styli require a power source, either through wire or battery, and their compatibility is generally limited to a specific device.



As shown in FIG. 2, other devices substitute hard-keys with graphical on-screen arrows or scroll bars that are typically used in full-size computer displays. The on-screen scroll bars, however, occupy valuable screen real estate and compound the limitations of small displays. Similar to the hard-keys, the on-screen arrows also generally restrict the navigational movement to horizontal or vertical direction.



In other forms of on-screen GUIs, e.g., pop-up menus, also take up valuable screen space, further reducing the available display area for content information. Additionally, on-screen pop-up menus typically provide available functions in multiple layers, thus requiring a user to move deeply into the hierarchy before reaching the desired function. This is time consuming and renders the GUI cumbersome and ineffective.



Therefore, it is desirable to provide navigation tools that allow small-size devices while maximizing the use of available screen real estate.



It is also desirable to provide tools to navigate within a document at any direction at varying speeds.



It is further desirable to provide navigation tools that can be activated without requiring specific electronic devices.



In addition, it is further desirable to provide an improved GUI that simplifies GUI by recognizing various characteristics of the touch input.



SUMMARY OF THE INVENTION



Systems and methods consistent with the present invention provide graphical control tools for efficient navigation in display devices.



Specifically, a method consistent with this invention of controlling display of content information in a physical viewing area comprises several steps. Initially, the system displays the content information in the physical viewing area. The system also displays a representation of a control tool over the display of content information. Thereafter, the system receives a user input selecting the control tool, and controls the display of content information according to the user input.



A system consistent for this invention for controlling display of content information in a physical viewing area includes displaying means, receiving means, and controlling means. The displaying means displays the content information in the physical viewing area, and displays a representation of a control tool over the display of content information. The receiving means receives a user input selecting the control tool. Thereafter, the controlling means controls the display of the content information according to the user input.



BRIEF DESCRIPTION OF THE DRAWINGS



The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate the invention and together with the description, serve to explain the principles of the invention.



In the drawings,



FIG. 1 shows conventional hard-key arrows for navigation control;



FIG. 2 shows conventional on-screen graphical navigation tool;



FIGS. 3A-3B are diagrams of an exemplary mobile telephone consistent with the principles of the present invention;



FIG. 4 is a block diagram showing the elements of the mobile telephone of FIG. 3A;



FIG. 5 is a block diagram showing the components of the memory of FIG. 4;



FIG. 6 is a block diagram of touch screen functionalities;



FIGS. 7A-7B show an exemplary inactive and active graphical navigation tool, respectively;



FIG. 8 is a sample screen showing an active navigation tool;



FIGS. 9A-9C show exemplary features of the navigation tool;



FIGS. 10A-10C are sample screens showing the navigation tool performing various navigation functions;



FIGS. 11A-11B show exemplary features of the navigation tool relating to speed of navigation;



FIG. 12 is a diagram illustrating a touch point distribution;



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area; and



FIGS. 14A and 14B are graphs showing the touch characteristics of a pen and a finger, respectively.



DESCRIPTION OF THE PREFERRED EMBODIMENT



Reference will now be made in detail to the present preferred embodiment of the invention, an example of which is illustrated in the accompanying drawings. Where appropriate, the same reference numerals refer to the same or similar elements. The appended claims define the scope of the invention; the following description does not limit that scope.



The graphical navigation tool of the present invention may be implemented in a wide range of electronic devices mentioned above such as electronic organizers, PDA's, and graphical display-based telephones. Although the need to maximize the use of screen real estate is most critical in portable electronic devices with small displays, the present invention can also be implemented in full-size computers or electronic devices. For purposes of illustration, however, the present invention will be explained in detail in a mobile telephone environment.



Specifically, FIG. 3A shows a mobile telephone 310 and FIG. 3B shows an exemplary wireline telephone preferably having the graphical navigation tool consistent with the present invention. Mobile telephone 310 includes main housing 210, antenna 320, keypad 330, and display 340. FIG. 4 shows the hardware elements in mobile telephone 310 including antenna 410, communications module 420, feature processor 430, memory 440, sliding keypad 450, analog controller 460, display module 470, battery pack 480, and switching power supply 490.



Antenna 410 transmits and receives radio frequency information for mobile telephone 310. Antenna 410 preferably comprises a planar inverted F antenna (PIFA)-type or a short stub (2 to 4 cm) custom helix antenna. Antenna 410 communicates over a GSM (Global System for Mobile Communications) switching fabric using a conventional voice B-channel, data B-channel, or GSM signaling channel connection.



Communications module 420 connects to antenna 410 and provides the GSM radio, baseband, and audio functionality for mobile telephone 310. Communications module 420 includes GSM radio 421, VEGA 423, BOCK 425, and audio transducers 427.



GSM radio 421 converts the radio frequency information to/from the antenna into analog baseband information for presentation to VEGA 423. VEGA 423 is preferably a Texas Instruments VEGA device, containing analog-to-digital (A/D)/digital-to-analog (D/A) conversion units 424. VEGA 423 converts the analog baseband information from GSM radio 421 to digital information for presentation to BOCK 425.



BOCK 425 is preferably a Texas Instruments BOCK device containing a conventional ARM microprocessor and a conventional LEAD DSP device. BOCK 425 performs GSM baseband processing for generating digital audio signals and supporting GSM protocols. BOCK 425 supplies the digital audio signals to VEGA 423 for digital-to-analog conversion. VEGA 423 applies the analog audio signals to audio transducers 427. Audio transducers 427 include speaker 428 and microphone 429 to facilitate audio communication by the user.



Feature processor 430 provides GUI features and a Java Virtual Machine (JVM). Feature processor 430 communicates with BOCK 425 using high level messaging over an asynchronous (UART) data link. Feature processor 430 contains additional system circuitry, such as a liquid crystal display (LCD) controller, timers, UART and bus interfaces, and real time clock and system clock generators (not shown).



Memory 440 stores data and program code used by feature processor 430. Memory 440 includes static RAM 442 and flash ROM 444. Static RAM 442 is a volatile memory that stores data and other information used by feature processor 430. Flash ROM 444, on the other hand, is a non-volatile memory that stores the program code executed by feature processor 430.



Sliding keypad 450 enables the user to dial a telephone number, access remote databases, and manipulate the GUI features. Sliding keypad 450 preferably includes a mylar resistive key matrix that generates analog resistive voltage in response to actions by the user. Sliding keypad 450 preferably connects to main housing 210 (FIG. 3A) of mobile telephone 310 through two mechanical "push pin"-type contacts (FIG. 4).



Analog controller 460 is preferably a Phillips UCB1100 device that acts as an interface between feature processor 430 and sliding keypad 450. Analog controller 460 converts the analog resistive voltage from sliding keypad 450 to digital signals for presentation to feature processor 430.



Display module 470 preferably includes a 160.times.320 pixel LCD 472 with an analog touch screen panel 474 and an electroluminescent backlight. LCD 472 operates in conjunction with feature processor 430 to display the GUI features. Analog controller 460 scans touch screen overlay 474 while feature processor 430 refreshes LCD 472.



Battery pack 480 is preferably a single lithium-ion battery with active protection circuitry. Switching power supply 490 ensures highly efficient use of the lithium-ion battery power by converting the voltage of the lithium-ion battery into stable voltages used by the other hardware elements of mobile telephone 310.



FIG. 5 is a block diagram illustrating the components of memory 440. Static RAM 442 stores data and other information used by feature processor 430. Flash ROM 444 contains various programs including a program 510, a touch screen program 520, a navigation program 530, and a drawing program 540. Program 520, preferably written in languages such as Java, C, or C++ for Macintosh, is a main program overseeing the operation of mobile telephone 310.



Touch screen program 520 facilitates processing of touch input on touch screen panel 474 using a typical touch input algorithm. Navigation program 530 handles navigation of the content information display. Drawing program 540 is a graphical drawing package. Programs 520, 530, and 540 may be one of any commercially available packages or a user-defined feature program or macro.



The present invention provides various features through tactile GUI. Initially, LCD 472 displays various GUI features. Referring to FIG. 6, a user touches touch screen panel 474 to provide user input, for example, to navigate around a document or invoke a desired function. Analog controller 460 scans touch screen panel 474 and reads the corresponding analog voltage of touch screen panel 474. Analog controller 460 then converts the analog values into corresponding digital values representing the Cartesian coordinates, which are transmitted to feature processor 430 for processing. The resolution of the touch input depends on the ability of analog controller 460 to discern among multiple levels of analog values, generally defined in bits.



FIGS. 7A-7B show an exemplary graphical navigation tool preferably used to navigate around documents that are too large to view within a single screen of a physical display (hereinafter referred as "viewing area"). The navigation tool may be used to view any kind of document including faxes, Web pages, or e-mail. In one embodiment consistent with the present invention, an inactive navigation tool is displayed and accessible to the user at all times (FIG. 7A). The user may activate the navigation tool by touching and holding the center of the navigation tool for a predetermined time period, for example, one to two seconds (FIG. 7B). An activated navigation tool is preferably transparent to avoid hindering the display of content information in the viewing area as shown in FIG. 8. Alternatively, the navigation star may change colors or other features of its appearance to indicate its active status. A solid line image, for example, may be used in greyscale displays that do not support transparency.



The present invention may be designed such that feature processor 430 ignores any touch input on the navigation tool unless the navigation tool has been activated. Instead, the touch input may be interpreted as input to access control buttons in the underlying document, write on the underlying document, or invoke other functions related to the underlying document. This will prevent against unintentional navigation in the viewing window in case the user inadvertently touches touch screen panel 474. In an alternative embodiment, the present invention may accept stylus input to access the underlying document while a finger or non-electromagnetic touch on any part of the navigation tool invokes the navigation function.



Referring to FIGS. 9A-9C, once the navigation tool is activated, the user may navigate through the document by selecting the graphical arrows, e.g., up, right, left, and down arrows (FIG. 9A), or graphical page icons, e.g., previous or next page (FIG. 9B). One skilled in the art may vary the type and number of graphical tools significantly. For example, the navigation tool may provide graphical representations for forward, next document, back, or home functions (FIG. 9C).



FIGS. 10A-10C show exemplary screen displays while the user is touching the navigation tool. Upon touching the right arrow of the navigation tool, for example, the right arrow is highlighted and navigation program 530 moves the display to the right (FIG. 10A). Similarly, touching the down arrow moves the display down (FIG. 10B). Although the four arrows are presented to guide the users, navigation program 530 supports navigational movement at any direction. If the user touches an area of the navigation tool equidistant between the up and right arrows, for example, navigation program 530 will move the display towards the upper-right portion of the underlying document at a 45-degree angle. Touching the arrows or any area in between, moves the display in the selected direction until navigation program 530 reaches the edge of the page.



Touching the next page icon moves the viewing window to the next page of the underlying document (FIG. 10C). If a particular document does not have a page corresponding to a previous or next page icon, navigation program 530 will not display the respective previous or next page icons. This would apply to one-page documents, or when the user is at the beginning or end of a multi-page document. In one embodiment consistent with the present invention, a momentary touch of the next page icon causes navigation program 530 to jump to the next page while a continuous touch on the next page icon causes navigation program 530 to continue scrolling through succeeding pages of the underlying document. The previous page icon may embody similar characteristics.



The user may also control the speed of the navigation. As shown in FIG. 11A, the speed of the navigation accelerates as the user touch moves from the center of the circle toward the circumference of the circle, i.e., tip of the arrow. Hence, the viewing window moves slowly when the user touches the blunt end of the arrow located at the center of the circle while the speed accelerates as the user moves the finger towards the tip of the arrow. The speed of navigation, therefore, is determined by the distance of the touch relative to the center of the circle. Likewise, similar principles apply to previous or next page/document icons where a touch closer to the outer edge of the previous or next page/document icons accelerates navigation through the document as shown in FIG. 11B.



Although the exemplary transparent tool discussed above is for navigation, transparent control tools may be implemented for a variety of functions. A transparent tool may, for example, be used for a Web browser application where the controls may be used for appropriate functions such as moving forwards or backwards through different Web pages or returning to home page. One skilled in the art may easily vary the design or the functionality of the graphical navigation tools described above without departing from the scope of the present invention.



In an exemplary embodiment of a navigation tool described above, a finger touch invokes navigational functions based on the feature selected and the location of the user touch. Alternatively, other objects making contact with touch screen panel 474 may invoke other tools or functions. A pointy stylus touch, for example, may invoke a menu with cardinal points representing multiple line widths, colors, or patterns.



In another embodiment consistent with the present invention, tools or application programs may be stored in flash ROM 444 to provide related interfaces to the user. The use of a finger may, for example, invoke tools or dialogues that are finger-touchable and large whereas the use of a sharp stylus may invoke a modified GUI with smaller touch targets. In a yet another embodiment, in a document viewing application normally navigable by a finger touch, use of a sharp stylus may automatically invoke a document annotation application for marking up the underlying document.



As described above, the touch-responsive GUI of the present invention are facilitated though various components including touch screen panel 474, analog controller 460, and feature processor 430. Specifically, analog controller 460 scans touch screen panel 474 to read the corresponding analog voltage of touch screen panel 474 activated by a user touch. Analog controller 460 then converts the analog values into a digital value representing the Cartesian coordinates, which is transmitted to feature processor 430 for processing according to the functionalities of the present invention.



When a user touches touch screen panel 474, program 510 initiates touch screen program 520 to determine the pointer size of the object making contact with touch screen panel 474 based on a touch point distribution or pointer size of the touch input. As shown in FIG. 12, touch screen program 520 can, for example, determine whether the pointer size of the object is a finger or a sharp object.



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area. Touch point program 520 first determines the individual points of contact made by the object (step 1310). It computes a centroid, or other average point, of the determined points of contact (step 1320). Touch program 520 then computes a standard deviation of the centroid as well as the variance (step 1330), and determines the pointer size based on the centroid and the standard deviation (step 1340). These computations are preferably performed on a real-time basis to provide immediate system response to the touch input. In order to achieve optimum results and accuracy, analog touch controller 460 preferably generates 150 points per second or more. Touch program 520 may also use the amount of pressure imposed on touch screen panel 474 as a function of time to determine the size of object. As shown in FIG. 14A, for example, if the amount of pressure increases or decreases sharply at a particular instant in time, touch point program 520 may determine that the touch corresponds to a pen. A finger touch, on the other hand, results in a gradual increase and decrease in pressure as illustrated by a smoother curve in FIG. 14B.



Program 510 can also be programmed to correlate certain pointer size to certain objects and invoke corresponding functions or tools. Such GUI provides a richer, yet simplified interaction between the user and mobile telephone 310. If program 510 determines that the pointer size of the object corresponds to the size of a finger, program 510 may initiate a navigation tool. If the pointer size corresponds to the size of several fingers, program 510 may invoke a drag function of the navigation tool. On the other hand, if program 510 determines that the pointer size of the object corresponds to size of a sharp point or pen, program 510 may initiate a drawing tool supported by drawing program 540. Similarly, if program 510 determines that the pointer size of the object corresponds to size of a pencil eraser, program 510 may initiate an erase function of the drawing tool. One skilled in the art may easily vary the functions or tools initiated by program 510. Additionally, the functions or tools may be commercial software packages, predetermined functions, or user-defined macros.



In addition to using the pointer size to determine the desired GUI, program 510 can also incorporate other characteristics of the user touch, e.g., gestures or movements, to simplify GUI and maximize screen real estate. A gesture recognizing interface extends the ability of the present invention to distinguish between different sized pointers to track gestures and movement of user input based on vector direction and magnitude, all in the context of active user application. This type of contextual gesture interface can infer by context, the implement, and the gesture chosen by the user what functions the user wishes to invoke. Accordingly, all these functions are available without menus or scroll bars and do not require additional screen areas to display the functions.



Program 510 recognizes other characteristics of the touch input including the context of the input, namely the task or sub-task applications running when the GUI is invoked. If a user is in a document navigation application, for example, program 510 interprets a quick drag to the right as a next page function. If the underlying task is an editing application, program 510 may interpret the same gesture as a highlight function and highlight a portion of the document touched by the user. Similarly, in graphics application, a quick drag to the right may invoke a drawing tool to draw from the starting point to the ending point of the touch points. In a document viewing application, the same touch may invoke a navigation tool to move the view of the document in the direction of the finger drag.



All of the above functions and features described above focuses on providing intuitive GUIs and minimize the need for users to memorize complicated, hierarchical menus or procedures. Additionally, the present invention maximize available screen real estate while providing a wide array of GUI and tools.



It will be apparent to those skilled in the art that various modifications and variations can be made in the system of the present invention and in construction of this system without departing from the scope or spirit of the invention. Other embodiments of the invention will be apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. The specification and examples should be considered as exemplary only, with the true scope and spirit of the invention indicated by the following claims.

PatentNumber=6088225,BACKGROUND TO THE INVENTION



1. Field of the Invention



The invention relates to cabinets for outdoor use for enclosing racks of electronics equipment, and to methods of manufacturing such cabinets.



2. Background Art



It is known to provide outdoor cabinets for communications equipment such as racks of cards holding electronic or optical components. Such cabinets are provided at outdoor locations where there is no suitable existing building to hold the equipment and protect it from adverse environmental conditions, and where the size of the equipment is too small to justify a dedicated building. Examples of such cabinets include roadside cabinets for housing electronics for controlling traffic signals, or cabinets for cellular radio network base station electronics.



Some of the principal considerations in the design of such cabinets include: level of environmental protection, corrosion resistance, strength to cost ratio, thermal management, public safety, aesthetic considerations, vulnerability to vandalism, ease of installation, ease of access to equipment, and level of electromagnetic shielding. The issue of thermal management will be discussed in more detail.



The main thermal effects are as follows. The equipment inside the enclosure generates heat which may need to be extracted. The enclosure may be subject to external sources of heat, such as solar radiation.



A common constraint in the design is that the equipment should not have ambient air passing over electronic components, to avoid deterioration from contaminants and corrosives in the ambient air. Thus the equipment may be sealed within the enclosure, and heat from components within the sealed part may be conducted to the outside of the sealed part, and the sealed part cooled by fans circulating ambient air. A heat exchanger may be used if further cooling is required. In extreme cases, air conditioning may be appropriate.



It is known to provide a cabinet with a single metal skin for the sides. This can provide sufficient strength and weatherproofing, to resist wind and rain. It offers little resistance to solar radiation, even if painted a light colour or silvered to reduce heat absorption.



It is also known from U.S. Pat. No. 4,535,386 to provide a sealed enclosure for electronic components such as silicon controlled rectifiers, using a single metal skin, but enhancing the natural convection past heat sinks mounted to protrude through the skin, by providing an outer chimney surrounding the heat sinks to duct cool air past the sinks and improve dissipation. However this disclosure is not concerned with a cabinet for outdoor use.



The provision of a double skin for the sides of the enclosure is also known, which assists in cooling the equipment by the "cold wall cooling" principle. A chimney effect is produced in the cavity between the skins. An inlet at the bottom of the cavity allows air in, to flow up the cavity and out of an outlet at the top of the cavity. Heat from the internal skin is thus extracted from the cabinet by convection, and thus the equipment inside the cabinet can be kept cool. Furthermore, heat from solar radiation on the external skin can also be extracted, and prevented from reaching the equipment inside.



Where the internal equipment is producing more heat than can be handled by natural convection in the double skin, it is known to provide fans at the top of the cavity to draw air through the cavity and thus increase the rate of heat extraction. If this is still insufficient, an air to air heat exchanger could be provided, or an air conditioning unit might be considered to take the air within the enclosure and return it to the enclosure at a lower temperature.



It is appreciated that such active cooling measures may reduce the reliability of the cabinet, or increase it's maintenance costs, and will certainly increase it's production cost. Accordingly thermal and fan management systems are used to minimise the amount of time the active cooling measures are used, to maximise the life expectancy of fans and associated filters.



SUMMARY OF THE INVENTION



It is an object of the invention to provide improved methods and apparatus.



According to a first aspect of the invention there is provided a cabinet for outdoor use for enclosing a rack of electronics equipment, the cabinet comprising:



a double skin protective outer casing for enclosing the equipment, the casing comprising:



a lower air intake into a cavity between the skins of the double skin of the casing and an upper air output from the cavity to the outside, defining a path for unforced cooling air to flow, to extract heat from the equipment by convection; and



the inner of the skins being formed in part at least by a heat sink of the rack.



One of the advantages arising from this is that the thermal path from the



cards in the rack to the cold wall is improved. This means the temperature difference between the inner skin and the air in the cavity can be increased for a given card temperature, so more heat can be extracted. This unites the thermal management of the rack and that of the enclosure in a way which has not been conceived before, and can achieve better natural convection cooling than previous attempts which have focused on improving the thermal performance of individual parts of the system.



Preferably, the heat sink forms at least part of a back wall of the rack, against which cards are inserted. This carries the advantage that the heat sink can contact all the cards in the rack, thus components generating heat can be mounted on any of the cards. Furthermore, the heat sink can be oriented to be vertical for good convection, while the open front of the rack can face the doors of the cabinet for easy access to slide cards in or out of the rack.



Preferably, the heat sink shares the same wall of the rack as a backplane comprising connectors for connecting signals to the cards. An advantage of this is that it enables the above mentioned thermal advantages to be achieved with few alterations to prior art racks oriented for horizontal insertion of cards, to couple with connectors on a backplane at the back of the rack. The backplane is thus oriented vertically, which is the preferred orientation for the heat sink, for good convection flow.



Preferably, the rack is arranged such that substantially the entire back wall forms the heat sink, the rack comprising:



guides for guiding cards inserted into the rack along an insertion axis, normal to the back wall and enabling subsequent movement of the cards after insertion, along a connection axis, perpendicular to the insertion axis; and



a backplane, comprising connectors for coupling to corresponding connectors on the cards, oriented perpendicular to the back wall and located to enable the coupling to take place by the subsequent movement of the cards along the connection axis. An advantage arising is that a better thermal path can be created if the entire back wall is used for the heat sink. Furthermore, a conventional backplane can then be used, without modification to accommodate heat sinks. Another advantage arising is that the heat sink can be oriented vertically for good convection flow, and the insertion axis can be horizontal, to enable easy access from a door in the wall of the cabinet for example.



Preferably, the rack further comprises a mechanism for urging cards individually along the connection axis after insertion.



Preferably, the back wall further comprises:



a thermally conductive contact surface for abutting a corresponding surface on one of the cards, extending along substantially the entire leading edge of each card, for making thermally conductive contact with a card inserted in the rack. An advantage of this is that it helps improve the thermal path from the card to the cavity, and thus enables more heat to be extracted.



Preferably, the heat sink comprises protrusions extending into the cavity. This enables the surface area of the inner skin in the cavity to be enlarged, to increase the amount of heat which can be transferred to the air in the cavity.



Preferably, the heat sink and the contact surface of the back wall of the rack are formed integrally as one piece. Among the advantages of this are that the thermal path can be improved, and construction made easier if there are fewer joints.



Preferably, the rack is removably attached to the rest of the enclosure, the heat sink fitting in an aperture in the inner skin. This can facilitate maintenance.



According to a second aspect of the invention there is provided a cabinet for outdoor use for enclosing electronics equipment, the cabinet comprising:



a double skin protective outer casing for enclosing the equipment, the casing comprising:



a lower air intake into a cavity between the skins of the double skin of the casing and an upper air output from the cavity to the outside, defining a path for unforced cooling air to flow, to extract heat from the equipment by convection; and



the inner of the skins comprising a fin extending into the cavity for promoting thermal transfer from the inner skin to the air in the cavity. An advantage arising is that the amount of heat which can be transferred to the air in the cavity can be increased because the surface area of the inner skin in the cavity is greater.



Preferably, the casing comprises a thermal insulation layer on the outer of the skins for insulating the equipment from solar radiation According to a third aspect of the invention there is provided a cabinet for outdoor use for enclosing a rack of electronics equipment, the cabinet comprising:



a double skin protective outer casing for enclosing the equipment, the casing comprising:



a thermal insulation layer for insulating the equipment from external conditions; and



a lower air intake into a cavity between the skins of the double skin of the casing and an upper air output from the cavity to the outside, defining a path for unforced cooling air to flow, to extract heat from the equipment by convection.



An advantage arising from the use of a layer of thermal insulation is that the deleterious effect of external heat sources such as solar radiation heating the cavity, can be reduced. This deleterious effect arises because the amount of heat extracted by unforced convection depends heavily on the temperature difference between the air in the cavity and the temperature of the inner of the skins, where the equipment heats this inner skin. A lower temperature of air flowing through the cavity can increase this temperature difference. Thus more heat can be extracted.



Preferably, a portion of the inner of the the skins of the double skin, comprises a heat sink of the rack of electronics equipment, and is provided with protrusions extending into the cavity. An advantage arising from this is that the thermal path from the rack to the cavity is improved and the protrusions increase the surface area in the cavity, and thus enable more heat to be transferred to the air in the cavity.



Preferably, the heat sink comprises a portion of a backplane of the rack. An advantage arising from this is that the thermal path from the electronics in the rack to the cavity can be improved, thus more heat can be transferred to the air in the cavity.



Preferably, the thermal insulation is provided on the inside of the outer skin of the double skin. An advantage of this is that the thermal insulation need not be weatherproof or vandal proof, or meet other requirements of the outer surface of the double skin.



According to another aspect of the invention there is provided a method of manufacturing a cabinet as set out above.



Any of the preferred features may be combined, and combined with any aspect of the invention, as would be apparent to a person skilled in the art.



To show, by way of example, how to put the invention into practice, embodiments will now be described in more detail, with reference to the accompanying drawings.



BRIEF DESCRIPTION OF DRAWINGS



FIG. 1 shows a side on cross section view of a known double skin cabinet;



FIG. 2 shows a cross sectional back view of the known double skin cabinet of FIG. 1;



FIG. 3 shows a double skin cabinet in which the inner of the skins is formed in part by a heat sink of the rack, according to an embodiment of the invention;



FIG. 4 shows another arrangement cabinet in which the inner of the skins is formed in part by a heat sink of the rack, where the heat sink and back wall of the rack are integral;



FIG. 5 shows the arrangement of FIG. 4 with fins;



FIG. 6 shows a cabinet in which the back wall of the rack is used for thermal contacts and a backplane for signal connectors is located above the cards;



FIG. 7 shows a view in cross section A--A of FIG. 6;



FIG. 8 shows a more detail of a mechanism for inserting cards into the rack of FIG. 6;



FIG. 9 shows a cabinet in which the back wall of the rack is shared by thermal contacts and signal connectors;



FIG. 10 shows a view in cross section A--A of FIG. 9;



FIG. 11 shows an insulated double skin cabinet according to an embodiment of the invention; and



FIG. 12 shows an insulated double skin cabinet having fins in the cavity according to an embodiment of the invention.



DETAILED DESCRIPTION



FIGS. 1, 2 Known Double Skin Cabinet



FIG. 1 shows a side on cross-section view of a known double-skinned cabinet. The cabinet may be rectangular in plan, with four walls enclosing a chamber 10 for housing the electronics equipment. The walls of the cabinet stand on a plinth 20, and a roof 30 is provided, which may be sloping, to shed water, and provide greater strength. The space within the roof may provide some insulation from solar radiation. A cavity 40 is provided between the skins of the double skin of the casing of the cabinet. A lower air intake 50, and an upper air output 60 are shown, to allow air flow in the direction of the arrows. An equipment rack 70 is provided within the chamber. This may be a stand alone rack or it may be fixed to structural elements such as bracing bars (not shown) in the chamber.



As shown, the cavity may provide convection cooling for the chamber, either unforced or forced. To provide forced air cooling, fans could be positioned near the upper air output 60, to draw cool external air through the cavity 40.



FIG. 2 shows a cross-sectional back view of the known double-skinned cabinet of FIG. 1. Reference numerals used in FIG. 1 show corresponding features in FIG. 2. The cabinet is illustrated without the rack 70. Hinged doors 80, 85 are shown to give access to the front of the chamber.



FIG. 3, Double-skinned Cabinet with Inner Skin Formed by Heat Sink of the Rack



FIG. 3 shows a double-skinned cabinet according to a first embodiment of the invention. In this embodiment, a pair of card racks 100, containing cards 90, are shown within the chamber 10. They are mounted directly on the inner skin of the double skin casing such that a part at least of the inner skin forms a heat sink of the rack. There needs to be an effective thermal path from the electronics on the card in the rack, to the inner skin.



This may be achieved for example by making the rack of a thermally conductive material such as a metal casting. Suitable materials are well known. The skins of the casing could be constructed of a material such as steel to which a galvanized finish is applied to minimize corrosion. The material of the inner skin at least should be thermally conductive, to provide a good thermal path.



Preferably the rack is fixed to the inner skin in such a way that there is a maximum area of surface contact, to provide a good thermal path. For ease of maintenance, the rack may be bolted to the inner skin. A thermally conductive grease can be used to improve the thermal conduction across the joint. The fewer joints there are, the better the thermal path. Accordingly, the rack as illustrated may be formed as a one-piece casting. It would be possible to have it made in several parts if the joints are made to be thermally conductive.



It is conceivable that some heat generating circuit elements may be fixed directly to the rack, insulated where appropriate, according to known techniques. Other heat generating elements may be located on the circuit card 90, and a thermal path provided to the edge of the card, using metal strips, or the metallization printed on the circuit board.



As illustrated in FIG. 3, the double skin is provided on only one side of the cabinet, though as needed, other sides could also be provided with the double skin. Although no fans are shown, forced air could be provided in the cavity if required, and could be thermostatically controlled, to operate only when needed. Other fans could be provided within the chamber 10, to provide forced air cooling of particular components, for example.



The inner skin could provide structural support for mounting the racks, though it may be preferable to provide vertical mounting bars (not shown) to provide structural support to the racks, so that the inner skin can be made of thinner material. A typical mounting for the racks may be designed to support up to 100 kg per rack. The cabinet may be large enough to retain racks stacked on top of each other to extend over six feet in height, or may be sized to accommodate a single rack.



FIGS. 4, 5 Integral Heat Sink and Back Wall of Rack



FIG. 4 shows in schematic form an arrangement according to another embodiment of the invention in which instead of the rack being attached to the inner skin, the back wall of the rack 100 forms part of the inner skin. This requires that the inner skin have an aperture corresponding in size and shape to the back wall of the rack. It enables the thermal path to be improved, since there is no longer a joint in the path at the contact surface between the inner skin and the back wall of the rack. However, some sort of seal may need to be provided, between the back wall and the surrounding parts of the inner skin, which may make manufacturing more difficult and expensive. The type of seal required would depend on the weather proofing and EMC specifications for the cabinet.



FIG. 5 shows a similar arrangement to that of FIG. 4, with the addition of a protrusion 110 in the form of a fin extending into the cavity, and oriented vertically. This serves to increase the surface area of the heat sink exposed in the cavity, and therefore increase the amount of heat which can be extracted by the air flowing in the cavity. Conceivably, the fins could be oriented diagonally if were desired to achieve an air flow away from the vertical, perhaps to enable the heat from a lower rack to avoid passing over the fins of an upper rack mounted immediately above the lower rack.



FIGS. 6,7,8 Back Wall of the Rack is Used for Thermal Contact, and Backplane is Located Away from the Back Wall



FIG. 6 shows a cabinet according another embodiment of the invention, again in side view, and in cross-section, to show the interior of the chamber. The entire back wall of the rack is used for the thermal contact between the card and the rack. Interconnections between cards are enabled by a backplane with signal connectors, which is shown located below the cards in the rack.



The rack has a back wall 140 which forms a thermal contact, and a guide for substantially the entire length of one side of a circuit card 170. The rack also comprises a backplane 150 shown below the cards 170, though it could conceivably be mounted above the cards. Connectors 160 are mounted on the backplane, for coupling to corresponding connectors on the card 170. For the sake of clarity, structural members of the rack, for supporting the backplane, are not shown. Likewise, parts of the rack for guiding the tops of the card are not shown. Fins 130 in the cavity may be formed as part of the inner skin of the casing. Alternatively, the back wall 140 of the rack may be formed integrally with the fins 130, to form part of the inner skin, fitting in an aperture in the rest of the inner skin, in a manner corresponding to that shown in FIG. 4.



FIG. 7 shows a view in cross-section at A--A of FIG. 6. This is a plan view of the cabinet. It is illustrated with just one card 170 in the rack. Many fins 130 are shown. Many thermal contacts forming a back wall 140 are shown. The backplane 150 supports many connectors 160. Conductors 190 are illustrated at one end of the backplane, where such conductors are passed in or out of the rack.



The cabinet is shown with two doors 230 at the front. Double skinned sides are provided on all four sides of the cabinet.



To provide an integral heat sink and back wall of the rack, since many



channels are required on both sides, it might be appropriate to form this as a one-piece aluminum extrusion. Other part of the rack could be formed separately.



To create a good thermal path from components on the circuit board 170, the heat generating components could be located close to the edge where thermal contact is made with the heat sink, and a large area of metallization could be provided between the components and the edge of the circuit board.



By providing a thermal contact along substantially the entire length of this edge of the card, the thermal path may be maximized. Preferably, the rack is arranged so that this edge is oriented vertically, so that the heat sink can conveniently be oriented vertically, to maximize natural convection.



FIG. 8 shows more details of a mechanism for inserting cards into the rack illustrated in FIGS. 6 and 7. Much of this mechanism is not shown in FIGS. 6 and 7 for the sake of clarity. The principal functions of the mechanism are as follows: it should allow cards to be inserted horizontally into the rack by hand; it should enable a user to move the inserted card vertically with sufficient force to insert the card into the connector, (the force should be directed evenly over the length of the connector, to ensure complete insertion over the entire length of the connector); it should enable the user to extract the card vertically from the connector; and extract the card horizontally from the rack. All this should preferably be achieved by a user who has access only to the front of the rack, (so that racks can be stacked and cards accessed while the racks are stacked).



An example of a preferred mechanism to achieve this is shown in FIG. 8 in a perspective view, in schematic form, to show the mechanical principles used. Actual dimensions are not necessarily illustrated to scale. The card 170, is fitted with a downward facing channel 183, extending along the top of one side of the card. A movable plate 193 is disposed alongside the card in the rack. The plate has an upwardly facing channel 195, at the top of the side facing the card. This channel can engage the channel on the card, to enable upward movement of the plate to cause the card to be extracted upwards out of its connector.



To enable the card to be forced downwards into the connector, a lip 181 is provided on the plate extending outwards over the channel on the card, and extending along the top of the plate. It is for engaging this channel, or the top edge of the card, when the plate is moved downwards. The plate can be moved downwards by means of a lever 197 pivoting at 187 on a pivot support 185 attached to the rack. An arrangement of a pin 191 sliding in a slot 189 enables the rotary movement of the lever to be converted into vertical movement of the plate.



If the lever rotates in a plane parallel to the card, it can be arranged so that an arm of the lever can be moved by a user at the front of the rack. An advantage of using a pair of cooperating channels, is that they can support the card as it is being inserted, and they provide a guide to assist sliding the card into the rack horizontally.



To install the circuit board the lever is pulled fully forwards, lifting the guide plate away from the connector. The guide channel on the circuit board is located into the corresponding channel on the guide plate and pushed fully home. The lever is then returned and locked in the vertical position, this action pushes the guide plate and hence the circuit board down, locating the board into the connector block.



Among the advantages of this arrangement are that the plate increases the thermal dissipation from the circuit board, reduces EMC interference between adjacent boards, and if made of metal, adds a fire barrier to the cabinet.



FIGS. 9,10--Back Wall Shared by Thermal Contacts and Backplane



FIG. 9 illustrates a further alternative embodiment of the invention, in which the back wall of the rack is shared by thermal contacts and signal connectors on a backplane. This reduces the area of thermal contact between the card and the back of the rack, since part of the back edge of the card is used for connectors. However, it enables construction to be simplified, since conventional horizontal insertion of the card can be used, obviating the need for a mechanism such as that shown in FIG. 8.



Fins 180, extending into the cavity, are connected to the back of the rack, formed by thermal contacts 210 and a backplane 200, itself comprising connectors 220. The card 240 is arranged to be inserted horizontally, using guides in the rack (not illustrated) above and below the card.



Again, the thermal contact at 210 at the back of the rack, could be formed integrally with the fins 180 forming part of the inner skin of the double-skinned casing of the cabinet.



Although as illustrated, approximately half the length of the back edge of the card 240 is devoted to thermal contact, and half to signal connectors, the proportions could be varied as appropriate. Furthermore, the connectors could be mounted on one side of the card, with thermal contact is made on the other side of the card, so that the entire length of the card could be used both for thermal contact and for connectors (not illustrated).



FIG. 10 shows a cross-section through A--A of FIG. 8. This is a plan view of the cabinet. It is shown with only one card, 240, inserted in the rack, and does not show card guides which may be provided in the rack above and below the card. This illustration is similar to that of FIG. 7, except that the connectors 220 and the backplane 200 now appear end-on, instead of face-on.



The thermal contacts 210 on the back wall of the rack form a channel for each card, receiving the back edge of the card, as it is inserted horizontally. The width of the channel for each card could be designed to be a parallel faced channel, wide enough to be a sliding fit. Thermally conductive grease could be used to ensure a good thermal path across the contact surfaces. Chamfered edges at the mouth of the channel would ease insertion.



The depth of the channels could be chosen to suit the design Deeper channels would enable a larger contact surface to be used, but might make insertion more difficult.



Conceivably, the sides of the channel for each thermal contact with the card could be spring loaded, to ensure good thermal contact, though this would increase manufacturing complexity and costs.



FIGS. 11,12--Insulated Double-skinned Cabinet



FIG. 11 is similar to FIG. 3 except that a layer of insulation 250 is illustrated. This is provided on the inside of the outer skin of the double skin part of the casing. It may also be provided on the inside of single skinned parts of the casing, as illustrated at the right hand side of FIG. 11. Such insulation is preferably provided by spraying a foam such as a polyurethane onto the metal shell. Alternatively, layers of glasswool or polystyrene foam could be prefabricated and attached to the metal skin. One disadvantage of this alternative, is that there is a greater risk of the insulation becoming separated from the shell and blocking the air flow through the cavity. The thickness of the insulation layer could be chosen to suit the amount of solar radiation expected at the site. Furthermore, such insulation could be provided only on the sides which are exposed to solar radiation when the cabinet is installed. However this may increase production costs and installation would be more involved because each site would need to be surveyed, and the cabinet insulation made specific to the orientation at each site.



Such insulation could also be provided on the inside of the roof space (not illustrated). It would also be conceivable to integrate the insulation layer and the outer skin, if a sufficiently strong insulating material were to be used, such as a thick fiberglass type material.



FIG. 12 illustrates in more detail how the insulation layer 240 is provided on the inside surface of the outer skin 235. Sufficient room is left in the cavity for the fins 110. As illustrated, the fins do not bridge the cavity, and space is left for air to flow between the insulation layer and the fins. The structure could be made considerably stronger if the fins bridged the cavity, which might enable lighter, cheaper materials to be used, though the air flow might be impeded slightly, and there could be some thermal leakage of solar generated heat into the fins, which might begin to reduce the cooling ability of the arrangement.



Other Variations



Although the embodiments described above illustrate unforced cooling, it would be conceivable to include fans to provide additional forced air cooling, preferably controlled to maximise reliability. Although the embodiments described above illustrate using a plate next to the card for vertical insertion and extraction, according to an alternative embodiment, the plate and lever arrangement might be located above the card, so that the cards can be placed closer to each other. In this case, the channel on the plate would be on the bottom of the plate. This would bring the disadvantage of requiring a reduced height of card, or a higher rack. Instead of a lever arrangement, an alternative, not illustrated, would be to have a surface facing the top of the card, sloping down towards the back of the card, and a wedge between the card and the surface, pushed in by the user to force the card downwards.



For a single rack in the cabinet, it would be conceivable to dispense with an insertion mechanism, and leave the rack open at the top for manual insertion of cards in the vertical direction. Although in some of the embodiments described, the connectors are on the bottom of the rack, they could be provided on the top, with a corresponding mechanism to insert them.



Other variations as well as those discussed above will be apparent to persons of average skill in the art, within the scope of the claims, and are not intended to be excluded.

PatentNumber=6112015,FIELD OF THE INVENTION



The invention relates to network management, and more particularly to a graphical user interface suitable for use in the management of large telecommunications networks.



BACKGROUND OF THE INVENTION



It is common to employ one of many existing network management tools to manage computer and/or telecommunications networks. These tools typically run on PC or UNIX workstations. In the telecommunications context, network management tools enable the maintenance, surveillance and administration of the multiple telecommunication devices which make up the network. Tasks performed by these network management tools through a network management interface include alarm monitoring, test and diagnosis of faults, performance monitoring and connection management.



An objective of most network management tools is to provide a centralized view of the network so as to enable the correlation of events and conditions that span network elements and subnetworks. A further objective is to facilitate the management of a network consisting of a non-homogeneous collection of telecommunication devices. Some existing network management tools provide GUI (graphical user interface) access to the users. An example of a data network management tool which provides GUI access to users is HP Open view. This tool and its associated GUI is appropriate for the management of data networks in which a set of relatively simple nodes may be complexly meshed. The nodes are simple in the sense that from the network management perspective, they can be in only one of a very small number of states. This tool and others like it are not appropriate for the management of even simple telecommunications networks which include nodes which are very complex. Telecommunications nodes are complex in the sense that from the network management perspective, they can simultaneously be in one or more of a large number of states.



There exist Bellcore and ISO (International Standards Organization) standards which include OSI (Open Systems Interconnect) standards which specify a set of generic states network objects forming part of a telecommunications network can be in. Network objects are products produced by a variety of different vendors and include nodes, links and shelf based equipment. The intent of the generic states is to allow network objects which are compliant with these standards to be maintainable remotely by non-vendor specific network management tools. These standards provide a textual definition to the states but the graphical representation of the permutations and combinations of these states is left up to network management tool developers. This opens the door to very complex and cluttered visual displays or more commonly to the superimposition of acronym subscripts and superscripts on top of the visual displays to avoid confusion. These standards are meant to be applied to most telecommunication network objects. Prior art network management GUI tools have not incorporated the full OSI and BellCore state models or have failed to do so in a manner which efficiently expresses them in a simple visual language which does not consume excessive space in the windows on a screen. The common approach is for such tools to address only a subset of the aforementioned standards, and to create new arbitrary "meta-states" that represent combinations of states.



The specific ISO standards and Bellcore requirements which are applicable are of course subject to change over time. At this time the relevant ISO standard is : ISO/IEC 10164-2, Information Technology--Open Systems Interconnection--System Management--Part 2, State Management Function (for CCITT Applications) CCITT Rec.X.731 (now ITU-T). The relevant Bellcore requirement is: Generic Requirements GR-1093-CORE, Issue Oct. 1, 1994 & Revision Dec. 1, 1995, Bellcore, Generic State Requirements for Network Elements.



SUMMARY OF THE INVENTION



It is an object of the invention to provide an improved network management GUI.



This invention is concerned with a GUI language used to perform network management of telecommunications networks.



According to a first broad aspect, the invention provides a processor implemented method for displaying information relating to a telecommunications network consisting of a plurality of network objects using a network management terminal having a display, the information consisting of a base state for at least one of the network objects, the method comprising the steps of: displaying on the display for each network object a basic icon corresponding to that network object; imparting to the display of each said at least one basic icon an attribute representative of the base state of the corresponding network object.



According to a second broad aspect, the invention provides a method for displaying OSI state and status information relating to a telecommunications network consisting of a plurality of network objects using a network management terminal having a display and processing means, the method comprising the steps of: the processing means converting the OSI state and status information into base states and supplementary states for each network object; the processing means displaying on the display for each network object a basic icon representative of that network object, the basic icon being a node icon for a node network object, a card icon for a card network object, and a link icon for a link network object; imparting to the display of at least one basic icon at least one attribute selected from a predetermined set of possible attributes; adding to the display of each basic icon zero or more modifier icons selected from a predetermined set of possible modifier icons; wherein each attribute is representative of a different predetermined base state; wherein each modifier icon is representative of a different predetermined supplementary state.



According to a third broad aspect, the invention provides a system for monitoring a telecommunications network consisting of a plurality of network objects, the system consisting of: a network management terminal having a display and processing means; means for conveying network management information from the network to the network management terminal; wherein the processing means displays on the display for each network object a basic icon representative of that network object; wherein the processing means converts the network management information into a base state for each of at least one network object; wherein the processing means imparts to each basic icon representative of said at least one network object at least one attribute selected from a predetermined set of possible attributes; wherein each attribute is representative of a different predetermined base state.



BRIEF DESCRIPTION OF THE DRAWINGS



Preferred embodiments of the invention will now be described with reference to the attached drawings in which:



FIG. 1 is a context diagram for the application of the invention;



FIGS. 2a-2d illustrate three different types of basic network element icons;



FIG. 2e illustrates a symbol set for identifying classes of network icons;



FIG. 2f illustrates several network element icons identified with symbols from the set illustrated in FIG. 2e;



FIG. 2g illustrates several link icons;



FIG. 3 illustrates a pictorial icon;



FIG. 4a is an example representation of a simple network using the symbols and icons of FIGS. 1 to 3;



FIG. 4b is an example representation of a network including container icons;



FIG. 4c is an example representation of a network including translucent container icons displayed over a map;



FIG. 4d illustrates an example of several container icons that have interlocking shapes;



FIG. 5 illustrates network icons in each of three base states;



FIG. 6 illustrates network icons in the usage state "Busy", and the Administrative states "Locked" and "Shutting Down";



FIG. 7 illustrates a node icon, a link icon, and a card icon in each of the three base states;



FIG. 8 illustrates modifier icons identifying the Procedural status;



FIG. 9 illustrates modifier icons identifying the Availability status;



FIG. 10 illustrates modifier icons identifying the Control status;



FIG. 11 illustrates modifier icons identifying the Standby status;



FIG. 12 illustrates the simultaneous display of states and statuses;



FIG. 13 illustrates the positioning of modifier icons on link icons;



FIG. 14 illustrates the positioning of modifier icons on card icons;



FIG. 15 illustrates an example of a selectable modifier icon;



FIG. 16 illustrates modifier icons identifying the Alarm status;



FIG. 17 illustrates further details of New alarm modifier icons;



FIG. 18 illustrates the depiction of outstanding alarms and alarms which are under repair;



FIG. 19 illustrates an example of the graphical depiction of a typical series of state and status transitions which might occur during an alarm scenario;



FIG. 20 is a flowchart for the steps taken to update the states and statuses depicted in a graphical representation of a network;



FIG. 21a-21f illustrate an example usage scenario; and



FIG. 22 illustrates node icons which may be expanded to display additional information.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



A telecommunications network consists of an interconnected set of network objects. There are three basic types of network objects, these being (1) network elements or nodes, (2) links, and (3) individual cards in a piece of shelf-based equipment.



Examples of network elements or nodes include voice switches, packet switches, cross connects, ATM (Asynchronous Transfer Mode) switches, ATM access and transport nodes. Network elements include shelf-based equipment located in a telecommunications company central office such as an ATM Concorde or OC192 ADM (Add-Drop Multiplexer) and field based equipment such as a coaxial node. A network element which is shelf-based is composed of a set of circuit cards installed in one or more shelves. An individual card in one of these shelves is also considered a network object. In this case, the piece of shelf-based equipment as a whole is a considered a network object, and at the same time each individual card in the shelf-based equipment is a network object.



Links connect nodes together and include copper wire links, microwave links, satellite links, coaxial links and optical fibre links for example. In some instances, repeaters may also be considered to be part of a link.



Additional components may be connected to the network which are used to manage the telecommunications network. Examples include databases, operating systems, terminals and printers. These components are not network objects, and do not form part of the telecommunications network per se.



FIG. 1 shows a physical context for the application of the present invention. There is a telecommunications network 2 consisting of a number of nodes or switches 3 and a number of links or transmission systems 4. The main network traffic consists of data or voice signals on the transmission systems 4 between the switches 3. Subscribers may access the network 2 with devices such as telephones 5 or personal computers 6 equipped with modems. In addition, there is managing equipment consisting of operations systems devices 7 and workstations 8 connected to a data communications network 9. The data communication network 9 includes a connection 10 to each of the switches 3 (nodes) and transmission systems 4 (links) in the telecommunications network 2. Management traffic flows on the data communications network 9 between the switches 3 and the managing equipment 7,8, the management traffic consisting of information for monitoring and controlling the network. The management traffic flows on the data communications network according to a communications protocol P which allows the switches and the management equipment devices 7,8 to understand each other. The interface between one of the network management devices 7,8 and the telecommunications network 2 may be referred to as a network management interface. The network management traffic may include state and status information for the switches 3 (nodes) and transmission systems 4 (links), and may also contain test, or traffic information for example. One or more of the management equipment devices 7,8 runs a network management GUI according to the invention and these management equipment devices will be referred to as network management terminals. These GUI equipped network management terminals have access to and in some cases control over network management information. A processor (not shown) forming part of each network management terminal receives the network management information, processes it, and presents it graphically on a display (not shown) with the GUI according to the invention. The invention provides a top level graphical view of the network objects which make up a network, and at the same time shows detailed state and status information for each network object. This gives network operators the ability to quickly visually interpret the state of the network at any time.



In the graphical representation of a network according to the invention, a basic icon is used to represent each network object. Icon attributes may be imparted to a basic icon to display state and status information for the network object represented by the basic icon. Icon attributes may include various icon outlines, shadings or three dimensional appearances as applied within the border or perimeter of the basic icon, for example. Further state and status information is displayed by attaching modifier icons to the basic icon. The various basic icons will be described with reference to FIGS. 1 to 4, and the manner in which state and status information is added to these icons will be described with reference to FIGS. 5 to 19.



A different basic icon shape is used to represent each of the three types of network object, namely nodes, links, and cards within a shelf. Referring now to FIG. 2a, a basic icon is shown which consists of a light grey coloured square icon used to represent a node. This will be referred to as a node icon. Identification symbols and numbers may be added to the basic icon to identify the type and capacity of the node it represents. A preferred set of identification symbols which includes some symbols recommended by the ITU-T is shown in FIG. 2e and several node icons identified with these symbols are shown in FIG. 2f. Referring to FIG. 2e, the ITU-T (International Telecommunications Union-Telecommunications Standardization Sector) based symbols include a square encompassing an "X" 12 representing a switch or a cross connect, a solid diamond 13 representing a transport node, a pair of solid triangles 14 representing a transport add-drop multiplexer, and a diamond separated into four squares 15 representing a transport cross connect. Suggested new symbols include a triangle with a series of parallel lines 16 representing an access node, a diamond which is solid except for a square hole in its centre 17 representing a regenerator, a diamond with a vertical slot in its bottom half to represent an LTE (line terminating equipment) and a question mark symbol 19 to represent an unknown network element. In some circumstances a symbolic node icon may be used which differs from the square icon depicted in FIG. 2a so as to be more representative of the node it represents.



Referring now to FIG. 2f, several examples of node icons for network elements are shown. Node icon 20 includes a symbol identifying it as a Transport ADM and the text "192" identifies its capacity. Node icon 21 represents an access element, with the text "FCOT" identifying the element as a Fibre Central Office Terminal. Node icons 22,23 represent transport cross connect network elements.



Referring now to FIG. 2b, a basic icon is shown which consists of a very thin rectangular green or light grey coloured icon used to represent a link. This will be referred to as a link icon. Links between two nodes are shown by link icons connecting the nodes and having a link type specifier icon in the centre of the link icon. In FIG. 2b only a segment of a link icon is shown. A link icon may consist of a series of segments which are arranged around other displayed icons so as no to interfere with them. Shown in FIG. 2g are preferred link icon link representations for each of CNET (control network) 30, optical fibre 32, and Electrical 34 type links. A more compact visual strategy may be employed when more than one link connects the same two nodes by using a single link bundle icon 36 instead of a series of individual link icons for the links. The four link icons described above are intended to be used to convey state and status information as discussed in detail below.



For nodes which are shelf-based, consisting of a number of cards, a node icon may be used to represent the entire node, or alternatively, a card icon representing each of the cards individually may be used. Referring now to FIG. 2c, a basic icon is shown which consists of a light grey coloured vertically oriented rectangular icon used to represent a card within a piece of shelf-based equipment. This will be referred to as a card icon. Typically, several card icons representing a set of cards within a piece of shelf-based equipment are shown together side by side to convey the fact that they represent cards forming part of the same shelf. An example of this is shown in FIG. 2d in which three card icons are displayed side by side. Using card icons instead of a node icon allows information for each card to be displayed independently.



The graphical representation may also include icons representing some of the components connected to the network which do not form part of the network. A simple pictorial icon may be used for these components. An example of a pictorial icon is given in FIG. 3 which shows a pictorial icon representing a terminal which may be a network management terminal, for example.



By way of example, FIG. 4a shows the graphical representation of a very simple network which uses the above described basic icon shapes for nodes, and links. It includes a pictorial icon 40 for a workstation terminal connected with a first CNET link icon 42 to a node icon 44 and a CNET link icon 46 to another node icon 52. The node icons 44,52 are for two network elements identified as switch cross connects by the symbol 12 from FIG. 2e. Also shown are a node icon 54 for a network element identified as a transport ADM by the symbol 14 from FIG. 2e, and a symbolic node icon 56 for a coaxial node with link bundle icons 60,64 connecting these elements to node icons 44, 52 respectively. The node icon 56 for the coaxial node is an example of a symbolic node icon having a different shape.



Depending on the complexity of a given network, the graphical representation of the network may include only a subset of all of the objects in the network. There may still be too many objects in the network to be conveniently shown at one time in a graphical representation such as that shown in FIG. 4a. In order to simplify the display of the overall network, the objects may be grouped in various ways depending upon some user-defined criteria. The grouping of elements may be based on geographic and/or other administrative criteria, for example. Preferably flexible polygonal container icons are used to perform such a grouping function. An example of a graphical representation of a network in which several container icons have been used to simplify the display of the network is given in FIG. 4b. The graphical representation includes node icons 66,67,68,70, link bundle icons 72,73,74,75,76, and container icons 79,80,81,82. Each container icon "contains" a collection of network object icons. A container icon may also contain other container icons in addition to the normal network object icons. Functionality may be provided to allow the specifics of what a container represents to be determined by opening the container. This might expand the container icon to display the collection of network object icons or additional lower level container icons which it represents. Container icons may present information about themselves such as labels.



The shape of the container icon may be manipulated so that it conforms to specific geographic or other administrative requirements or criteria. The container icons may be displayed transparently or translucently over a map of familiar geography for improved recognition. Default flexible container



colours are selectable by the network administrator. When they are created they are preferably translucent, having a muted colour such as grey-brown, grey-green, or grey-blue so as not to conflict with any of the alarm colours, as discussed below. An example of this is shown in FIG. 4c. Transparent container icons 90, 91, 92 are used to simplify or contain the portions of the network located in Oakland, San Francisco Bay, and Silicon Valley respectively. The container icons are transparently displayed over a map of the relevant geographical area. Also shown are a number of small square node icons 93,94,95,96 identified as transport nodes and links 97,98,99,100,101 connecting the transport nodes to each other and to the container icons. The use of container icons enables improved partitioning of the network to match any particular requirements. FIG. 4d shows an example of three polygonal containers labelled "Region A", "Region B" and "Region C" which have interlocking shapes which would be suitable to simplify the representation of non-overlapping groupings of network objects. Transparency of the containers enables overlapping and meshed regions of the network. As an example of meshed regions of a graphical network representation, a first container icon may contain a first set of network object icons, a second container may contain a second set of network object icons, and a third container may contain a set of network object icons which includes icons from each of the first and second sets. The complex relationships which exist in most of today's telecommunications networks often lend themselves to having their network objects grouped in various different overlapping ways and the use of container icons improves a user's ability to understand these complex relationships and groupings.



In the management of networks, and particularly telecommunications networks, a state model is used to provide a top level view of the network. In any such model, each network object can be in one or more of a large number of states and statuses. The states and statuses, and their definitions, and the allowed interactions between states are defined by each particular state model. The invention provides a graphical user interface which allows the visual depiction of very complex combinations of states. While the particulars of the invention can be adapted in many ways to any specific state model, a preferred embodiment of the invention provides a graphical representation of network objects such as nodes, cards and links and their states and statuses as defined by the current OSI model.



In the visual language provided by the invention, each network object is represented by a basic icon as discussed above. Each basic icon representing a network object can be in one of a number of base states. These base states are indicated primarily by an attribute imparted to the basic icon such as a different border, texture or perimeter. In addition, a set of modifier icons is provided which can be attached to the basic icon representing the network element to indicate supplementary state information. A modifier icon is an additional graphical symbol which is attached to or superimposed over a portion of the basic icon. A conversion between the states and statuses specified by a given state model and the base states and supplementary states provided by the graphical representation preferably maps the more frequently occurring combinations of states or statuses from the state model onto base states, and the less frequently occurring combinations of states or statuses onto supplementary states, thereby minimizing the required number of modifier icons.



The OSI model currently includes three state types, and at any instant in time, each object of the network is in three OSI states simultaneously, one state from each of the three state types. Each object has an Operational state which may be "Enabled" or "Disabled". Each object has a Usage state which may be "Busy", "Active" or "Idle". Each object has an Administrative state which may be "Unlocked", "Shutting down", or "Locked". The OSI states are summarized in the following table:



______________________________________ State Type States Graphic Representation ______________________________________ Operational Enabled basic icon with imparted Disabled attributes Usage Busy Active Idle Administrative Unlocked basic icon with modifier Shutting Down icons superimposed Locked ______________________________________



Each icon representing a network object is displayed in such a manner that the three OSI states of that object can instantly be discerned. This is done by imparting an attribute and in some cases a modifier icon to the basic icon which reflects the OSI states. The preferred attributes and modifier icons imparted to the basic icon for the various state combinations are shown in FIGS. 5 and 6 for card icons and node icons. These same attributes and modifier icons are used with link icons, but these are not included in the Figures.



As shown in FIG. 5, the OUA (Operational, Usage, Administrative state combination) of (Disabled, Idle, Unlocked) is indicated by imparting an attribute to the icon consisting of a dashed border. The OUA of (Enabled,Idle,Unlocked) is indicated by imparting an attribute to the icon consisting of a solid border. The OUA of (Enabled,Active,Unlocked) is indicated by imparting an attribute to the icon consisting of a three dimensional border.



The OUA of (Enabled,Busy,Unlocked) occurs less frequently and is represented by the icon having the three dimensional attribute in combination with a modifier icon consisting of a black exclamation mark as shown in FIG. 6. The "Busy" usage state is conveyed with a modifier icon and is thus a supplementary state.



Each of the OUAs in FIG. 5 have an Administrative state of "Unlocked". The OUAs of (Disabled, Idle, Locked), (Enabled, Idle, Locked) and (Enabled, Active, Shutting Down) are indicated by the addition of a lock modifier icon as shown in FIG. 6. The Administrative state is conveyed through the use of modifier icons and is thus a supplementary state.



Combinations of OSI states which can be represented with icon attributes only, and without the requirement for any modifier icons are the base states referred to previously. The base states in the above described graphical representation are shown in FIG. 5 and consist of (Disabled,Idle,Unlocked), (Enabled,Idle,Unlocked), and (Enabled,Active,Unlocked). The particular graphical display attribute was chosen for each of these base states to convey an intuitive visual semantic meaning. A dashed border attribute was selected for the base state of (Disabled,Idle,Unlocked) due to the visual semantics communicated by dashed lines, namely that of being disabled; a solid border attribute was selected for the base state of (Enabled,Idle,Unlocked); and a solid 3D border attribute was selected for the base state of (Enabled,Active,Unlocked) to imply a "plump" node "full of activity or traffic". Since all three base states have the administrative state "Unlocked" the base states in the remainder of the text will be referred to simply as (Disabled, Idle), (Enabled, Idle), and (Enabled, Active) for brevity.



FIG. 7 shows the three base states for each of three types of network icon, namely a node icon, link icon, and card icon.



Referring back to FIG. 4a, the three dimensional borders of node icons 50,52,54,56 are indicative of the base state (Enabled, Active). Link icons 42,46,58,60,62,64 also each have a three dimensional appearance indicative of the base state (Enabled, Active).



In addition to the three state types, the OSI model includes five status types, these being Alarm, Procedural, Availability, Control and Standby. The possible statuses for each status type are summarized in the following table:



______________________________________ Graphic Status Type Statuses Representation ______________________________________ Alarm None basic icon with Critical modifier icons Major superimposed Minor Under Repair Outstanding or Acknowledged Procedural None Initialization Required Not Initialized Initializing Reporting Terminating Availability None (available) In Test Failed Power Off Off Line Off Duty Dependency Degraded Not Installed Log Full Control None (unrestricted) Subject to Test Partly Locked Reserved to Test Suspended Standby Providing Service Standby Providing Service Hot Standby Cold Standby ______________________________________



Unlike the OSI states, a network object does not necessarily have a status from each status type, and in many cases will have no statuses at all. In the graphical representation of the network, which statuses of the five status types, if any, that apply to a given network object are represented by modifier icons. Each modifier icon is intended to be a visual metaphor for the status it is representing. Note that in the OSI model, a given status may occur simultaneously with only certain combinations of states. In the present context, this means that a given status may occur simultaneously with only certain base states. How modifier icons are used to represent the Procedural status, Availability status, Control status, and Standby status is illustrated in FIGS. 8 to 11 respectively. How the statuses illustrated in FIGS. 8 to 11 may be combined is illustrated in FIGS. 12 to 15. How modifier icons are used to represent the Alarm status is illustrated in FIGS. 16 to 19.



It is noted that in the particular OSI implementation of the invention described herein, operational and usage states are indicated by imparting attributes to the basic icon. Administrative states and all the OSI statuses are indicated using modifier icons superimposed on the basic icon graphic. As mentioned previously, the state and status information conveyed through the use of attributes is referred to herein as base state information, and the state and status information conveyed through the use of modifier icons is referred to herein as supplementary state information. In this particular embodiment, the network management terminal receives the network management information initially in the form of OSI state and status information and performs a state set conversion, converting the OSI states and statuses into base states and supplementary states for each network object. Once the base states and supplementary states for each network object have been determined, the attributes and modifier icons which must be added to the basic icons are also known. More generally, an icon attribute may be used to display a base state selected from a set of base states, each base state representing a state, a status or a combination of states and statuses, and modifier icons may be used to display a set of supplementary states, each supplementary state representing a state, a status or a combination of states and statuses. In some cases it may be appropriate to map the network management information directly onto base states and supplementary states eliminating the requirement of performing a state set conversion.



Referring now to FIGS. 8 to 11, in each of the illustrated examples, the modifier icon is shown as it might be applied to both a node icon and a card icon. Some textual description of the various statuses is also provided in the figures where appropriate.



FIG. 8 shows how modifier icons may be used to represent the Procedural status for each of the three base states. In the case in which there is no Procedural status, no modifier icon is required. The Procedural status "Initialization Required" can occur only for the base state (Disabled, Idle) and is represented by a modifier icon consisting of a hand with an upward pointing solid triangle. A modifier icon consisting of three upward pointing solid triangles is used to represent the Procedural status "Initializing" for either of the base states (Disabled, Idle) or (Enabled, Idle). A modifier icon consisting of three downward pointing solid triangles is used to represent the Procedural status "Terminating" for any of the three base states. A modifier icon consisting of two upward pointing triangles and a small bar graph is used to represent the Procedural status "Reporting" for either of the base states (Enabled, Idle) and (Enabled, Active). In this example, the Procedural status is supplementary state information since it is displayed through the use of modifier icons.



FIG. 9 shows how modifier icons may be used to represent the Availability status for each of the three base states. In the case in which there is no Availability status, no modifier icon is required. A bar graph modifier icon is used to represent the Availability status "In Test" for the base state (Disabled, Idle). A broken stick modifier icon is used to represent the "Failed" Availability status for the base state (Disabled,Idle). An unplugged modifier icon is used to represent the Availability status "Power off" only for the (Disabled, Idle) base state. A clock modifier icon is used to represent the "Off Duty" Availability status for the base states (Disabled,Idle) and (Enabled,Idle). To indicate the Availability status "Degraded" a grey exclamation point modifier icon is used for either of the base states (Enabled,Idle) or (Enabled,Active). Recall that a black exclamation point modifier icon was used to indicate the usage state "Busy". Finally, the Availability status "Not Installed" is shown for the (Disabled,Idle) base state by adding hatch lines to the icon.



FIG. 10 shows how modifier icons may be used to represent the Control status for each of the three base states. The "Subject to Test" Control status is represented by a bar graph modifier icon for each of the base states (Enabled,Idle) and (Enabled,Active). The "Reserved for Test" Control status is represented for any of the three base states by a modifier icon consisting of a bar graph with a lock.



FIG. 11 shows that modifier icons may be used to represent the Standby status for each of the three base states. A node which has a primary and a backup unit is illustrated by two node icons one of which is behind the other. The icon in the foreground relates to the primary unit and may be referred to as a primary icon, while the icon in the background relates to the backup unit and may be referred to as a backup icon. A card having a primary and a backup unit is indicated by a card icon with a pair of overlapping rectangles, namely a primary rectangle and a backup rectangle,



symbolic of the redundancy.



For node icons, the status of the backup unit is indicated by the border of the backup icon. The Standby status can be either "Providing Service" which corresponds to the backup unit having a base state of (Enabled,Active) and is illustrated by a solid backup icon, "Hot Standby" which corresponds to the backup unit having a base state of (Enabled,Idle) and is illustrated by the backup icon having a solid border, and "Cold Standby" which corresponds to the backup unit having a base state of (Disabled,Idle) and is illustrated by the backup icon having a dashed border.



For card icons, both rectangles being unshaded is indicative of "Cold Standby". The "Hot Standby" status is indicated by the primary rectangle having a shaded appearance with respect to the backup rectangle. The "Providing Service" status is indicated by switching the places of the two rectangles, shading the backup rectangle black and by writing the symbol "2" within the backup rectangle to indicate that it is the backup card which is providing service.



There may be a need to show concurrent states or statuses. This can be achieved by listing the appropriate modifier icons on the icon. FIG. 12 shows several examples of this in row 160. Also shown in FIG. 12 in row 162 is an alternative to showing a large number modifier icons, wherein an information modifier icon is used to draw the user's attention to a change in the state or status. By clicking on the information icon, detailed information is then displayed.



In the above described embodiment, modifier icons are positioned at the top of the network node icons. This positioning is somewhat arbitrary and could vary based on the particular object identified by the node icon according to any number of predetermined criteria. For example, they could be positioned so as to avoid overwriting the node identifier, support more than one simultaneous icon, make the icons appear as separate and selectable objects, avoid overwriting the alarm count, or maintain some consistency with the alarm strategy.



FIG. 13 shows an example of how modifier icons might be positioned on a link icon for a link in each of the three base states. Two lock icons are shown indicating that the link has been administratively locked for both transmit and receive. Other positions for the modifier icons on link icons are possible.



Modifier icons can be positioned anywhere on a card icon depending on the physical layout of the equipment. If the card has distinguishing characteristics such as lights, they should be shown on the icon in their correct position to give the craft and network operator a common reference point when they are communicating. As a result, modifier icons should ideally be positioned in locations that would not obliterate these distinguishing characteristics. FIG. 14 shows distinguishing characteristics at both the top 180 and bottom 182 of the card and also shows a series of modifier icons 184 on a card.



In some cases, it may be advantageous to make particular modifier icons selectable so as to provide access to further information. An example of this is shown in FIG. 15 which includes a bar graph modifier icon indicative of the Availability status "In Test". The bar graph modifier icon is selectable to provide access to a menu which in the illustrated case includes the options "Show details", "Open test manager", and "Hide Status".



Referring now to FIGS. 16 to 19, a comprehensive strategy for conveying detailed OSI alarm status information will be described. An alarm is an event status generated by a network object which may indicate that some sort of irregular condition has occurred, and that test and repair work may be required. In the OSI model, there are alarm types having three different levels of severity. These OSI alarm severities are "Critical", "Major", and "Minor" and are abbreviated by the letters "C", "M" and "m" respectively.



FIG. 12 shows modifier icons are used to represent the Alarm status for each of the three base states. A "New" alarm is an alarm for which no acknowledgement or action of any kind has been taken. The existence of New alarms is signalled by a bubble modifier icon with "abbreviated alarm text" written therein indicating the number and the severity the New alarms. Abbreviated alarm text in the alarm bubble contains a count of the highest severity new alarms only. The bubble modifier icon and the basic icon are also coloured to draw attention to them, and to reflect the severity of the alarm, where the colours yellow, orange and red are used to indicate increasing severities minor, major, and critical respectively. Thus a basic icon coloured orange with an orange bubble modifier icon with the abbreviated alarm text "1M" written therein means that one New Major alarm has occurred. The presence of one New Major alarm is shown in FIG. 12 for the (Enabled,Idle) 120 and (Enabled,Active) 122 base states for each of a card icon and a node icon. Note that the Figures are in black and white, and as such the colouring actually used to display alarms cannot be shown.



Once an alarm has been acknowledged, it becomes an Outstanding alarm rather than a New alarm. When there are no New alarms, the bubble modifier icon is removed, and the basic icon including its border is recoloured its normal shades of grey. Outstanding alarms are indicated by the presence of an additional outline surrounding the border of the basic icon, with the colour of the additional outline matching the colour associated with the severity of the highest-severity alarm. The outline is displayed so as not to interfere with the border already displayed. This allows the border and outline to convey different information. Abbreviated alarm text indicating a count of the highest severity alarms, both new and outstanding, is written within the icon itself. An example of the appearance of the icon with one Outstanding Critical alarm 124,126,128 is shown in FIG. 16 for each of the three base states. Each of the icons 124,126,128 has an additional red coloured (dark shade as illustrated) outline surrounding it and has the text "1C" written within it indicating the presence of a single outstanding Critical alarm. There may be New and Outstanding alarms at the same time. In this case, the bubble modifier icon and the abbreviated alarm text in the bubble together with the colour of the bubble and basic icon (including the border) will indicate the New alarms, and the outline surrounding the basic icon will indicate the highest severity of Outstanding alarms.



After an alarm has been acknowledged, and some repair work has been instigated, the alarm status "under repair" is used to indicate this to be the case. The alarm status "Under Repair" is indicated by a "hand" modifier icon. When the hand modifier icon is applied, the additional outline surrounding the basic icon is removed assuming that no additional outstanding alarms exist.



In addition to the three OSI alarm severities of minor, major, and critical, the preferred embodiment of the invention includes two additional alarm severities, namely "Warning" and "Unknown". A comprehensive display of how each severity of new alarm would appear on a container icon, a node icon, a link icon, and a card icon is shown in FIG. 17. In each example, one alarm of the indicated severity is new, as indicated by the bubble. The total number of the highest severity alarms is written within the icon. In this case, the total number is the same as the number of New alarms meaning that there are no outstanding alarms. In the case of container icons, the alarm indications reflect the sum of the most severe of the alarms pertaining to the network objects contained by a given container icon. Thus, if four different network elements contained within a container each experienced one New Critical alarm, then the alarm bubble would contain the abbreviated alarm text "4C" indicating that the container has four new Critical alarms.



The presence of additional alarms which have a severity lower than that of the highest severity is indicated by appending a "+" to the abbreviated alarm text. If the additional alarm is new, the "+" will be appended to the abbreviated alarm text appearing in the bubble modifier and to the text appearing on the icon itself, while if the additional alarm is outstanding, then the "+" will only be appended to the abbreviated alarm text appearing on the icon itself.



As indicated above, an outstanding alarm is also shown symbolically by adding an additional outline around the icon. Once the condition that caused an alarm is removed, for instance, once the corresponding fault is under repair, that alarm is no longer outstanding. When this occurs, the additional border around the icon is removed, and the abbreviated alarm text is updated to reflect the new condition. FIG. 18 illustrates in row 140 the appearance of several icons each having one outstanding critical alarm and at least one outstanding alarms of lesser severity as indicated by the abbreviated alarm text "1C+" and the red (dark) border. In row 142 of FIG. 18, similar icons are shown after the "under repair" modifier icon has been added.



FIG. 19 illustrates a typical sequence of icon appearances for an example alarm scenario. First, a single new critical alarm occurring at a node is indicated by a red (dark) modifier icon bubble containing the text "1C" and by the basic icon being shaded red (dark) (A). Since the total number of both New and Outstanding alarms is also one, the text "1C" also appears inside the node icon. The node has a base state of (Enabled,Active) as indicated by the three dimensional appearance of the icon. In (B), the alarm has been acknowledged and becomes an outstanding alarm. This is indicated by the removal of the bubble icon modifier, by the red outline surrounding the node icon, and by the text "1C" remaining inside the node icon. The colour of the node icon has returned to normal, and the base state is still (Enabled,Active). In (C) the node is still in the base state (Enabled,Active) but has the Administrative state "Shutting Down" as indicated by the lock modifier icon. In (D) the base state has changed to (Enabled,Idle) as indicated by the non-three-dimensional appearance of the icon. For this base state, the lock modifier icon signifies the Administrative state is "Locked". In (E) the base state has changed to (Disabled,Idle) as indicated by the icon's border being dashed. In (F), the solid red outline has been removed indicating that the critical alarm is no longer outstanding. The hand modifier icon indicates that the network element has the Alarm status "Under Repair". The abbreviated alarm text has been removed from the icon in this case. In (G) an additional modifier icon has been added to indicate the "In Test" Availability status.



In addition to the graphical representation of the alarms, Alarm manager window(s) may be provided which present a textual tabular summary of the alarms present on a particular set of network objects. Each network object included in the table has a record which summarizes the alarms for that network object.



In the embodiment described above, exemplary base state icon attributes and supplementary state modifier icons have been used to represent a all of the states, and a subset of the statuses provided in the OSI model. Additional modifier icons (not shown) may be assigned to the remaining statuses so as to provide a complete graphic representation of the entire OSI model.



In FIG. 20, a flowchart is shown of the logic followed by the GUI in updating displayed state and status information when a change in a state or status occurs for any network object forming part of a network being graphically represented according to the invention. At step 0, it is assumed that the initial states and statuses of the network objects are known. In step 1, a check is made to see if a change in a state or a status for any network object has occurred. If not, then no action is required. If a change for a specific network object has occurred, then in step 2 a check is made to see if that network object is included in an active alarm manager window. If the network object is included in an active alarm manager window, then the record in the alarm manager window for that network object is updated to reflect the new state and status information. At this point, whether or not the basic icon for the specific network object is displayed or not, the basic icon is defined as a "context symbol" in step 4. A basic icon is the first level of context symbol. A container icon containing a basic icon is the next level of context symbol. A container containing a container is the next level of context symbol and so on. Steps 5, 6, and 7 are now repeated for the various levels of context symbol. In step 5, the context symbol which may be a basic icon or a container icon, is updated with icon attributes and modifier icons to reflect the modified state and status information. Of course, in some cases, the particular context symbol may not be included in what is currently being displayed. For example, if the basic icon is within a container icon, then it will not be displayed. However, the state and status information for the basic icon is still updated but with no immediate effect upon the graphical representation until the basic icon is actually displayed. In step 6, if the context symbol is not within a container, then the processing of that event finishes. Otherwise, the container containing the context symbol is redefined as the context symbol, and steps 5,6,7 are repeated as necessary. Container icons include alarm information consisting of alarm modifier icons and text, but do not in general include the remaining state and status modifier icons and attributes, these only being displayed on the relevant basic icon. The only difference in updating the alarm information for a container icon as opposed to a basic icon is that a container icon reflects the sum of the worst alarms outstanding for all of the basic icons or container icons within it.



The initial graphical representation of the network is set up by a chief administrator using a GNE (Graphic Network Editor) screen which is used to define the position of network objects against their background. Normal users of the network management tool access the GUI via a GNB (Graphic Network Browser). The GNE is used to make configuration changes as the network evolves and as network elements are added or removed. A configuration of workstations to monitor a network using the GUI according to the invention will typically consist of at least one terminal, though for large networks a more typical application of the invention will have several workstations running the GUI concurrently to allow many operators to share the effort of surveillance of the network. Whether on a single screen or multiple ones, the setup of the view presented to the operators is done by the chief administrator using the GNE.



The GNE provides the chief administrator with a basic graphic editor (not unlike many PC drawing packages) and the following capabilities:



provide a top level view GUI of the network;



the ability to create sub levels of the top level to enable partitioning the nodes or containers representing the network into logical sub groupings as required;



import as many background images (such as maps of cities, countries or building floor plans) as will be required to provide a frame of reference in the various GUI levels;



auto-discovery so that any new elements added to the network pop up automatically in the top level of the GNE;



auto-discovery may also include the automatic definition of the element type;



the ability to create flexible containers in any of the levels in the GNE (the definition of the shape of these containers being set by typical graphical editing techniques: clicking and dragging a mouse to define the shape on top of the background);



the ability to drag and drop (via a mouse) network elements into containers and reposition the network elements to meaningful locations against the background;



the ability to assign a name (text label) to network elements and containers as well as assign names to each level or window in the GUI;



the ability to define how many GNB users there will be and for each user which views of the network GUI will be accessible;



the basic set of GUI symbols and objects as defined by the invention with their associated attributes to represent network elements, links between elements and different containers.



Once the initial setup is made, the GNE's main function is to (re)position



network icons and container icons if the network is reconfigured in any way. For instance as new network objects are added and pop up in the GNE's top level view, they need to be situated in an appropriate location relative to the existing network object icons. Otherwise with an unchanging network configuration, the GNB views are used to monitor the network and the GNE is likely inactive.



With the network configuration and views laid out by the GNE all users of the invention access the network management tool via their GNB windows. The layout and content of windows and containers is not modifiable by users from the GNB. The GNB provides the user with a standard windows like means of navigating through the levels (to open or close or select which view to bring to the forefront or to "drag" and reposition a window on the workstation screen).



An example scenario using the network management GUI according to the invention running on a network management workstation equipped with the capabilities described above will now be described with reference to FIGS. 21a-21f. In the example scenario which follows, a network is shown which is still growing. A large amount of configuration activity is ongoing, and the network is experiencing some troubles.



Referring firstly to FIG. 21a, shown is a top level graphical representation of a network presented in a GNB (graphical network browser) window 200 on a display of the network management workstation. In this view, there are five regional container icons 201,202,204,206,208, labelled "Main", "West", "South", "Centre" and "North" respectively. In this top level view, no individual network objects are shown. In the Main container icon 201, there is written the abbreviated alarm text "3m" 210. This indicates that there are three minor alarms which have occurred within this container. The fact that there is no alarm bubble modifier icon signifies that the three minor alarms have all been acknowledged. A yellow outline 211 surrounds the border of container icon 201 also indicating the existence of acknowledged minor alarms.



In FIG. 21b the Main container icon 201 is coloured red, and a red bubble modifier icon 212 has been added containing the abbreviated alarm text "1M". This indicates that a new major alarm has been detected. The abbreviated alarm text within icon 201 has been updated to "1M+" where the "+" indicates that there are outstanding alarms of lesser severity than major. The yellow outline 211 is also still shown. Also shown is an Alarm Manager window 214 which is displayed as a result of the operator double clicking on the alarm balloon 212. A single click would have produced a menu with a number of items including the Alarm Manager. The Alarm Manager window 214 contains further details of the new major alarm. The operator decides to look at the network details, and does this by double clicking on the Main container icon 201 to open it.



In FIG. 21c the GUI display after the operator has double clicked on the Main container icon 201 is shown. A new window 216 titled "Main" displays the details of the network elements contained by the Main container icon 201. These include four nodes icons 220,222,224,226 labelled "Main A", "Main B", "Main C", and "Main D" respectively and several links icons connecting them. Now the particular node icon 220, Main A, which produced the alarms previously displayed in the top level view of FIGS. 21a and 21b is displayed in red along with the red alarm balloon.



Additional information contained in the Main display window 216 shown in FIG. 21c includes the fact that a link 230 connecting Main A to Main C has failed as indicated by its red dashed appearance. Modifier icons 232,234 are attached to the Main D node icon 226 as a result of a previous operator action. These modifier icons 232,234 show that the node has been manually set to shut itself down, and is under repair respectively. Two nodes icons 236,238 are also shown which are in a "plan to add" state. These nodes have been installed, but have yet to be configured as part of the network.



The next step in the scenario is for the operator to further investigate the source of the alarm. An operator can select a test to be run on the node which produced the alarm. In FIG. 21d, the operator has selected node icon 220 and then selected "Test 1" from a "Tests" menu. The effect of this is for an "in test" modifier icon 240 to be attached to the node icon 220 as shown in FIG. 21e. When the test is complete, the modifier icon changes to inform the operator that this is the case. This may include an indication that physical repairs are required. If physical repairs are required, then the operator can dispatch field personnel to complete them. When the repairs are completed, the equipment would then perform a self test to confirm normal operating conditions, and would report this to the network management workstation.



In FIG. 21f, all of the equipment in the Main window has been restored to a normal state as indicated by the lack of any abnormal colours, modifier icons, outlines, abbreviated alarm text etc. This completes the example scenario.



Numerous modifications and variations of the present invention are possible in light of the above teachings. It is therefore to be understood that within the scope of the appended claims, the invention may be practised otherwise than as specifically described herein.



While a symbol set which includes ITU-T symbols has been used to identify network elements on the icons, alternative symbol sets could be used, or the shape of the icon itself could be used.



While particular shapes for the node and link icons have been used in the illustrated and described examples, other shapes could be used with equal effect.



Modifier icons have been described which have particular shapes and positions, but clearly alternative shapes and positions could be used, so long as each modifier icon is clearly associated with a particular basic icon which represents a network object, and so long as the information intended to be conveyed by the modifier icons is clearly visually discernable.



A particular strategy for dealing with alarms has been described in the preferred embodiment consisting of a combination of alarm bubble modifier icons, abbreviated alarm text, shading the bubble and basic icon, and displaying outlines around the basic icon. While particularly appropriate for the OSI alarm states, this strategy could be applied equally well to other alarm state definitions. Alternative methods for representing this alarm information could also be employed.



In some cases, information in addition to the state and status information needs to be made available to the operator. The node icons may be expanded to a size appropriate for displaying the information required. An example of this is given in FIG. 22. A basic node icon 300 for a transport node is shown, and further identified by its location in Toronto. In order to identify the capacity of the transport node, expanded node icon 302 is used. Further details are given with node icon 304, where no expansion of the icon was required. In order to display performance statistics or traffic behaviour, for example, expanded node icon 306 may be used in which the relevant graphical information is included within the boundaries of the expanded node icon. This provides a convenient way to map this additional information onto a physical view of the network in an easily comprehendible way.



Although the invention has been described as applied in a particular way to represent the OSI standard, the scope of the invention includes other ways of representing the same OSI standard and other standards such as the BellCore requirements. The primary and secondary states specified in the BellCore requirements are summarized in the following table:



______________________________________ Primary State Primary State Qualifier IS in service NR normal ANR abnormal RST restricted ANRST both ANR and RST OOS out of service AU autonomous OOS MA management OOS AUMA both AU and MA AURST AU and RST MAANR MA and ANR Secondary State ACT active AINS auto in service BUSY no spare capacity COMB sharing mate's load DGN diagnostic EX service affecting exercise FAF supporting facility OOS FEPO far end processor OOS FLT faulty IDLE no users but ready IDLERCV connected to transmit but not to receive IDLETRMT connected to receive but not to transmit INHIP inhibit in progress LPBK loopback in progress MEA mismatch of equipment and attributes MON reached abnormal threshold MT manual OSS for maintenance MTCLEIMD maintenance limited due to defect OVFL overflow PMI performance monitoring inhibited PPS pre-post service PRI protection release inhibited PSE protection switch exercise in progress PWR abnormal power condition RAR rearrangement in progress RDLD red lined SDEE supported entity exists SGEO supporting entity outage STBYC cold standby STBYH hot standby STBYI standby inhibited SWDL software downloading SWTCH switching system activity caused OOS SWTI software transfer inhibited SWUL software upload in progress TRD transferred load to mate TRMB terminate both TRMF terminated from TRMT terminated to TS test in progress UAS unassigned UEQ unequipped WRK working ______________________________________



In applying the invention to the representation of the primary and secondary states of the BellCore standard, it would be preferred that the base states be used to represent the primary state information, and that modifier icons be used to represent the secondary state information.

PatentNumber=6115646,FIELD OF THE INVENTION



The invention relates to process automation and more particularly relates to work flow management in a geographically dispersed distributed heterogeneous computing environment.



BACKGROUND OF THE INVENTION



Many processes are made up of a number of activities which must be performed by different software applications on geographically distributed processing nodes. Such processes often also include steps which must be executed by humans. It would be advantageous to have a process automation system which is capable of running such processes in an automated fashion in a manner which makes efficient use of the resources provided by the distributed processing nodes, and which at the same time satisfies various constraints. It would also be advantageous for such a system to be dynamically configurable at run time, and to permit the "plug and play" of new applications on the processing nodes without effecting previously existing processes.



U.S. Pat. No. 5,535,322 to Hecht, which issued Jul. 9, 1996, entitled "Data Processing System with Improved Work Flow System and Method" describes a system which uses an overall pull system design and an attribute-based file system to store work in progress. The common "pull system" protocol uses DCE (Distributed Computing Environment--a standard from the Open Software Foundation), and each application service pulls work only when it is ready; there is no pushing of work onto an application service. It also does not use an ORB (object request broker) and does not provide the ability for dynamic scheduling.



U.S. Pat. No. 5,627,774 to Schutzman et al which issued May 6, 1997 entitled "Automatic Electronic Messaging System with Feedback and Work Flow Administration" describes an event-driven and conditional rule-based system. The system status reporting or feedback is used for follow-up activity, such as workflow administration or routing. The control in the Schutzman system is centralized, does not use an ORB, and does not provide the ability to extend services at run time.



Also, in Schutzman the feedback information is used for work flow administration, allocating work or tasks in accordance with rules or applications among different queues.



U.S. Pat. No. 5,581,691 to Hsu et al which issued Dec. 3, 1996 entitled



"Work Flow Management System and Method" describes a work flow management system and method for executing and tracking the progress of long running work flows, and for recovering from system failures during the execution of long running work flows. The system does not use an ORB bus, but instead uses a static scheduling scheme based on time-outs, and uses a centralized control scheme based on a "Flow" controller that controls the execution of each work flow. In terms of recovery, the Hsu system logs records and output event signals, stored in a history database, to ensure the recovery of a work flow upon a system failure.



U.S. Pat. No. 5,301,320 to McAtee which issued Apr. 5, 1994 entitled "Work Flow Management and Control System" describes an approach to the creation of large application systems by representing workflow tasks in a fully modular fashion that allows the designer to alter the order and relationships among tasks without the reconfiguration of the entire workflow system. The system can integrate various types of application software, and is capable of partitioning tasks among various operators, computers and computer terminals as specified by the designer. This integration is not done using an ORB bus; and is not object-oriented, and does not have dynamic features such as dynamic scheduling.



U.S. Pat. No. 5,630,069 to Flores which issued May 13, 1997 entitled "Method and Apparatus for Creating Workflow Maps of Business Processes" describes a method and system which provides consultants, business process analysts, and application developers with a unified tool with which to conduct business process analysis, design, and documentation. The fundamental concept of workflow analysis is that any business process can be interpreted as a sequence of basic transactions called workflows. The workflow system uses client/server design and concentrates workflow operations in the workflow server rather than the end user applications.



In addition to the above described patent literature regarding workflow systems, there are several existing commercially available work flow management software products.



One such product entitled "Action Workflow Enterprise Series" developed by Action Technologies does not support dynamic scheduling, does not use an ORB bus, and does not support the WPDL (Workflow Process Definition Language) of the WfMC (Workflow Management Coalition). It only focuses on human centred workflows. In addition, since the modelling elements for the organizational embedding are not very expressive (only roles and identities), complex rules of responsibility cannot be modelled at all.



A system entitled "COSA" from the German software company Software-Ley is built according to the client/server paradigm, does not use an ORB, and does not provide dynamic scheduling of processes. COSA's modelling elements are dedicated to model human organizations, not "organizations" of servers, machines and cells which might be useful in manufacturing environments. The only data types supported in COSA are files and unstructured variables. Data flow of structured data between activities cannot be specified.



Another WFM system, FlowMark, from IBM is a database centred workflow management system. It does not use an ORB bus, does not support dynamic scheduling, does not support runtime extension of services, and does not support dynamic upgrades to notification policies. FlowMark follows the client/server paradigm. The only way to execute a FlowMark process without human intervention is to declare program or process activities as automatic.



InConcert from XSoft uses standard services like RPC (remote procedure call), NFS (network file system) and database, and does not use an ORB bus. InConcert is distributed over a heterogeneous network according to a client/server architecture. It does not support dynamic scheduling and does not extend workflow services at run time.



Finally, SAP Business Workflow from SAP AG is a database centred WFM system which uses R/3 to provide an enterprise with standard functionality for information processing. SAP Business Workflow is integrated into R/3 and not a stand-alone system.



SUMMARY OF THE INVENTION



It is an object of the invention to obviate or mitigate one or more of the above identified disadvantages.



Another object of the GPAE invention is to provide an improved decoupling method for processes, control engine, and agents that execute the processes following the "orders" of the control engine.



Another object of the invention is to provide scalable work flow management services over a distributed and heterogeneous computing network.



A further object of the invention is to provide extensible mechanisms that support the dynamic (run time) plug-in of processes, agents and services.



According to a first broad aspect, the invention provides a process automation system for controlling the execution of processes on a plurality of processing nodes each having processing agents associated therewith, the system comprising a GPAE (generic process automation engine) and an ORB (object request broker) bus connected to the plurality of processing nodes, the GPAE having: a) a build time part for creating and storing at least one process definition identifying a sequence of work items, pre-conditions and post-conditions for the execution of work items, and propagation rules for propagating outputs of work items to inputs of other work items, and for creating and storing a request to create a process instance for a particular process definition; b) a run time part comprising process instance servers for coordinating the enactment of the work items forming part of the process definitions and a scheduler for scheduling each work item forming part of the process definition either for execution at a given time and by a particular processing agent on a particular one of the processing nodes or for execution by a human, the scheduler using constraint propagation logic.



Advantageously, the process automation system can be used in those application areas that require the automation of processes to (a) reduce costs, (b) reduce process execution times, (c) increase quality, and (d) support increasing bandwidth demands. Examples of these application areas include: ordering management, inventory control, banking, health, government services, production related processes, medical processes, S/W electronic delivery, automated testing, automated assembly, and network management.



The process automation system is preferably event-driven; for example, the completion of an activity instance triggers an event to the parent process instance to execute the next set of activities.



With CORBA's (common object request broker architecture) object request broker (ORB), a client calls a method within a specific object. Different object classes may respond to the same method invocation differently through the polymorphism mechanism. Because each object manages its own private instance data, the method is implemented on that specific instance data.



CORBA is based on the object-oriented paradigm. The object-oriented paradigm supports key concepts: inheritance, data encapsulation, polymorphism, and separation of interface and behaviour as an object's components.



Preferably, GPAE uses a dynamic notification paradigm: those parties that are interested in an event register their interest with GPAE and are notified upon the occurrence of the event. In GPAE the recipient of an event can specify the action to be executed (similar to a "callback" mechanism) at run time.



Preferably, GPAE's control is distributed in a set of process instances, and its dynamic scheduling and resource allocation mechanisms are based on constraint propagation logic theory.



Preferably, GPAE uses an ORB and a pool of plugged-in process instances that act as distributed work flow engines. These work flow engines control and enact the contained network of activities according to the corresponding process definition, input data, and the schedule, created by the scheduler-resource allocator server plugged into the CORBA bus.



Preferably, GPAE's architecture is open: new roles can be created, new processes can be modelled, and new services can be added at run time. In this regard, GPAE can also be considered as a distributed object-oriented and pattern-oriented work flow development environment.



Preferably, GPAE monitors the state of servers continuously and recovers them as needed at run time using the persistent state.



Preferably, GPAE provides the ability to model processes and to enact manual and automated activities.



BRIEF DESCRIPTION OF THE DRAWINGS



Preferred embodiments of the invention will now be described with reference to the attached drawings in which:



FIG. 1 is a top level architectural view of a process automation system according to an embodiment of the invention;



FIG. 2 is a logical view of a CORBA (common object request broker architecture) bus;



FIG. 3 is a more detailed block diagram of the process automation system of FIG. 1;



FIG. 4 is an illustration of the automated flow of the process automation system of FIG. 1;



FIG. 5 is an illustration of a main panel screen display for the process automation system of FIG. 1;



FIG. 6 is an illustration of a work list menu that may be used to monitor manual (non-automated) tasks;



FIGS. 7a and 7b are illustration of two forms that may be used to query the system about operational runtime information based on a set of filters (e.g., status, start time, request name);



FIGS. 8a and 8b are illustration of two forms that display the run time progress in response to a query;



FIG. 9 is an illustration of a process definition screen display;



FIG. 10 is an illustration of a work item properties screen display;



FIG. 11 is an illustration of a screen display used to select an activity definition;



FIG. 12 is an example of a screen display form which may be used to define a transition;



FIG. 13 is an illustration of an activity definition screen display;



FIG. 14 is an illustration of a screen display form which may be used to open and view an activity definition;



FIG. 15 is an illustration of a display for specifying attribute definitions (input and output arguments) for activity and process definitions;



FIGS. 16a and 16b are illustrations of an example of a process definition and its sub-processes;



FIG. 17 is an example of the process automation system of FIG. 1 applied to a particular application; and



FIG. 18 is an example of a screen display form which may be used to submit a request and to specify the execution of a selected process.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



Referring firstly to FIG. 1, a top level architectural view of a process automation system according to an embodiment of the invention includes has two main components, these being a GPAE (general purpose automation engine), or simply "engine" 10 and a CORBA (common object request broker architecture) bus 16. The purpose of the engine 10 is to coordinate through the CORBA bus 16 the execution and automation of a plurality of processes on a plurality of processing nodes 18 connected to the CORBA bus in a manner which makes efficient use of the processing nodes and which satisfies various conditions and constraints for the execution of the processes.



The processes are defined as process definitions 12 which are input to the GPAE 10. A process definition is a specification of a sequence of work items that need to be executed for a given process and a series of conditions or constraints for their execution.



The processing power for executing processes resides in the processing nodes 18 on which various software applications or tools execute. More particularly, the processing nodes are capable of executing activities which may be included as part of a work item in a process definition.



It may be that one or more actions forming part of a process definition require human input or action. A human performing such an input or action will be referred to as a "role". Thus a particular activity may be executed by a processing node or a role. Roles and tools/applications available to be run on processing nodes together will be referred to as "processing agents" or simply "agents".



The engine 10 is connected to the processing nodes 18 through the CORBA bus 16. Through the CORBA bus 16, the engine 10 is capable of invoking any of the tools/applications on the processing nodes 18. The engine 10 serves to decouple the process definitions 12 from the processing agents.



When a particular process is to be run, an input is made to the engine 10 in the form of a request 14. The request identifies the process to be executed and contains input information for a specific instance of the process. As described in detail below, the engine 10 then coordinates the execution of the process, and generates any appropriate feedback and output 20.



As described previously, the system has an engine component 10 and a CORBA bus component 16. The engine 10 consists of two main parts, these being a build time part 22 and a run time part 24.



The build time part 22 is used by roles to:



capture a process definition graphically and store it in a repository, describing its components, order of execution, conditions for their execution, and attribute propagation rules;



approve a process definition for its usage in production;



model resources;



model, define roles and access control privileges;



define goals (policies) mainly for notification, scheduling, resource allocation, and security services;



create a request, tie it to a process definition, specify the priority and due date, and submit the request to the run time part 24; and



query progress of scheduled and enacted requests.



The run time part 24 is the part of the system that:



notifies roles about events, this is the only service exported in this part to roles;



schedules and allocates resources to requests based on the run time availability of resources and defined goals;



executes (enacts) the processes identified by the due requests; and



stores the system's operational and state information persistently for recoverability and historical-trail reasons.



The CORBA bus 16 is the part of the system that is used to:



plug-in tools (software applications) that execute work items forming part of processes;



allow client objects and server objects to communicate;



allow the interaction of the components of the build time, run time parts, plug-in tools, and ORB services.



CORBA



CORBA is a dynamic distributed architecture framework which may be used to efficiently combine components into systems. The most recent specification of CORBA is CORBA 2.0. The services which run on CORBA are specified in the CORBAServices: Common Object Services Specification, produced by the Object Management Group, Inc. in Nov. 22, 1996. There are various commercial products available which implement CORBA 2.0, such as IONA's Orbix 2.2.



The CORBA bus provides two main components, namely an IDL (interface definition language) and an ORB (object request broker). CORBA uses IDL contracts to specify boundaries of components residing on the bus and the component's contractual interfaces with potential clients. The CORBA IDL is purely declarative. This means that it provides no implementation details. IDL provides operating system and programming native independent interfaces to all the services and components that reside on a CORBA bus. It allows client and server objects written in different languages to



inter-operate. A client object is either a system process, or an entity (object) within a system process that invokes a method (a member function) on a representative object (proxy) of a server object to request a set of specific actions. A server object is either a system process or an object that a) has an IDL interface, b) is plugged-in to the bus, and c) satisfies a request. Server objects are packaged as binary components that remote clients can access via method invocations. Client objects need to know the IDL interface that a server object publishes.



The object request broker (ORB) is the object bus. It lets objects transparently make requests to and receive responses from other objects located locally or remotely.



The GPAE engine (10 in FIG. 1) can be considered as a client of a set of object servers, the servers being the tools provided by the applications/components on the processing nodes 18, when the engine requests the tools to execute, using a set of in attribute values of activities, and to capture the tools's execution statuses in a set of activities' out attributes.



The build time part 22 can also be considered a client of the run time part 24. The ORB 16 receives client requests from the build time part 22 and dispatches them to the corresponding server(s) in the run time part 24 to service the requests.



In CORBA, a client/server application becomes a collection of collaborating components. Another example of a runtime object interacting with a server buildtime object is the instantiation of a process instance. The process instance being instantiated asks the process definition (a buildtime object) for its graph information (network of work items). The process definition returns the requested graph and the process instance copies it to itself.



A logical view of the CORBA bus is shown in FIG. 2. A number of client objects 40 are shown each connected through a respective IDL interface 42 to the ORB 44 which is in turn connected to a number of server objects 48 through another respective IDL interface 46.



For one object to request something from another object, it must know the target object's IDL interface. CORBA has an interface repository containing definitions of all these IDL interfaces. It also contains metadata that lets components discover each other dynamically at run time. This makes CORBA a self-describing system. As an example of what one object might request from another, a GUI (client object) can query the run time part of GPAE (server object) about the status of a specific request instance. Request instances are named components which are stored persistently in GPAE's ObjectStore based repository.



The client objects 40 do not need to be aware of the mechanisms used to communicate with or activate the server objects 48. A CORBA ORB's client/server middle-ware provides the following main benefits: static and dynamic method invocations, high-level language bindings, self-describing system, local/remote transparency, built-in security and transactions, polymorphic messaging and coexistence with existing systems.



Using a CORBA bus in the process automation system according to this embodiment of the invention provides the benefit that new software applications that execute activity and process instances can be registered and added to the bus at run time. This allows the run time "plug-in" of new process definitions and their execution without affecting the overall functionality or availability of the system at run time. This is important because an authorized role can use this capability to test/introduce a new process in a "testing" environment, thus not impacting production. Another benefit is that a new implementation for an existing GPAE service can be added and tested at run time. The client is not aware of a servers' implementation.



In addition CORBA 2.0 specifies an Internet-inter-ORB protocol (IIOP). The IIOP is basically TCP/IP with some CORBA-defined message exchanges that serve as common backbone protocol.



The Object Management Group (OMG) has published standards (CORBAServices) for fifteen object services; the ones used by GPAE are the naming service, the event service, the life cycle service, the security service, and the trader service, and these will now be briefly described.



The naming service allows components residing on a bus to locate other components (distributed objects) by name. GPAE uses this service to register servers (e.g., persistent server, process instance servers) with the naming service at bootstrap time and dynamically at run time. The run time registration of servers is used to support the ability to extend the services provided by GPAE at run time.



The event service allows distributed objects to dynamically register or unregister interest in specific events. The event service defines an object called an event channel that collects and distributes events among components that know nothing of each other. This service is used in the GPAE to implement a) a model view controller (MVC) pattern between the work item definitions/runtime entities (model), the controller (the GPAE's APIs) and the GUI (view), and b) the notification of the outcome of processes to work list menus or to interested parties. The Controller aspect of the Model View Controller (MVC) pattern is the GPAE's Application Programmatic Interface (API). This API serves as a programming interface between he GUI (the view) and the GPAE Build-Time/Run-Time objects (the model). It is responsible for interpreting events from the view and sending appropriate messages to the model. It then tells the view to update itself accordingly based on returned values from the messages sent to the model. The pattern interactions can be illustrated as follows:



View (GUI)<==>Controller (API)<==>Model (BuildTime Objects). The "<==>" symbol represents an interaction between two entities. The term "controller" should not be confused with the controller (process instance) to be discussed later. The use of the word controller here is a historical one used to describe this MVC pattern.



The life cycle service defines operations for creating, copying, moving and deleting components on the bus. This service is used to implement the factory pattern (Gamma 95).



Factories are used to create instances of objects in their respective servers. From a client perspective CORBA objects are often created by invoking normal CORBA operations on factory objects. Factory operations activate CORBA objects (server citizens) as well.



Activation is the act of starting an existing CORBA object to service requests (method invocations). The opposite operation to activation is called deactivation. Deactivation is the act of shutting down an active CORBA object. For example, if an activity instance object must be activated then the following generic algorithm is used: (a) use a factory finder to find an activity instance factory in the activity instance server, and then (b) send a create message to the factory; the invocation of this message creates and activates an activity instance object within the activity instance server.



Each GPAE (CORBA) server has a factory finder. The factory finder can be used to find a factory responsible for the creation of objects of a specific type. For example, a factory finder in the Definition Server is used to find either a process definition factory or an activity definition factory. A server that supports multiple CORBA objects, like the Definition Server is known as a Shared server. Most GPAE servers are both shared and multi-threaded servers.



The security service provides a complete framework for distributed object security. It supports authentication, access control lists, confidentiality, and non-repudiation. It also manages the security policy. The implementation of the GPAE uses this service to control and audit access the read/write access stored information such as work item definitions, operational data, and historical data.



The trader service provides a "Yellow Pages" for objects; it allows objects to publicize their services and allow clients to find them based upon which services the client needs. For example, the resource allocator 78 uses this service to find a resource that satisfies a set of agent's constraints (e.g., CPU target).



A more detailed block diagram of the process automation system according to this embodiment of the invention is shown in FIG. 3. The system includes the CORBA bus 16, the GPAE 10, and a number of plugged in tools (running on processing nodes) 18. The GPAE 10 includes the following blocks, all of which are connected together through the CORBA bus 16: GPAE provisioning and query 70, WWW(IIOP) 72, work list menu 74, scheduler 76, resource allocator 78, process instances 80, repository 82, and object services 84. Each of these blocks will now be briefly described with further details being provided later where appropriate.



The GPAE provisioning and query block 70 provides a "query view" of process instances 80, enabling an authorized role to find out about request progress, operational data (e.g., start time of execution of a process, its duration, and outcome), and historical data (errors recorded persistently). Historical data is used to find patterns of errors and then conduct proper root cause analysis to improve processes.



The WWW (IIOP) block 72 provides an interface to the WWW as described previously. IIOP specifies how a set of message formats and common data representations for communicating between ORBs are exchanged over a TCP/IP network. IIOP makes it possible to use the Internet itself as a backbone ORB through which other ORBs can bridge. In addition, IIOP also defines a format for interoperable object references (IORs).



The work list menu 74 is a list of activities to be performed by roles.



The scheduler 76 is a multi-threaded server. It has the responsibility of producing a schedule that considers the available resources (processing nodes and human resources), an activity's static constraints (e.g., computer's architecture, swap space, disk space), an activity's dynamic constraints (e.g., load average), and overall process goals, such as load balancing, round-robin use of resources, the minimization of the utilization of a set of resources, and the maximization of the utilization of another set of resources.



A schedule produced by the scheduler 74 provides to activities forming part of a requested process instance 80, a tuple composed of a host and a time. The host is where an agent (tool or role) associated with an activity executes; and the time is the date and time when the agent will execute.



The termination of the execution of an activity triggers an event for the scheduler 76. The scheduler 76 interacts with the resource allocator 78 to request a resource that meets the next activity's constraints.



The resource allocator 78 is a server which has a dynamic view of the available resources. Resources can be modelled and characterized in terms of static and dynamic properties. The resource allocator 78 uses the CORBA's trader service to find resources that support a set of static and dynamic properties. Static properties are those related to the hardware and operating system of a computing node. Dynamic properties are those related to the runtime state of the computing node; these include load average, utilization factor, number of available file descriptors, available memory, and free disk space. The scheduler 76 and the resource allocator 78 are preferably based on constraint-based mechanisms provided by ILOG.



The process instance 80 is a work flow "engine" responsible for the execution of its contained sub-processes and activities in serial or parallel modes. The process instance 80 invokes the "execution" method on activities. There is a process instance per enacted process definition. In CORBA, the process instance is a CPIS (CORBA process instance multi-threaded server). There is a pool of CPISs that get recycled according to the number of incoming requests to GPAE. The process instances 80 start the set of tools associated with activities at the time and place specified by the schedule.



The repository 82 is where process definitions, activity definitions, attribute definitions requests, process instance data, activity instance data and operational and historical data are stored persistently.



The object services block 84 includes the previously described naming service, event service, life cycle service, security service and trader service.



Users 86 are capable of interacting through GUIs (graphical user interfaces) on user workstations 88. The user workstations 88 can be connected to a LAN or WAN inter/intra computing networks. Through the GUIs, users are able to interact with the GPAE provisioning and query block 70, the WWW (IIOP) block 72, and the work list menu 74.



The ORB 16 may for example be IONA's Orbix 2.2 implementation of CORBA 2.0 and its object services. For this implementation, each workstation where a CORBA server runs has to have an Orbix daemon running. The Orbix daemon represents the activation part of the CORBA ORB. All persistent data (definitions, operational and historical data) may for example be stored in an object-oriented repository built on top of an OODBMS (object oriented database management system) such as ObjectStore 5.0 from Object Design Inc. The scheduler may for example be implemented using ILOG's products Schedule and Solver 3.2. The GUI may for example be developed using ILOG's GUI Builder and JAVA's AWT class library. As part of the implementation strategy, a set of design patterns have been implemented. The design patterns used in GPAE include:



Model View Controller (MVC)



This isolates a model object from the view through the used of a controller which reacts to events from the view and sends appropriate messages to the model. The controller then tells the view to update itself based on the result of the messages sent to the model. The GPAE, the MVC model is implemented using CORBA's event services.



Factory



This abstracts life cycle operations (create/copy delete/move & activation of distributed objects).



Abstract Server



It is possible to create abstractions that are fixed and yet represent an unbounded group of possible behaviours. The abstractions are base classes, and the unbounded group of possible behaviours is represented by all possible derivative classes.



For example, if a client interacts with an abstract server class, and it requires to use a different server, then a new derivative of the abstract server class can be created. The client can remain unchanged.



Strategy



This defines a family of algorithms, encapsulates each one, and makes them interchangeable, Strategy lets the algorithm vary independently from the client that uses it. Different strategies can be swapped in and out as need to be. This design pattern is used to implement the ability to change run time policies in real time.



Observer



This defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.



The ORB uses two repositories: the Interface Repository (IFR) and the Implementation Repository (IR); they are not considered CORBA services but CORBA'a components. The IFR is an on-line database of object definitions (i.e., a container of IDL type definitions). The ORB uses the IFR for the following reasons: (a) to translate objects that go across heterogeneous ORB's; (b) to provide to clients the ability to obtain the interface information of any object; and (c) to allow clients to create "on-the-fly" method invocations. The IR is a storage place for the implementation definitions, such as information about which server implementations are installed in a given system.



The notification process shown on FIG. 10 may consist of a notification activity and other activities not shown in FIG. 11. When the system bootstraps all the service providers (servers) are registered with the naming service and their interfaces are stored in the interface repository (IFR).



FIG. 4 identifies the main control and data flow aspects of the buildtime and runtime parts of GPAE, including interaction with agents. A user is first presented with an introductory main panel such as shown in FIG. 5. The main panel of FIG. 5 presents the user with three main options, these



being "File" which when selected allows a user to select an exit option (not shown) or to select a query option (not shown), "Definitions" which allows process definitions and related items to be defined or edited, and "Enactment" which allows a user to create a request for a process definition to be instantiated. If an authorized role selects the query option then a query window appears. The query window is described below with reference to FIGS. 7a and 7b.



The steps appearing in FIG. 4 can be classified into build time steps (executed by the build time component of GPAE as illustrated in FIG. 1) and run time steps (executed by the run time component of GPAE as illustrated in FIG. 1). The build time steps can be further broken down into steps forming part of a process definition stage and steps forming part of a request creation stage. The run time steps can be broken down into steps forming part of a process enactment stage, and steps forming part of a process query stage.



During the process definition stage, item 1 represents three buildtime steps consisting of the creation, edition, and approval of a process definition and its components by an authorized role. Further details regarding process definition are provided below with reference to FIGS. 9 to 16.



Item 2 represents four buildtime steps, these being the creation of a request, the query of another request to reuse its data or the query of process definitions, the edition of a request (data-filling of the request attributes), and the selection of a process definition, all done through the provisioning interface (part of the GPAE provisioning and query block 70 of FIG. 3). After a request is assembled and saved, it is submitted for enactment. During the request creation stage, an authorized role creates a request instance and ties it to a process definition. The data (in parameters and out parameter values) are specified at this stage, as well as the desired execution frequency, roles to be notified about the outcome of the request (also considered an event) and its priority. Request creation is described in further detail below with reference to FIG. 17.



Item 3 illustrates the flow of a request to the scheduler. Now the request has entered the process enactment stage.



In item 4, the scheduler produces a schedule based on item 3 and creates a process instance (that contains a copy of the process definition) and allocates a process instance server to enact the process instance at the date and time the request is due. The scheduler has a dynamic view of the state of the available resources (e.g., human and computing nodes). More specifically, during the process enactment stage, when a request is passed to the scheduler, the scheduler knows about: a) the available resources, b) the schedule of all the requests submitted to the system, c) the requests' priority, and d) the request's due date-time. Based on this information, applying constraint propagation logic the CORBA scheduler produces a near optimal schedule. This schedule specifies when and where the first work item of a process should start executing.



The process instance server is responsible for the navigation and pruning of the graph of work items that is instantiated from the process definition. The process instance server contains a deep copy of the graph captured in the process definition. When multiple entities have a deep copy of some data, the entities have their own copy of the data; they do not share the data. If the data of one entity is modified, the other entity's data is not modified.



In item 5, a particular process instance server is executing a set of activities. The process instance server does this by launching tools at the date-time and on computing nodes specified by the schedule. To invoke a particular work item forming part of a process, an activity instance is created for the work item. Each activity instance invokes an "execute" method on a specific multi-threaded tool manager. A tool manager plugs a software application (a tool) into the CORBA bus. When the tool manager receives the "execute" invocation, it launches the tool (using the ORB) on the processing node specified in schedule. The tool executes and returns the outcome of the execution to the activity instance. The activity instance in turn returns the status of its execution to the process instance.



Tools that are plugged into the GPAE CORBA bus need to support an interface which allows GPAE to execute, suspend, cancel, and resume these tools. This interface is called the TM (tool manager). Tool execution requires an exchange of data between the tool manager and GPAE. Input to and output from a tool that interacts with the TM are exchanged through sequences of in attribute and out attribute objects. These are CORBA objects which encapsulate a name-type-value triad. Resources required by the tool (such as type of platform, disk space . . . etc.) are requested from GPAE, using the TM, and supplied to the tool as a sequence of resource objects. An example should clarify the above. Suppose there is a mailer legacy tool which sends an E-mail message to a set of recipients. A tool manager implementation to wrap this tool will require the following in attributes: sender's E-mail address, recipients' E-mail addresses, title of message, body of message. The tool manager will indicate the outcome of the execution (success or failure) using an out attribute called status. Additionally, the tool manager requests processing nodes on behalf of the tool: e.g., an HP-700 series computing node, to execute the tool, and a computing node that is connected to the inter/intra-net to interact to a global mailing system. When GPAE sends an execute request to the mailer's tool manager it will supply it with the sequence of required in attributes and resources that correspond to the requested processing nodes. The tool manager will then execute the tool on the supplied resources and collect its exit code. On finishing execution, the tool manager deposits the outcome of the mailing request into the status out attribute.



The process instance checks the conditions for the next set of activities. If an activity needs to be executed then it interacts with the scheduler to determine when and where it should be executed. If instead, the set of work items have been exhausted, then the process instance terminates and communicates the state of the termination to the request.



The request multi-casts the termination event and any interested parties are notified. This notification mechanism uses the CORBA event service. An authorized role can receive notification upon the occurrence of an event by means of a set of notification means. These notification means may include for example E-mail, electronic pager, and a work list window. When a CORBA object (sender) multicasts messages to other CORBA objects (receivers) plugged-in to the bus, it means that the sender communicates indirectly with the receivers by sending a message that a set of receivers will receive. The receiver determines what event it is interested in receiving and what it will do with the information it receives. In the terminology of the CORBA event service, the sender of a message is a supplier and the receiver a consumer. The event service allows objects to dynamically register or unregister their interest in specific events. A notification is a message an object sends to interested parties informing them that a specific event occurred. In GPAE, a set of work list menus are notified by a process instance about an activity instance error event. When a work list receives this event it adds the name of the activity instance and its (error) status to a list, ready to be displayed by an authorized role. The suppliers produce events; the consumers process them via event handlers. An event channel is an intervening object that is both a supplier and a consumer of events. It allows multiple suppliers to communicate with multiple consumers asynchronously (multicast) without knowing about each other. For example, in GPAE, a process instance pushes an activity instance error event to an event channel, and the event channel pushes the event to a set of work lists. A process instance is not aware that the event channel is pushing its event to other CORBA components or to work list menus. In GPAE's implementation, event channels are registered with CORBA's naming service.



The notification mechanism/service is event based and is responsible for multicasting events. Those parties interested in specific events are then notified. An interested party can register interest on an event (e.g., the successful execution of a process) and can also register the action to be performed upon the arrival of the event. One application of this service is the creation of reports that are posted in the Internet for its global access by authorized personnel. Another usage of the notification service is the one used by the work list menus. Work list menus, such as the one shown in FIG. 6, are updated by the notification service to notify specific roles about the set of tasks (manual activities) that need to be completed before deadlines. The block that does the notification is represented by the event service 84 in the block named object services. As explained previously, GPAE uses the CORBA event service to implement the notification service. The use of this service not only allows the notification of events to interested parties but also enables the event driven capabilities of GPAE.



Manual flow happens, for example, when the execution of an activity triggers an event that requires manual intervention (e.g., an unexpected error in the execution of a tool). In this case, the event will be multi-casted to a work list menu such as shown in FIG. 6 for example. An authorized role, who may have been notified, may access the work list (in-tray) menu. The role uses the work list to locate the request that contains the activity that triggered the event. At that point in time, the role has a set of (work list) choices which include cancelling the request, fixing the problem and restarting the request, fixing the problem and restarting the activity, and ignoring the problem and asking the request to continue. The selected choice "tells" the process instance contained in the request to take an action according to the selected choice.



In item 6 the process instance server is shown storing the status of the request (as well as any relevant operational data) in the repository. This information will then become available for query.



During the process query stage (which occurs concurrently with the process enactment stage) an authorized role can query the progress of a request, a process instance, or an activity instance. Item 7 illustrates the interaction between a CORBA query manager (part of the GPAE provisioning and query block of FIG. 1) and the repository. Item 8 shows the response of a query from a query manager flowing back to the query (provisioning interface).



A particular query may be defined using a screen display query window such as illustrated in FIG. 7a for example. The query window allows an authorized role to define queries based on a) filters using regular expressions, and b) entities (definitions and requests) that filters are applied to. The format of a query is: <Entity><filters . . . >. Filters can be specified either by generic regular expressions or using specific filter dialog windows such as shown in FIG. 7b with specific options (filters) according to different types of entities such as process and request. A filter dialog consists of an ordered list of fields that are displayed in the query window. For each field there are two columns indicating the sort-order and method (ascending or descending), and two columns for the filter. Changing the method that the list in the query window is sorted is accomplished by dragging and dropping the sort-order numbers. The filter dialog will then be redrawn with the fields in the new order. To change the method of sorting, an authorized role changes the check box beside the field name. To set a filter, beside the field name, a role chooses the operator ("<", "<=", "=", "!=", ">=", ">", "contains") and enters the values. For some fields not all operators will apply. For some fields there may be specific values, e.g., "now" for fields that contain a time. The contents of a filter can be saved to a file using file-Save or file-Save as, and retrieved from a file using file-Open. When the contents of the filter dialog are to be applied to the query window, the OK button should be pressed. To not use the contents of the dialog, press the cancel button. Pressing either button will close the dialog frame. Pressing the apply button, will update the query windows contents, but the dialog will remain. The window named process monitor shows relevant fields for process instances. The window named request monitor shows relevant fields for request entities.



This results in ViewRequestExecution window display such as illustrated in FIG. 8a. This window displays the results of a query that uses either regular expression based filters or the filters shown in the request monitor filter window (FIG. 7b). The request query window has a button that can be pressed to access the filters. The description of the named columns of FIG. 8a are as follows: request: the name of the request instance; Process: the name of the requested process instance; Activity: the name of all the activity instances under the requested process; Status: the status of all the activities (e.g., executing, cancelled and pending, cancelled and terminated); Out parameters: shows in a menu such as the example of FIG. 8b the output attribute values for a selected work item.



Process Definition



There are many ways by which process definitions for use with the process automation system may be created. One preferred method of process definition creation will now be described with reference to FIGS. 9 to 16.



A process definition may be created using a GUI such as shown in FIG. 9. A process definition includes process description information 150, attribute definitions which include in parameters 152 and out parameters 154, pre conditions 156 and post conditions 158 and a graph pane 160 of work items.



The graph 160 of a process definition consists of one or more work items connected with links. A work item may be another process definition (a sub-process which is itself defined) or an activity definition, an activity being the unit of atomic work. A palette symbol menu 162 for process definition includes four palette items namely a link 163, a square 164, a circle 166 and an arrow 168. The selection of each of these items allow actions on the graph pane as follows: a) arrow 168: its selection allows a user to select and double click on graph components (circle, square, link) in the graph pane (160) so as to edit them or to move them around in the graph pane; b) Circle 166: allows a user to draw an activity definition symbol by selecting it, dragging it and dropping it in the graph pane; c) rectangle 164: allows a user to draw a process definition symbol by selecting it, dragging it and dropping it in the graph pane; d) link 163: allows a user to draw a link between two graph components by clicking both an origin work item and a destination work item in the graph pane.



A process definition can nest a set of process definitions in a linear or recursive manner. The process definition menu may be used to navigate and edit a containment hierarchy of processes and activities.



A link represents the order of potential execution of two work items (origin and destination) and is represented by an arrow connecting the two work items. The work item at the tail of an arrow (origin work item) executes first and then the work item pointed to by the arrow (the destination work item) may execute depending upon whether the conditions on the incoming links, the post-conditions on the origin work item(s), and the pre-conditions of the destination work item(s) are satisfied.



To create a graph, the symbols (circle, square and link) in the palette symbol menu may simply be selected, dragged and dropped on the graph pane 160. A particular work item in the graph is associated with either a process definition or an activity definition depending on the symbol used in the graph for the work item. By double clicking on the work item, an entity to be associated with that work item may be selected using a menu such as the pop-out work item properties menu, shown on FIG. 10. In this example, the work item indicated by 170 has been selected by double clicking on the circle. In the resulting work item properties menu of FIG. 10, the work item has been given the name "Cuttape". It is then associated with a particular activity definition by inputting an activity definition in a field within a window entitled "workflow definition". By clicking on the "select a work item" icon, a menu listing available activities such as shown in FIG. 11 will pop up allowing a user to select an activity definition from the list. Similarly, by clicking on the work item which is a process definition, a work item properties window would pop up, and a



list similar to that of FIG. 11 would pop up, but which contains a list of process definitions. In this manner all of the work items in the graphical display are associated with process definitions or activity definitions.



To set the conditions on the links shown on the graph pane 160 of the process definition menu (FIG. 9), a role double clicks on a link; this pops out a transition properties menu such as shown in FIG. 12. The transition properties menu is used to capture the conditions on a transition (link) between two work items, based on relations and values of in parameters and out parameters. This menu is also used to capture the explicit propagation rules which determine which output parameters of a given work item are to become input parameters for another work item.



FIG. 12 shows the menu used to capture the properties of transitions. A transition specifies the attributes of a link between two work items. FIG. 12 also shows an example of the transition from an "Upload" activity (171 in FIG. 9) to a "Cuttape" activity (170 in FIG. 9). The condition field allows the capture of a condition on the transition. The syntax allows "OR" and "AND" expressions and more generally is of the form: <attribute> operator <value> where attribute is an out attribute of an activity, operator is any of ("<", "<=", "=", "!=", ">=", ">"), and value is an integer. For example (rc!=0). The propagate field allows for the capture of the propagation rules. The description field allows the capture of meaningful documentation about the transition (e.g., to describe the purpose and meaning of a transition).



Attribute propagation rules: the attribute propagation rules contain implicit (default) and explicit propagation rules. These propagation rules are entered by an authorized role at build time and enforced at run time by a process instance (PI). A PI assigns the proper values to the in and out attributes of activities before and immediately after the enactment of an activity. The in attribute default propagation rules are: a) An in attribute gets the value from its predecessor work item's (parent's) matching out attribute name. b) If an attribute matching name is not found then the search is done with respect to the containing process. c) If an input matching name is not found in the containing process then the value for the in attribute is set to a default value stored in the work item's definition. An explicit input propagation rule overrides the default rules. The syntax of an explicit propagation rule is as follows: attribute.sub.-- 2=attribute.sub.-- 1 that is, the value on the right of the assignment operator (attribute.sub.-- 1) is copied to (by value) to the left of the assignment operator (attribute.sub.-- 2). According to this syntax, attribute.sub.-- 2 specifies the name of an in attribute of a work item (e.g., activity.sub.-- 2) associated with a work node in a process definition (ProcessDef.sub.-- x), and attribute.sub.-- 1 specifies the name of an out attribute of a work item (e.g., activity.sub.-- 1) associated with a work node in a process definition (ProcessDef.sub.-- x).



Explicit out attribute rules for a process are defined on the final links in the process instance's graph. They have the following format:



<vertex.sub.-- name>.<workItemName>.<attrDefnName> where vertex.sub.-- name and work node are used interchangeably.



For all out attributes of the process, the process instance does the following: If an explicit out attribute rule exists, then the value is set according to that rule; If an explicit rule does not exist, then it follows the implicit rules which are: Find the same attribute name in the out attributes of the previous work item instances which have been executed and have a link with a true condition into this node. If found there then take the value from the first one found, and if not found there, then it checks the containing process in attributes and if found there then take that value.



For activities, if an out attribute was not set explicitly, and an in attribute exists with the same name, that value will be copied to the out attribute. The value copied to the out attribute is taken from the first work item's in attribute matching name, according to a left to right graph traversal rule.



An activity definition may be created or amended using a menu such as shown in FIG. 13. An activity definition is the definition of an atomic unit of work to be executed by an agent (a role or a tool). A particular activity definition to be opened and edited can be selected using a GUI menu such as the menu shown in FIG. 14. The activity definition GUI menu of FIG. 13 is similar in some respects to the process definition menu of FIG. 9. It includes activity definition description information 180, attribute definitions which include in parameters 182 and out parameters 184, and pre conditions 185 and post conditions 186. It also includes a field 187 to select a tool (software application) to execute the activity, and includes a start mode field 188, and a finish mode field 190. The start mode and finish mode describe the degree of automation when triggering and terminating an activity. There are two automation modes: automatic mode is fully controlled by the workflow engine, i.e. the engine proceeds executing the workflow after e.g. an application implementing the activity has properly terminated and returned control. Manual mode requires user interaction, i.e. control is passed to the engine (process instance) to proceed executing the workflow only after an explicit role sign-on for termination of this activity. The automation modes can be applied to the start and end of an activity.



Start mode: describes how the execution of an activity is triggered. The default start mode is automatic in which case the execution is triggered implicitly by the system. Alternatively, it may be manual which requires the execution to be triggered explicitly by the end user.



Finish mode describes how the system operates at the end of the activity. A finish mode of automatic results in an automatic return when the invoked application finishes control, and a finish mode of manual requires the end user to terminate the activity explicitly.



An attribute definition may be created and or amended using a menu such as shown in FIG. 15. FIG. 15 shows the attribute definition menu. Attribute definitions are used to specify the name, type, default value, and description of an attribute. An attribute is similar to a programming typed variable that holds data. An in attribute definition specifies the input parameter for a work item; an out attribute definition specifies the output parameter for a work item. A name uniquely identifies an attribute definition; a type defines a structure type (e.g., integer, string, union, etc.); a value is a data value that fills the defined type holder; a description explains the purpose of the attribute definition.



For example, FIG. 15 shows an attribute named "display" which can be used by an activity to display some information on a specific computing node's terminal display (i.e., bcarh8dd:0.0).



To capture the process definition, the implementation of the buildtime part is preferably compliant to and extends the Workflow Process Definition Language (WPDL) adopted by the Workflow Management Coalition (WfMC 97). A process definition can be considered as a static entity, which becomes dynamic when an instance of the process definition is created, scheduled and enacted by the GPAE's runtime part 24.



By way of example, a process definition will be described for a process used to compile software modules, execute a loadbuild, store the loadbuild output results in a repository and notify interested parties. This will be referred to as the COMP.sub.-- LDBLD process (compile and loadbuild process). A process definition graph for COMP.sub.-- LDBLD is shown in FIG. 16a and consists of four main sub-processes, these being a compile sub-process, a loadbuild sub-process, a store sub-process, and a notify sub-process. For simplicity, links with error conditions are not shown on FIG. 16a.



The compile sub-process extracts source code from a version control repository, and compiles in parallel on multiple resources the S/W modules, considering dependency rules.



The loadbuild sub-process executes after the successful completion of the compile process. It takes the output of the compile process as its input (according to the work item attributes' propagation rules) and a set of functional inputs, and generates an initialized load (an executable).



The store process executes after the successful completion of the loadbuild process. It stores the generated executable into a repository for its worldwide global access (once the status of the load is set to "Released").



The notification process notifies those roles that registered interest about the event regarding either the successful completion or failure of the process.



In FIG. 16b, a further breakdown of the store process of FIG. 16a is shown to illustrate activities, links and conditions on links. As described previously, each work item (activity or process) contains in attributes and out attributes, as well as pre and post conditions. In addition, a set of explicit and implicit rules (default rules) specify the direction of propagation of out attributes of a set of work items to in attributes of another set of work items. A process definition may contain references to sub-processes, separately defined, which make up part of the overall process definition. For example, the store process detailed in FIG. 16b contains the subprocess "admin" 303. It is the process definition which is interpreted by the engine (i.e., a process instance), acting as a template for the creation and control of instances of that process during process enactment.



The store process shown on FIG. 16b consists of a network of activities and their relationships 302, criteria to indicate the start 300 and termination 301 of the process, and information about the individual activities, such as associated agents and attributes, etc. In this example, the store process starts by executing the activity "exist load". The "exist load" checks the existence of a given load in a repository. If the output of this activity is "true" and a return code (rc) captured in an out attribute is also true then the "check out" activity is executed. If instead, the output of the "exist load" activity is false and a return code (rc) captured in an out attribute of "exist load" is true then the "check in" activity is executed. If the return code (rc) captured in an out attribute of "exist load" is false (rc!=0) then the "admin" process is executed instead. The arrows represent links between work items. The conditions on these arrows 302 aid a process instance (one of many GPAE distributed work flow engines) to determine what must be executed next.



The store process includes the activities "exist load", "check out", "check in" and the sub-process "admin". The activities are connected with conditional links. When the "Store" process is enacted, the activity "exist load" first executes. If the outcome of this execution is "true" then the "check out" activity will execute; if instead the outcome of the execution of the "exist load" activity is false, then the "check in" activity will execute. If any of the activities fail (the return code "rc" is different of zero) then the "admin" processes will execute. The admin process will then issue an event (not shown on the Figure) that will be received by the work list menu(s).



FIG. 17 is a modified version of FIG. 3 for the above described COMP.sub.-- LDBLD process. In this example, the plugged in processes (applications or agents available to execute activities) include compile tools 200, loadbuild tools 202, sanity testing tools 204, a source control repository 206, a software vault 208, software patching tools 210, and various version definitions 212.



The source control repository 206 is a tool which stores source code under version control. The compile tools 200 are tools which compile the source code to produce object files that correspond to a specific target computer architecture. The loadbuild tools 202 produce an executable binary file as the result of assembling object files. The sanity testing 204 tools execute a set of test suites that check the behavior of the executable under typical scenarios at run time. The software vault 208 is a repository that stores executables under version control. This repository is accessed by software distribution centres located in geographically dispersed regions to distribute the executables to interested parties. The software patching tools are used to fix problems detected in the executable by applying corrections to them and producing a new version (of that executable product) in the software vault 208. The other versions of tools 212 represent new versions of the above tool sets that are used to test new functionality (e.g., an optimization to the compile toolset) without affecting the production environment or existing processes.



These toolsets are plugged-in to the CORBA bus to execute a set of process definitions, similar to the one shown in FIG. 16a and FIG. 16b. Given the above, an operator can submit a request to GPAE to enact an end-end process that is executed by the described toolsets. The execution of a new proc

PatentNumber=6192397,BACKGROUND OF THE INVENTION



1. Field of the Invention



The present invention relates to the field of data communications. In particular, the present invention provides a system for establishing a master-slave relationship, at the physical layer, on a point-to-point link in a peer-to-peer network.



2. Background



Peer-to-Peer networks utilize a communication protocol such as Carrier Sense Multiple Access/Collision Detection (CSMA/CD). The philosophy of this type of network is that every device coupled to the network determines, on an independent basis, when to send information to another device coupled to the network. To summarize this process, when a device has data for transmission to another device on the network, the device checks the medium across which it intends to transmit the data for any existing traffic. If the device senses traffic on the medium, it waits until the medium is free of traffic before initiating transmission of its data. If the device does not sense traffic on the medium, then it attempts to send data across the network to the other device. If the sending device detects a collision during the transmission, it suspends transmission and waits a randomly chosen amount of time before attempting to resend the data by repeating the above process.



As the utilization of a peer-to-peer network increases, the number of collisions on the network increases, thereby reducing the overall throughput of the network. To address this problem, technology has developed various types of hardware capable of higher data transmission rates and has developed more efficient network software. Higher data transmission rates reduce the time period during which the data is on the medium for a given amount of data, thereby reducing the probability of a collision with data from another device.



Network software typically includes several layers of protocol. For example, in an Ethernet local area network, the network interface comprises: the physical layer, the media access control sublayer and the logical link control sublayer. The physical layer's function is to take data packets given to it from the media access control layer and place the packets on the medium to be delivered to a destination device. The carrier sense, collision detection functions to support the arbitration of access to the medium by the attached device.



Each device in a peer-to-peer network is a peer to other devices in the network. Thus, no device is considered to be "superior" to any other device on the network. As such, a master-slave relationship between devices is not typically supported in a peer-to-peer network environment. It is therefore desirable to provide a system capable of establishing a master-slave relationship (when such need arises), at the physical layer, on a point-to-point link in a peer-to-peer network.



SUMMARY OF THE INVENTION



The present invention provides improved performance in a peer-to-peer network by permitting the establishment of a master-slave relationship between any two devices at each end of a point-to-point link. By establishing a master-slave relationship, the master may provide control signals or other data to the slave for use by the slave.



An embodiment of the present invention provides a system for establishing a master-slave relationship at the physical layer between a first device and a second device in a peer-to-peer network connected by a point-to-point link. The system generates a first information which is associated with the first device. Additionally, a second information is generated which is associated with the second device. The first information is compared with the second information to generate a comparison result. Based on the comparison result, one device is designated as a master and the other device is designated as a slave.



Another feature of the invention provides that the generation of the first information and the second information is performed by the first device and second device, respectively.



A specific aspect of the invention transmits the first information from the first device to the second device and transmits the second information from the second device to the first device. Each device then compares the first information to the second information to determine which device is master and which device is slave. Since each device has the same data and the same criteria, their determination is expected to agree.



An embodiment of the invention assigns a particular value to each device. If the assigned values are unequal, then the assigned values are used to determine which device is master and which device is slave. If the assigned values are equal, then the first device selects a first random number and the second device selects a second random number. The first selected number is compared with the second selected number to generate a comparison result. Based on the comparison result, one device is designated as master and the other device is designated as slave.



BRIEF DESCRIPTION OF THE DRAWINGS



The present invention is illustrated by way of example in the following drawings in which like references indicate similar elements. The following drawings disclose various embodiments of the present invention for purposes of illustration only and are not intended to limit the scope of the invention.



FIG. 1 illustrates an exemplary network structure upon which the present invention can be implemented.



FIG. 2 illustrates a comparison of protocol layers between the ISO standard and the IEEE 802.3 standard.



FIG. 3 is a flowchart illustrating a method for designating one device as a master and one device as a slave.



FIG. 4 is a flowchart which more specifically illustrating a method for overriding a device's assigned designation as master or slave.



FIG. 5 illustrates a pair of devices coupled to provide a clock loopback function.



DETAILED DESCRIPTION



The following detailed description sets forth numerous specific details to provide a thorough understanding of the invention. However, those skilled in the art will appreciate that the invention may be practiced without these specific details. In other instances, well-known methods, procedures, components, and circuits have not been described in detail so as not to obscure the invention. Referring now to the drawings, in which like numerals represent like elements throughout the several figures, aspects of the present invention and the preferred operating environment will be described.



The present invention provides a system for establishing a master-slave relationship, at the physical layer, on a point-to-point link in a network. Thus, one device on the point-to-point link is designated a master and the other device is designated a slave. This master-slave relationship may be used to provide control signals, clock signals, or other data from the master to the slave.



In a particular example, the master-slave relationship may be used to provide a clock loopback function on a point-to-point link between the master device and the slave device. The clock loopback function allows higher data transmission rates, thereby reducing the probability of collisions. If one of the devices or ends on the link is designated as a master and the other as a slave at the physical layer, then the master can provide the clocking mechanism for both devices while the slave loops the clock signal back to the master. This configuration allows higher transmission rates on cabling that previously could not transmit data at these rates because of a high noise-to-signal ratio (due to the poor signaling characteristics of the wire). Additional details regarding clock loopback is provided below with reference to FIG. 5.



FIG. 1 depicts an exemplary network in which an embodiment of the present invention may be implemented. The network includes several End Devices 115, 120, 125, 130, and 135 (also referred to End Devices A through E, respectively). The End Devices may be any device capable of being coupled to a network, such as computer workstations. The End Devices 115-135 are connected to Central Device Units 105 and 110 using point-to-point links 145a-145e. Each Central Device Unit 105, 100 may also be coupled to one or more additional Central Device Units, thereby interconnecting all of the devices coupled to the Central Device Units. Although not shown in FIG. 1, End Devices may also be coupled directly to one another.



An example of transmitting data on the network of FIG. 1 is as follows: End Device A has data to transmit to End Device E. To accomplish this transmission, End Device A transmits data along link 145a to Central Device Unit 105. Central Device Unit 105 then transmits the data across link 150 to Central Device Unit 110. Central Device Unit 110 transmits the data along link 145e to the its destination at End Device E.



The present invention permits the establishment of a master-slave relationship between any two devices on a point-to-point link in a network. This includes the link between any of the Central Device Units and an End Device (links 145a-145e), between two End Devices (link not shown) or between two Central Unit Devices (link 150). A device in the context of this specification will be defined as either an End Device or a Central Device Unit that connects the end devices. Furthermore, although only five End Devices and two Central Device Units are shown, this is only for discussion purposes since any number of End Devices and Central Device Units may be incorporated into the network. In a particular embodiment of the invention, the End Devices and the Central Device Units are part of an Ethernet local area network (not shown).



FIG. 2 depicts a comparison of protocol layers between the International Standards Organization Open Systems Interconnect (ISO OSI) and Institute of Electrical and Electronic Engineers, Inc. (IEEE) 802.3 data communication standards as well as a breakdown of the physical layer in IEEE Std 802.3u--1995. FIG. 2 depicts two of the ISO OSI layers, the physical layer 210 and the Data Link layer 205. These are the two layers that perform the services required within a local area network. FIG. 2 also illustrates the comparable IEEE 802.3 protocol layers, commonly referred to as Ethernet, comprising: the Logical Link Control sublayer 215; the Media Access Control sublayer 220; and the Physical layer 225.



The Ethernet protocol layers are defined by a standard developed by IEEE and promulgated as IEEE 802.3. In IEEE 802.3u, the physical layer is divided into the following sublayers: the Physical Coding sublayer (PCS) 230; the Physical Medium Attachment sublayer (PMA) 235; the Physical Medium Dependent sublayer (PMD) 240; and the Auto-Negotiation sublayer 245. In one embodiment of the invention, the Auto-negotiation sublayer of IEEE 802.3 is utilized to perform the functions described below. This Auto-Negotiation sublayer provides a service within the physical layer for devices to detect the modes of operation supported by a device at the other end of a point-to-point link, determine common abilities and configure joint operation. Using the Auto-Negotiation sublayer, devices may establish services to each other that other devices on the network need not be aware of or even support. For additional information regarding IEEE 802.3 and the Auto-Negotiation sublayer, refer to "Media Access Control (MAC) Parameters, Physical Layer, Medium Attachment Units and Repeater for 100 Mb/s Operation," IEEE Std 802.3u--1995, Clause 28.



A clocking loopback function may be provided at the physical layer to make digital signal processing (DSP) more efficient, thereby allowing higher data transmission rates on cables or wires not previously capable of handling these rates. By looping back the same clock signal, both the master device and the slave device use the same clock signal. This common clock improves the ability of the DSP circuits to remove noise from the signals and, therefore, improve the flow of data. Noise removal is especially important when transmitting signals at high speed across lower quality wires or cabling; i.e., wires or cabling having a higher noise-to-signal ratio.



In a specific example, the present invention may be used in networks having previously installed cables or wires that are otherwise unable to take advantage of higher transmission rates due to the poor, or low quality, signaling characteristics of the cabling or wire. Prior to the present invention, users or administrators of these networks wishing to improve transmission rates may be required to install new cables or wires at considerable expense. In addition to the cost of the new wire or cable itself, the cable may be required to be installed in existing walls or structures. By using the invention described herein, existing cables having a poor transmission quality may be used without requiring the installation of new, higher quality, wires or cables.



FIG. 5 depicts a clock loopback function where a Device 500 ("Device A") is designated as the master and Device 505 ("Device B") is designated as the slave. Device A generates, or receives from an external source, its timing signal (clock signal). Device A uses this clock signal to transmit data using a Transmitter 515 across link segment 530 to Device B. A Receiver 525 in Device B receives Device A's data on link segment 530. Device B then loops back the clock signal received from Device A and uses Device B's Transmitter 520 to transmit it's data to Device A across link segment 535. Device A's Receiver 510 receives data with the clock signal used by Device A's Transmitter 515. Since Device A and Device B have established a master-slave relationship, both devices know which device will be using their own clock signal and which device will be looping back the other's clock signal.



Link segments 530 and 535 shown in FIG. 5 illustrate two separate data flows in opposite directions. This arrangement may be accomplished by using a multi-conductor twisted-pair cable or a fiber optic pair. Those skilled in the art will appreciate that various other types of wires and cables may be used as link segments 530 and 535 in FIG. 5.



FIG. 3 illustrates a procedure for designating one device as a master and one as a slave. The method of FIG. 3 starts at step 305 and continues to step 310 where the first device is assigned as a master or a slave. The procedure then continues to step 315 where the second device is assigned as either a master or slave.



In one embodiment of the invention, the assignments in steps 310 and 315 are performed during each device's initialization to the network. For example, as End Device A (FIG. 1) begins an initialization sequence to add itself to the network, End Device A sets itself as a master or a slave based on its default designation. This default designation as master or slave may be based on a preassigned status set within the device. This default designation may be modified by the network administrator. When Central Device Unit 105 is initialized, it sets itself as a master or slave based on its default designation.



Following the assignment as master or slave to both of the devices, the procedure of FIG. 3 continues at step 320 where the first device and the second device pass their assigned values to each other. In essence, each device transmits its default designation to the other device.



At step 325, having passed assigned values, a comparison is performed to determine if there is a conflict (i.e., both devices assigned as slaves or both devices assigned as masters). This comparison may be performed by both devices simultaneously.



If the assignments are not the same at step 325, the procedure stops at step 340 at which time the devices will continue with their network initialization or begin communicating in the standard network environment. Otherwise, the procedure continues to step 330 where one of the devices is selected to change its assignment. Additional details regarding the changing of assignments is provided below with respect to FIG. 4. After selecting the device assignment to override at step 330, step 335 continues by changing the assignment of the selected device such that it is different from the other device's assignment. The procedure of FIG. 3 then stops at step 340, and permits the devices to continue network initialization and begin regular network communication.



FIG. 4 illustrates in greater detail the selection and changing procedure steps (330 and 335) of FIG. 3. The procedure of FIG. 4 starts at 405. At this point there has already been a determination that a conflict exists in the assignment of master and slave status to the two devices. To resolve the conflict, the procedure continues to step 410 where the first device randomly selects (or generates) a number or other information. At step 415, the second device randomly selects (or generates) a number or other information. The first and second random numbers must be independent from one device to another to prevent the two devices from generating the same series of random numbers. Additionally, the random numbers are preferably selected such that it is equally likely that either device will be selected as master. These random number selections may be generated by any process available to the device.



A particular embodiment of the invention is described as generating random numbers to determine which device assignment will be overridden. However, those skilled in the art will appreciate that tokens or other information may be generated by each device and compared to determine which device assignment is overridden. Any token or information may be used, provided that the tokens or information may be distinguished from one another using a comparison mechanism.



The maximum value of the random number (e.g., number of bits) is a design choice recognizing that the larger the number the less probability that both numbers will be the same. Consequently, the larger the number, the more time and resources will be devoted to handling this random function as it will need to be transmitted to the other device. For example, one may not want to choose to design a random number that takes up four bytes of data because this data will need to be transferred to the other device and four bytes will take up more transmission time than a one byte random number. Similarly, one may not want to choose a random number that only takes up one bit because this increases the probability of both devices generate the same random number.



After both devices have selected a random number, the method continues to step 420 where both devices transmit their random number to the other device. At step 425, both devices compare the two random numbers. If the random numbers are equal, then the method repeats steps 410 through 425. If the random numbers are not equal, then, at step 430, both devices determine which device had the higher number. If the first device has a higher number, it's designated as master at step 435, regardless of how it was initially assigned. In this situation, the second device is designated as slave at step 440, regardless of how it was initially assigned.



If, at step 430, the first device was not higher than the second device, then the procedure continues to step 445 where the second device is designated as master and the first device is designated as slave. Again the designations in step 445 and 450 are performed regardless of how the devices were initially assigned.



One embodiment of the present invention includes using the Auto-Negotiation sublayer of the IEEE 802.3u standard. Referring to the network shown in FIG. 1, End Device A is added to the network so that it can communicate with the other network devices. Once the medium 145a is connected, End Device A begins to initialize itself onto the network. As part of the initialization process of IEEE 802.3u to establish the physical link, the Auto-Negotiation sublayer in the End Device A and Central Device Unit 105 will each transmit Fast Link Pulse (FLP) bursts on the link between the two devices. Within these FLP bursts include bits which allow devices to transmit operational modes supported by the devices. In this example, within a FLP burst, a device will set bits signifying whether it can support a master-slave function, whether its default designation is a master or slave and several bits devoted to a random number in case of a conflict arises where both devices' default designations are the same (i.e., both devices are designated as preferring master or preferring slave).



If a master-slave relationship is to be developed between End Device A and Central Device Unit 105, both devices send one or more FLP bursts to the other, carrying the information designated above. Therefore, End Device A and Central Device Unit 105 each have a complete set of information from both devices including whether both devices can support the master-slave function, the other device's default designation, and each other's random number. This information is used to resolve any conflicts in the default designation. Therefore, if either device lacks the ability to support a master-slave relationship, then no such relationship is established. If, on the other hand, both End Device A and Central Device Unit 105 have the master-slave function bit set, signifying that each device supports the master-slave function, but the devices have different defaults (i.e., one is a master and the other is a slave) then each device uses its default designation.



However, if both devices support the master-slave relationship and both devices have the same default designation, then they compare their own random number with the random number sent from the other device in the FLP burst, and the device with the highest value becomes the master and the device with the lower value becomes the slave. If the random numbers are the same, another random number is generated by each device and sent to the other in another FLP burst. Another comparison is performed and the procedure continues until the random numbers are not equal and a master and a slave has been established.



From the above description and drawings, it will be understood by those skilled in the art that the particular embodiments shown and described are for purposes of illustration only and are not intended to limit the scope of the invention. Those skilled in the art will recognize that the invention may be embodied in other specific forms without departing from its spirit or essential characteristics. References to details of particular embodiments are not intended to limit the scope of the claims.

PatentNumber=6198558,FIELD OF THE INVENTION



The present invention is directed to communication network access architectures and particularly relates to reducing the complexity of Optical Network Units (ONUs) in a Fiber-In-The-Loop (FITL) architecture by repartitioning some of the functionality to other elements of the network.



BACKGROUND OF THE INVENTION



In order to provide a communications network with the capability to accommodate current and future high bandwidth (broadband) services, optical fiber is being extended deeper into the network, towards the end user. The final link to homes or businesses in present-day systems is often still part of the installed distribution infrastructure, comprised mainly of twisted pairs of copper wire arranged in a topology of distribution cables and drop lines. For high-bandwidth applications, signal loss along a twisted pair increases with frequency and so the length of the twisted pairs must be kept small, leading to deeper penetration of the fiber.



In fact, it is known that the loss in decibels is nonlinearly related to the frequency of measurement (raised to the power 0.5 to 0.7, depending on the frequency and the type of cable) and hence a cable with a loss of, for example, 20 dB at 1 MHZ would have a loss of at least 28 dB at 2 MHZ, and at least 40 dB at 4 MHZ. Moreover, the signal loss in a twisted pair is also proportional to its length. It has been found that if the twisted pair is intercepted at a distance close enough to the end user so that high bit rates (on the order of 25 Megabits per second (Mbps)) can be successfully delivered, then, depending upon the complexity of the loop transmission equipment, the loop must be shortened so as to have a length of at most approximately 500 to 3,000 feet.



This upper bound on loop length has led to the development of new access architectures, known in the art as Fiber-To-The-Cabinet (FTTCab), Fiber-To-The-Neighbourhood (FTTN), Fiber-To-The-Curb (FTTC) or Fiber-To-The-Building (FTTB), all generically referred to as Fiber-In-The-Loop (FITL). The FTTC architecture has been the method of choice when considering the delivery of broadband services to a residential area consisting of single-family dwellings.



Traditional FITL implementations provide a system in which a Host Digital Terminal (HDT) controls the FITL network and is located at, say, a central office. The HDT is connected on one side to core network resources and on another side (the "access side") to a series of dependent Optical Network Units (ONUs) via a fiber-based link in the form of a Passive Optical Network (PON), a Synchronous Optical Network (SONET) ring or a number of point-to-point links. Finally, the ONUs communicate bidirectional data with the individual end users along the final (short) stretches of copper.



At such short maximum loop lengths of only a few hundred feet, the number of subscribers that can be served by a single ONU is rather limited. Therefore, the ONU must be small, simple and inexpensive for the service provider to buy and install so that its initial cost can be borne by the revenues from the small number of subscribers that the ONU serves. Furthermore, having only a small group of subscribers served by any one ONU requires that a very large number of ONUs be deployed to create a ubiquitous access network. This demands that the ONUs, once installed, be individually very cheap to maintain while allowing for future changes in subscriber service requirements. Since the ONUs are placed deep in the "outside plant", any requirement which causes these ONUs to be visited, either for repair purposes or for provisioning different subscriber services (by changing line card functionality), will result in a system that is too costly to operate.



Conventional prior art FITL architectures, FTTC in particular, have adopted the approach of installing shelves or frames of equipment, including service-specific line cards, in a protective housing on the curbside. Such ONUs are large, complex and require regular visits, in order both to modify services by changing line card types and to repair the units, since more complex ONUs are more likely to fail. Hence, the cost of deploying an array of service-specific line cards is prohibitively high in terms of capital cost (complex electronics, large cabinets) and also in terms of operating costs due to the need to visit the ONU so as to implement a service type change by replacing the line card type. Furthermore, installing cabinet-mounted equipment is often complicated by the unavailability of acceptable locations in residential areas. This becomes more critical as the loop length is shortened and ONU size is reduced to the point where ONUs are installed within subdivisions and not at their edges.



An alternative prior art approach consists of replacing the service-specific line cards with (somewhat more expensive) service-independent line cards that can be configured in software. These are primarily based upon the use of wideband analog front-end loop drivers, oversampling codecs, bit-rate-reduction (decimator) blocks and digital filtering components, also known as Digital Signal Processor Application-Specific Integrated Circuits (DSP ASICs). This combination of functions allows the service-specific functions of the line card to be implemented in software, which can be downloaded to the ONU from the HDT, thereby eliminating the need to visit the ONU to change the service type delivered to a subscriber.



This solution, also referred to as Service-Adaptive Access (SAA), has been adopted by Nortel in the development of its S/DMS Access Node, which can be deployed in a FTTC or FTTCab configuration. The ONU, also called an RDT (Remote Digital Terminal), consists of an array of service-dependent line cards, or alternatively service-independent line cards based upon on-card DSP processing and each using a DSP dedicated to that card, or possibly (in order to control cost) a mix of both types of line cards, in addition to common equipment for multiplexing the digitized signals, a control processor and an optoelectronic transceiver. The number of different line card types can be reduced by replacing some or all of the standard POTS (Plain Old Telephone Service) cards with SAA line cards.



When data flows from the subscriber into the ONU, (known as the "upstream" path), the S/DMS Access Node samples the input analog signal arriving on the twisted pair and puts it into a standard digital format prior to transmission from the ONU to the HDT. In the opposite ("downstream") direction, the ONU converts, for example, .mu.-law-encoded digital voice data into an analog format for delivery to a user's home. Unfortunately, the deployment of such ONUs, each comprising a set of service-independent line cards, has several serious drawbacks in the context of a FITL system with deep fiber penetration:



1) Cost



The DSP-based line card has a larger power consumption, complexity and failure rate, which translates into significantly higher system cost;



2) Size



The size of the ONUs has increased, making it more difficult to install them in locations close to the end user;



3) Complex software download



The ONU and access system at the HDT have to provide a high-integrity software download/verification path which requires a processor in each ONU for monitoring download integrity;



4) Initial servicing



The functionality of the individual line cards is such that the ONU must be visited each time a new subscriber is to be accommodated. The SAA cards do not allow "future-proofing", i.e. it is not possible to connect every loop to a line card (regardless of whether or not that loop was expected to go into service immediately) and then to remotely provision, or "initialize", that loop;



5) Efficiency



The DSP is placed on the line card and as such is dedicated to a single loop. Furthermore, it has to be dimensioned for the most stringent expected processing demands that can be encountered in the loop. In combination, this leads to the number of high-performance DSPs deployed being equal to the number of lines served. Thus for many service types, including low-bandwidth POTS (the most common), each DSP may be operating at a fraction of its full capacity. However, this spare capacity cannot be shared across other loops, leading to an effective increase in power consumption and total system cost.



It is important to note that reducing the size of the ONU by reducing the number of DSP-based SAA line cards per ONU does little in the way of mitigating the above disadvantages. In fact, partitioning the equipment into smaller ONUs with lower line counts per ONU results in an increased overall complexity since the simplification achieved on a per-ONU basis is more than offset by the increased number of ONUs that have to be deployed. As the ONU line count falls, the overall complexity of the ONU population required to serve a particular area or group of subscribers rises and has deleterious consequences on the mean-time-between-failures (MTBF) of the ONU population, requiring a higher degree of maintenance activity. This translates into more frequent on-site visits ("truck rolls") by the repair crew and requires more travelling to the increased number of ONU sites.



SUMMARY OF THE INVENTION



It is an object of the present invention to obviate or mitigate one or more disadvantages of the prior art.



In a fiber optic communication system comprising a host digital terminal (HDT) for connection to a core communications network and connected by optical fiber to at least one optical network unit (ONU) for interfacing to a plurality of different subscriber loops, wherein digital data travelling from the core network to one of the plurality of subscriber loops undergoes a change of format from one of a plurality of first data formats to one of a plurality of second data formats, and wherein digital data travelling from each of the plurality of subscriber loops to the core network undergoes a change of format from one of the plurality of second data formats to one of the plurality of first data formats, the invention may be summarized according to a first broad aspect as the improvement wherein signal processing functions for converting the digital data from any first data format to any second data format and vice versa are executed in the HDT.



In a system for accessing a core communications network, the system comprising a host digital terminal (HDT) for connection to the core network and connected by optical fiber to at least one optical network unit (ONU) interfacing to a plurality of subscriber loops, wherein the HDT comprises a digital switch matrix and a plurality of programmable digital signal processors (DSPs) connected to the digital switch matrix, and executing respective processing functions, the invention may be summarized according to a second broad aspect as a method of communicating data between the HDT and the at least one ONU, comprising: in a downstream direction, the switch matrix routing data received from the core network to selective ones of the DSPs; the DSPs performing respective processing functions, yielding downstream processed data; the switch matrix routing the downstream processed data to the at least one ONU; and in an upstream direction, the switch matrix routing data received from the at least one ONU to selective ones of the DSPs; the DSPs performing respective processing functions, yielding upstream processed data; the switch matrix routing the upstream processed data to the core network.



According to a third broad aspect, the invention may be summarized as a host digital terminal (HDT) for enabling bidirectional communication between a core network and at least one optical network unit (ONU) having a plurality of line interface units (LIUs), the HDT comprising a digital switch matrix, a plurality of programmable digital signal processors (DSPs) connected to the digital switch matrix for executing the signal processing functions; at least on first optical transceiver connected between the optical fiber and the switch matrix; at least one second optical transceiver for connection to the core network and connected to the switch matrix; and means to control the digital switch matrix so as to select, for each LIU, at least one first signal processing function to be executed by a first subset of the plurality of DSPs on data arriving from the core network through the at least one second optical transceiver and destined for the LIU, and at least one second signal processing function to be executed by a second subset of the plurality of DSPs on data arriving from the LIU through the at least one first optical transceiver and destined for the core network.



The invention may be summarized according to another broad aspect as an optical network unit (ONU) for enabling communication between a plurality of subscriber loops and a host digital terminal (HDT), comprising a plurality of substantially identical line interface units (LIUs) for respectively interfacing to the plurality of subscriber loops and each having an oversampling codec; an optical transceiver for connection to the optical fiber; and a bidirectional multiplexer connected between the optical transceiver and the plurality of LIUs.



BRIEF DESCRIPTION OF THE DRAWINGS



The present invention will be described with reference to the following drawings, in which:



FIG. 1A is a block diagram illustrating a prior art FITL communications network;



FIG. 1B is a block diagram showing a FITL communications network constructed in accordance with the present invention, including an exemplary inventive HDT and ONU;



FIG. 2A shows an exemplary data structure on the downstream fiber link of the prior art network of FIG. 1A;



FIG. 2B illustrates upstream data flow on the fiber link of the prior art network of FIG. 1A;



FIG. 3A shows an exemplary data structure on the downstream fiber link of the inventive network of FIG. 1B;



FIG. 3B illustrates upstream data flow on the fiber link of the inventive network of FIG. 1B; and



FIGS. 4A, 4B and 4C are detailed block diagrams illustrating three different embodiments of part of the HDT of FIG. 1B in accordance with the present invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT



Before the invention is described in detail the structure and function of the conventional prior art system of FIG. 1A will be described.



With reference to FIG. 1A, a fiber-based access system intended to provide FTTCab, FTTC or FTTB as part of a communications network consists of two main types of components, an HDT 1 and a plurality of ONUs 2 (only one of which is shown). Each ONU 2 has a plurality of Line Interface Units (LIUs) 3,27 connected to a bidirectional optical fiber distribution cable 4 via an intervening mux (multiplexer-demultiplexer) 5, a PON out station (PON-OS) 28, and an optical transceiver 6.



A number of different ONUs in the same vicinity are grouped together by virtue of their associated distribution cables being joined together at a passive optical splitter 30 which is connected directly by means of an optical fiber umbilical 4a to a transceiver 16 of the HDT 1. There may be a plurality of groups of ONUs, each group being connected to the HDT through a respective optical fiber umbilical and transceiver. Prior art configurations for the fiber link between the HDT and the multiple ONUs include the PON configuration shown in FIG. 1A, a point-to-point connection between the HDT and each ONU, as well as ring configurations with an optical transport ring passing from the HDT through each of the ONUs in turn and returning to the HDT.



The HDT 1 further comprises a digital switch matrix 17 connected to the transceivers 16, in addition to an operations, administration and maintenance (OAM) processor 18, a control processor 19 and a signalling processor 20, each of which are also connected to the digital switch matrix 17. The OAM processor 18 includes a communication port 200 by which it can receive control, provisioning and configuration instructions from the management layer of the core network 23 as well as return the access system operational and maintenance status to the network management system. Finally, a plurality of transceiver blocks 21 are connected between the switch matrix 17 and the core network 23.



Turning now to the structure of the ONU, each LIU 3 is connected on one side by a bidirectional signal path 23 to the mux 5 and on the other side to a respective subscriber loop 7 which is commonly a copper twisted pair. The LIU 3 performs the function of bidirectional communication of signals with the subscriber equipment in the appropriate analog format (e.g., 4 kHz voice for POTS, 2B1Q line coded signals for ISDN--Integrated Service Digital Network) over the intervening twisted pair 7; the insertion of suitable loop currents by an Analog Front End (AFE) 8; and the superimposition of a ringing signal when required (and its rapid removal when the line conditions change to those of an "off-hook" phone) via a ringing generator 9. The LIU 3 includes a loop status detector 10 to detect when the phone or other service is activated (this may include detecting modem tones or changes in d.c. (direct current) or a.c. (alternating current) conditions on the loop 7.



The LIU 3 usually includes a wideband digital one-bit delta-sigma oversampling codec 11 able to provide adequate bandwidth and quantizing noise performance when converting signals between the analog and digital domains, a decimator 12D which removes some of the excess upstream bandwidth from the oversampling codec 11, and an inverse decimator (or "interpolator") 12ID for converting downstream words into a high-rate bit stream. The multi-bit words are fed into (read from) a service-specific processor 14 implemented as a digital signal processing (DSP) engine which converts the upstream (downstream) oversampled and decimated data on the subscriber side 22 of the DSP 14 to (from) a standard format data stream on the core network side 23 of the DSP 14. For instance, data arriving from the subscriber may be converted, in stages, from a 4 kHz analog POTS signal on the loop 7 into an analog voice waveform (free of d.c. loop signalling) at the output 24 of the AFE 8, then into a 1 Mbps one-bit delta-sigma encoded bit stream at the output 25 of codec 11, subsequently into 32 kHz.times.20 bits/word linearly encoded samples at the output 22 of the decimator, and finally into an 8-bit .mu.-law pulse code modulation (PCM) signal at the output 23 of DSP 14.



Typically, a service-specific Service Application Software (SAS) is downloaded from the HDT 1 under instructions from an OAM manager via the OAM processor 18 located in the HDT 1, and stored in a service-specific SAS Random Access Memory (RAM) 15 associated with the DSP 14. Each LIU 3 interfaces with one physical path to one subscriber, such that if a subscriber has two twisted pair drops to the subscriber's premises, then two LIUs, and hence two DSPs, are required.



As an alternative to the oversampling codec, decimator, service-specific processor and SAS downloaded to the SAS RAM 15, a simple, fixed functional block such as a .mu.-law (or A-law) PCM codec or an ISDN 2B1Q line driver/receiver and formatting block can be used. In these cases the LIU 3 would take on a fixed function and it would be necessary to visit the remote site of the ONU to physically change the LIU type in order to change the services delivered. This is both costly and time-consuming because the LIU is usually located in a small cabinet in an outside-plant location, and technical staff have to find the location of the ONU and drive to it before they can physically change the appropriate LIU.



An ONU 2 is implemented by assembly of an array of LIUs 3 in a card cage (or its equivalent) along with additional circuit packs for common equipment such as the mux 5, the PON-OS 28, the optical transceiver 6 and an ONU control processor 26 which receives and transmits ONU control commands from and to the HDT 1. The Loop Status Detector 10 and Loop Status Processor 13 of the LIU 3 communicate loop-specific status and processing commands from the ONU control processor 26 to the ringing generator 9. Not shown is a control link from the ONU control processor to the codec 11 for controlling its output and sampling rates.



The mux 5 may be implemented using time slots or packets. For this discussion, time division multiplexed (TDM) time slots will be assumed. The mux 5 has to accommodate differing final processed bandwidths on its signal paths 23 from each of the LIUs 3 and hence has to be programmable in bandwidth per port on its access (subscriber) side. For instance, a POTS circuit would occupy 64 kbps and hence would require one 8-bit word (time slot) every 125 .mu.s (the standard frame period for TDM) for the information path. On the other hand, an ISDN circuit runs at 144 kbps, thus requiring three 8-bit time slots every 125 .mu.s.



In addition, a form of signalling and control path between the HDT and ONU is required. This can be achieved in one of many known forms, such as common channel signalling with multiplexed signalling messages from all line cards flowing in a single signalling channel, channel associated signalling or even embedded tone signalling or bit-robbing.



The fiber optic links 4, 4a support a bidirectional transmission path over one or two fibers. Either two fibers with unidirectional operation of each fiber could be used, or alternatively optical signals could be propagated in both directions down a single fiber with optical carriers being of a different wavelength in each direction.



In the direction from the HDT 1 to the ONU 2, the basic partitioning of the transmitted bandwidth from the HDT to each ONU is carried out by known means such as assembling the traffic information into a subframe of packets, cells or sequences of time slots. The subframe can also comprise control information as well as the ONU address. An example of a prior art format at the input to ONU 2 is shown in FIG. 2A. Each 125 .mu.s frame N sent down the umbilical 4A comprises a plurality of subframes, each of which is addressed to a specific ONU. The subframe for ONU #3 consists of an ONU address synchronisation field, a control field, a common channel multiplexed signalling field and a traffic field comprising T eight-bit time slots for the transmission of data.



The traffic, signalling and control fields, are multiplexed in one of many well known ways. One method is to allocate several time slots to the address field, then the first of two timeslots after the address field to a signalling channel and the other to a control channel. The signalling channel carries loop status information and instructions to and from a specific line card interface in a multiplexed format (e.g. Common Channel Signalling or Multiplexed Channel-Associated Signalling). The control channel carries ONU control information including SAS downloads as well as OAM status information.



The remainder of the payload time slots are used for multiplexed traffic data, which is in one or more 64 kb/s, 8-bit bytes (assuming a conventional 125 .mu.s frame rate). Each service payload is in its final format as required at the access/core network interface. In the illustrated example, POTS occupies 1 time slot, ISDN takes up 3 time slots and DS-1 occupies 25 timeslots, while the total number of traffic time slots is T=29. The demarcation boundaries between each subframe can be changed as long as the sum of the lengths of all packets, cells or sequences of timeslots does not exceed the frame length.



In the direction from the ONU 2 to the HDT 1, each ONU transmits a burst of data, timed so that, when combined by the splitter 30, the bursts of data from all the ONUs form a train of incoming bursts at the HDT end as shown in FIG. 2B. The transmission protocol operates in TDM mode with HDT synchronization of ONU burst timing to avoid burst collision, which would otherwise result in one ONU overwriting another ONU's data in the upstream path. In this way, transmission path delay from each ONU can be measured. Pairs of upstream bursts on the umbilical are separated by "guard bands" to allow tolerance on the burst control loop. The structure of the individual subframes travelling in either direction is the same, although the inter-subframe assembly methods are different.



In the HDT 1, the switch matrix 17 accepts TDM frames from transceiver 16 and, according to a mapping controlled by the control processor 19, routes the individual time slots in each frame towards the appropriate transceiver 21. Similarly, the switch matrix 17 accepts downstream data from the transceivers 21, subdivides the data into traffic time slots that constitute a particular subframe that is routed to the appropriate ONU. This switch "fabric" also acts as a conduit to connect ONU signalling and control paths to the signalling, control and OAM processors 20, 19, 18.



The signalling processor 20 formats the signals from the ONUs into a standard protocol (e.g., TR-303) to feed the network interfaces 21 (and vice versa), and formats the signalling messages to pass on subscriber-generated and access-generated messages to the core network 23 (and vice versa).



The control processor 19 controls the overall operation of the HDT and subtending ONUS, based on system status inputs and inputs from the OAM processor 18 and signalling processor 20. For instance, the control processor 19 will manage the cross-connection map for the HDT switch matrix 17.



It is noted that a key feature of the prior art system is the transmittal of fully formatted data across the fiber 4, 4a. The ONU 2 is responsible for producing an analog version of an oversampled digital signal based on a received downstream flow of, say, mu-law-encoded voice data. Similarly, the ONU 2 oversamples its subscriber input and formats it for upstream use by the HDT 1. Clearly, the benefit of this technique lies in the bandwidth savings achieved by transmitting fully formatted data across the PON. However, the complexity of such ONUs leads to the previously discussed disadvantages in the areas of cost, size, software download complexity, initial servicing and efficiency.



It would instead be more desirable to place complex processing functions in the HDT 1, by transmitting "raw" (unformatted) data across the PON. This is particularly feasible in today's era of fiber optic bandwidth abundance. Accordingly, the present invention is now described with reference to FIG. 1B, in which an inventive fiber-based access system intended to provide FITL (especially FTTC) comprises an HDT 101 and a plurality of ONUs 102 (only one of which is shown). Each ONU 102 consists of an array of LIUs 103, 127 along with a bidirectional mux 105, an ONU control processor 126, as well as a PON-OS 128 and an optoelectronic transceiver 6. As in the prior art, the mux 105 is of the TDM type, comprising ports that are programmable so as to allot a selectable number of time slots (and hence, bandwidth) to each LIU in both directions of communication.



The mux 105 is connected to an oversampling codec 111 in each LIU 103 by a downstream line 153 and an upstream line 125. Not shown is a control link from the ONU control processor to the codec for controlling its output and sampling rates. The codec 111 preferably comprises complementary one-bit sigma-delta analog-to-digital and digital-to-analog converters, and is connected to a wideband AFE, which interfaces directly with an analog drop line 7 leading to and from a subscriber. Preferably, the link from the fiber at the curb to the subscriber is formed by copper twisted pairs, although coaxial cable may be accommodated by the use of a suitable AFE 8.



Each LIU further comprises a ringing generator 9 and a loop status detector 10, which are connected to each other by line 147, to the AFE 8 by respective lines 145,146 and to the mux by respective lines 133,134. The ringing generator 9 adds a ringing signal to the line under control from signal 133 received from the mux 105, and removes it when the loop status detector 10 determines that the line is in the off-hook position. The loop status detector 10 also provides a digital rendition of the analog line voltage on signal 134 connected to the mux 105. It is to be understood that the ringing generator 9 and loop status detector 10 may be connected directly to the control processor 126 instead of to the mux 105. Moreover, the mux 105 may itself be connected to the ONU control processor 126.



Electrical communication between the mux 105 and the PON-OS 128 can be effected using a bidirectional link 135 or two unidirectional links. The ONU control processor 126 is connected to the PON-OS 128 by a bidirectional signal link 123. The transceiver 6 serves to transform the (multiplexed) electronic data into an optical signal destined for the HDT, and to convert an optical signal from the HDT into electronic data used by the mux 105. The optical signals in both directions preferably originate from, and are combined onto, a single fiber optic cable 4.



Multiple optical fibers come together at a passive optical splitter 30, which in the upstream direction adds the optical energy on each fiber and sends the resultant signal along an umbilical link 4a to the HDT, and in the downstream direction splits the downstream optical signal on the fiber umbilical 4a into a number of identical optical signals a travelling along respective individual fibers 4.



The HDT interfaces with the umbilicals (4a as well as others not shown) by means of respective optoelectronic transceivers 16 connected to a digital switch matrix 117. The switch matrix is a conventional TDM digital switch with traffic data entered into sequential locations in a large data memory at a given fixed frame rate, and the same data read out again in a sequence controlled by a connection memory. The sequencing is controlled via a control link (not shown) by a control processor 119 in the HDT. The control processor 119 is preferably also connected to a loop status processor 113, which performs functions such as decoding a telephone number dialled by the subscriber based on the sampled digital line voltage transmitted from the loop status detector 10 in each LIU 103.



The HDT 101 further comprises a second switch matrix 131, also a conventional TDM digital switch controlled by the control processor 119, which is connected to a plurality of transceivers 21 that interface with the core network (not shown). Also connected to switch matrix 131 are a signalling processor 20 and an OAM processor 118. As in the prior art, the signalling processor 20 formats outgoing data so that it is in the proper signalling format (e.g., TR-303) used by the core network, and vice versa. The OAM processor 118 provides the core network with status information via a link 200; this link also serves to relay instructions for configuring the mux 105 in the ONUs 102. The control processor controls the overall operation of the HDT and subtending ONUs, based on inputs from the OAM processor 118 and the signalling processor 20, as well as system status inputs.



The switch matrices 117, 131 are connected by a bidirectional "hair pin" connection 132 and also through sets of DSPs. The connections are shown in greater detail in FIG. 4B. The first bank of processors consists of a plurality of DSPs 114X, Y, Z that process respective demultiplexed upstream signals 160X, Y, Z and produce respective signals 170X, Y, Z that are routed by switch matrix 131. Decimators 130X, Y, Z respectively intercept the upstream signals 160X, Y, Z so that the associated DSPs are fed fixed-length words of data at a certain speed instead of an oversampled bit stream at a higher rate, as output by the codec in a given LIU.



The second set of processors joining the switch matrices 117, 131 is a plurality of DSPs 114A, B, C which process signals 161A, B, C arriving from switch matrix 131, forming signals 163A, B, C. The DSPs 114A, B, C are connected to respective interpolators 129A, B, C, which create respective high-rate bit streams 164A, B, C that are routed by switch matrix 117.



Each DSP 114X, Y, Z and 114A, B, C is preprogrammed by application and data files stored in respective SAS RAMs 115X, Y, Z and 115A, B, C to execute a conversion algorithm that converts digital data from one format to another. The actual number of DSPs, decimators and interpolators required will depend on total system requirements.



The hair pin connection 132 serves to interconnect the two switch matrices 117, 131, should it be necessary to implement a complex conversion algorithm involving multiple processing steps executed by traversing the DSPs several times in sequence.



From the above, it can be seen that the structure of the inventive system differs from that of the prior art in that the ONUs have been simplified by migrating the DSP functionality to the HDT. As a result, instead of transmitting fully formatted data across the PON, only "raw" (unformatted) data at high bit rates is exchanged between the HDT 101 and ONU 102 (and others not shown) along the fibers 4, 4a. The high data rates required are easily achievable using commonly available optical fibers.



It is helpful to first describe the format of data travelling downstream from the HDT on the fiber 4a with reference to FIG. 3A, which illustrates how a downstream frame F of 125/M .mu.s (microseconds) is divided into subframes SF1-SF5 destined for respective ONUs. The value of 125 .mu.s is the standard length of a frame in the public switched telephone network (PSTN) and M is the factor by which this frame length is reduced, usually 1, 8, 12, 16, 24, 25 or 32. As will be shown hereunder, M is used in determining the so-called bandwidth granularity (BG), which is a measure of the resolution in bandwidth deliverable across the PON.



The relative size of a subframe, expressed as the number of BG units required to provide enough transport capacity for the corresponding ONU, may differ from one ONU to another. Considering a particular subframe SF3, it is shown as divided into four fields: an ONU address and synchronization field, a control field, a signalling field and a traffic field. There may also be residual (or spare) bandwidth that is available on the fiber 104 but unexploited by the ONUs, which is shown for the purpose of illustration as occupying a subframe SF6, although in reality the fields of this subframe do not carry useful information.



At the basic physical transport layer the address, control, signalling and traffic fields (or "channels"), are preferably time slots populated with bits and dedicated to transmitting certain classes of information from the HDT to the ONU. The address field in each subframe identifies the ONU for which the traffic is destined. The signalling field preferably carries instructions (such as ringing generator control) to a specific LIU in a known multiplexed format. The control field provides OAM status information and instructions to configure the mux 105, thereby to allocate a certain bandwidth to each LIU according to the service-dependent bandwidth needs for that LIU. The control channel in the downstream subframes also provides control of the codec sampling and output rates in each LIU, as well as precise timing instructions for the transmittal of bursts of upstream data.



The traffic field is divided into a multitude of (in this case, twenty-nine) time slots T1-T29 of "P" bits each. The BG can be defined as the bandwidth offered by the transmission of one time slot per frame, and is dependent on the number of bits per time slot ("P") and on the above-identified frame size reduction factor ("M"). In mathematical terms,



The number of time slots occupied by an LIU in a subframe is dependent on "M", "P" and the required bandwidth by the LIU. It is useful to set P.times.M=64 (yielding a BG of 512 kbps) when the oversampled data is required to be sent at data rates that are multiples of 0.5 Mbps. Nonetheless, the bandwidth granularity is an arbitrary but fixed design parameter that can be designed to accommodate a different base multiple of bandwidth used in the system.



The traffic time slots are arranged into a known number (in this case, fifteen) of groups G1-G15, each group providing downstream data to a respective LIU. The number of time slots required per group is selectable and will depend on the bandwidth granularity and on the type of service provided.



These same time slots are used in the analogous construction of upstream subframes transmitted by the ONU 102 to the HDT 101. The mux 105 forms a subframe that is subdivided into groups of time slots, whereby a group is associated with a specific LIU and is allotted a number of time slots that is dependent on the BG and on the required upstream bandwidth. Upon command from the HDT, an ONU transmits its fully constructed upstream subframe on a once-per-frame basis, although the subframes arriving from various ONUs are not contiguous, but instead arrive separated by guard bands.



The flow of downstream and upstream data between the core network and a subscriber, passing through the inventive access system, is now considered with reference to FIGS. 1B and 4B. It is particularly useful to contemplate two exemplary scenarios, denoted A and B. Scenario A deals with the situation in which the core network sends and receives multiplexed channels of 8-bit mu-law PCM voice data that are connected through the HDT and ONUs to analog subscriber loops that send and receive analog POTS signals. Scenario B treats the situation in which a Frame Relay (or similar packetized) service carried across an ATM core network is delivered to and from an end user as a Frame Relay service over a DS-1 (1.544 Mbps) twisted pair link.



In downstream scenario A, switch matrix 131 routes the multiplexed channels of 8-bit mu-law encoded voice samples (arriving in a standard network format) to DSP 114A after reformatting is done by the signalling processor 20. DSP 114A is dedicated to producing a stream 163A of, say, 20-bit linearly encoded samples at 32 kHz from the 8-bit mu-law encoded data. In the prior art, this exact same function would be performed by a dedicated DSP within each destination LIU. In contrast, DSP 114A in the present invention processes multiple channels destined for corresponding LIUs, and is thus effectively shared by a number of different LIUs. The data stream 163A passes through interpolator 129A so as to enter switch matrix 117 as a high-rate bit stream 164A, typically on the order of 1 Mbps per channel. This data is in a generic data format, as it simply requires digital-to-analog conversion by the codec in the destination LIU.



Switch matrix 117 also accepts the other high rate data streams 164B, C produced by the respective DSPs 114B, C, and arranges the data into groups, subframes and frames according to destination LIU, ONU and PON in the manner described earlier. The optical downstream signal exiting the HDT, which may have a data rate on the order of several hundred Mbps, is converted to electronic format by the transceiver 6 and subsequently fed to the PON-OS 128.



At the PON-OS 128, the address field in each subframe is checked in order to determine whether the current ONU is the intended recipient of that subframe. Only the subframes intended for that particular ONU are output on link 135 to the mux 105. For each LIU 103, the mux 105 outputs, by a process of demultiplexing, the proper traffic time slots on the link 153 to the codec 111, along with control information for the ringing generator 9 on link 133. In addition, the PON-OS 128 provides control information to the ONU control processor 126 via link 123; alternatively, this information may be delivered from the mux 105.



Within each LIU, the codec 111 then converts the high-rate bit stream on its network-side link 153 into an analog POTS waveform, and the AFE 8 adds appropriate ringing voltages and loop currents. As discussed earlier, the AFE is also responsible for removing the ringing voltage when an off-hook condition is detected, and may interface to a variety of loop termination media, such as copper twisted pair or coaxial cable.



Considering now the upstream path in scenario A, the AFE 8 will prepare the analog POTS signal for sampling by the oversampling codec 111 at around 1 MHz. The oversampled data 152 is fed to the mux 105, where a suitable number of time slots in a subframe are allotted to this stream. Also, the mux 105 will partially fill the control and signalling fields with the status of the analog line received from the loop status detector 10 via path 134. The address field will indicate the source ONU.



The mux 105 then assembles the time slots from each LIU, as well as all of the information in the remaining fields, forming a subframe, and sends it to the PON-OS 128. The PON-OS waits for the go-ahead from the ONU control processor 126 before sending the subframe onto the fiber 4 via the transceiver 6. The ONU control processor 126 receives this timing information from the HDT in the control field of the downstream subframes. Each ONU sharing the same fiber umbilical 4a is cyclically instructed to send its burst of data, resulting in a "train" 400 of subframes SF1-3 as shown in FIG. 3B. Any consecutive pair of bursts is separated by a short time span 402 of variable length during which no transmission occurs, called a guard band. This is designed to account for the delay in instructing one ONU to transmit while ensuring that the previous ONU has ceased transmission.



The train 400 of data containing the oversampled POTS signal of upstream scenario A arrives at switch matrix 117 of the HDT 101 through transceiver 16. The corresponding traffic time slots are extracted and routed via decimator 130X to a DSP 114X which converts the oversampled decimated data arriving from the subscriber to 8-bit mu-law data. DSP 114X will likely be assigned the task of converting multiple upstream data channels from oversampled decimated format into mu-law format. The output 170X of DSP 114X subsequently passes through switch matrix 131, where it is routed towards its possibly multiple destinations elsewhere in the network via transceivers 21. The signalling processor 20 appropriately formats the outgoing signals prior to optoelectronic conversion by transceivers 21.



In downstream scenario B, ATM cells arriving from the core network and carrying the Frame Relay service are routed by switch matrix 131 to a first DSP 114B. DSP 114B is dedicated to the process of reassembling segments of Frame Relay packets contained in the ATM cell stream into pure Frame Relay packets. This reassembly portion of a so-called segmentation and reassembly (SAR) process is achieved by removing the ATM Gus envelope around the Frame Relay packet segments in the payload of each ATM cell and reassembling those segments into Frame Relay packets.



However, the output 166 of DSP 114B is still not in a suitable format for delivery to the customer (who is expecting to receive line coded 1.544 Mbps DS-1 data). Therefore, the output 163B of DSP 114B is rerouted to the input of another DSP processor 114C by switch matrix 117, hair pin connection 132 and switch matrix 131. DSP 114C is empowered with the insertion of Frame Relay packets into the payload of a 1.544 Mbps DS-1. DSP 114C also formats the digital signal with the required line code, yielding data stream 163C.



Data stream 163C is subsequently passed through an interpolator 129C to yield a very high rate oversampled bit stream 164C, having a data rate on the order of 20 Mbps and requiring, for example, 40 time slots at a bandwidth granularity of 512 kbps per slot. The bit stream 164C is multiplexed by switch matrix 117 and delivered to the appropriate codec 111 of the destination ONU in the manner described above. At the codec 111, the oversampled line coded DS-1 data is converted into an analog waveform, although the data per se is still in digital format, being encoded in the various voltage level durations and changes characteristic to the line code in use.



It is to be noted that bit stream 164C in this downstream scenario B is in the same universal oversampled format as bit stream 164A previously considered in downstream scenario A (although its rate is higher). In fact, the commonness of the data format communicated between the HDT and the ONUs (and vice versa) is an important property of the present invention. The rates, on the other hand, will depend on the service being offered, and the output or sampling rate of the codecs can be controlled via the downstream control channel, as previously discussed.



It is also noteworthy that interpolation is not applied at the output 163B of DSP 114B since this data requires further processing by DSP 114C. This does not imply that an interpolator should be absent at the output of DSP 114B, but rather that all interpolators 129A, B, C be preferably equipped with "bypass mode" functionality (i.e., OUTPUT=INPUT), so that data which is hair pinned several times is interpolated only after having gone through the final DSP prior to delivery to the subscriber.



In upstream scenario B, the digital DS-1 signal sent by the subscriber along the loop 7 undergoes frequency selective loss, accumulates noise and suffers from other impairments as it is propagated along the twisted pair drop. By the time the subscriber-emitted signal reaches the AFE 8, regeneration is required to recover the original digital data from the distorted analog waveform. In the prior art, this regeneration is performed in the LIU proper. In contrast, the codec 111 in the inventive system simply oversamples the data at around 20 MHz as if it were a wideband analog input signal. In other words, the codec 111 "blindly" oversamples the signal and performs no data recovery, leaving the data in the common, high-bandwidth digital format.



The mux 105 inserts the oversampled bit stream into the time slots preassigned to that LIU, subsequently creating a subframe which is sent to the HDT via the PON-OS 128 and transceiver 6 using the upstream burst transmission procedure described above. Clearly, the inventive system trades bandwidth efficiency for simplicity of operation and economy of construction.



At the HDT, oversampled DS-1 data arrives at a transceiver 16, and is subsequently routed to a first DSP 114Y which is programmed to recover the 1.544 Mbps bit stream from the oversampled version of the distorted line coded signal. This known regeneration process is achieved by a combination of frequency equalization, noise filtering and the application of a clocked decision threshold. The output 170Y of DSP 114Y is then routed to the input of a second DSP 114Z via switch matrix 131, hairpin connection 132 and switch matrix 117.



The second DSP 114Z removes the DS-1 header and plainly outputs the payload in the form of Frame Relay packets which had been contained in the original DS-1 stream. The output 170Z of DSP 114Z is once again "hair pinned" back to a third DSP (not shown) which segments the Frame Relay packets into ATM cells by applying the segmentation portion of the SAR process described above. Finally, the ATM data is ready to be sent to its destination through switch matrix 131 and a transceiver 21. Analogous to interpolation in the downstream case, decimation performed in the HDT occurs only once, i.e., at the input to the first DSP in line for processing subscriber-generated data.



Typical oversampling and decimating rates for several common service types are illustrated in the following table:



Oversampled Oversampled and Decimated Bit Service Bit Rate Rate POTS 1-2 Mbps 32 kHz .times. 20 bits/word = 640 kbps Foreign 1-2 Mbps 32 kHz .times. 20 bits/word = 640 kbps Exchange ISDN 2-10 Mbps 160 kHz .times. 10 bits/word = 1.6 Mbps DS-1 20-40 Mbps 1.5 MHZ .times. 10 bits/word = 15 Mbps



Incidentally, it is also interesting to consider the requirements of the switch matrices 117, 131 in view of the above rates. It is noted that the throughput of a prior art switch matrix 17 would determined by the aggregate fully formatted data capacity to and from all of the PONs connected to that switch matrix, whereas inventive switch matrix 117 is sized to carry the aggregate of all the oversampled data to and from the ONUs in addition to all of the data that is "hair pinned", resulting in the requirement for a much larger data memory when using a standard 125-.mu.s frame length. However, if the frame length is shortened to match the larger channel bandwidths of the oversampled signals, the memory requirement is reduced since less data arrives per frame. The value of M discussed above can thus be chosen to alleviate the requirements on switch matrix 117 by setting a convenient operating frame rate.



The digital switch matrix 131 has somewhat lesser requirements in that it handles data exiting the DSPs in a finalized format while also handling higher-bandwidth data "hair-pinned" back to the access side switch matrix 117. However, no data need travel through switch matrix 131 in non-decimated form. Switch matrix 131 would thus be chosen as having a frame rate of standard length, i.e., 125 .mu.s. Alternatively, several switches may be concatenated in the case where a high amount of "hair-pinning" is expected, one switch operating, for example, on a short frame with another one operating on a 125-.mu.s frame.



It is important to note that relocation of digital signal processing tasks from the ONU to the HDT results in a cheaper, simpler, more efficient and more reliable ONU for deployment deep into the network. On the HDT side, considerable gains in DSP efficiency are also realized. For example, although individual processors are dedicated to a particular task, say conversion of mu-law PCM to linearly encoded samples, a single DSP can be used to perform the task at hand on a number of different data streams. These streams may be destined for completely different ports on the network, such as LIUs on different ONUs in different PONs. Whereas the number of processors required in the prior art was equal to the number of LIUs, the inventive system permits the use of a pool of DSP resources that can be shared across many LIUs. Since not all tasks require the same amount of processing, the HDT need concern itself with total DSP processing power, but not with a particular number of DSPs. Moreover, the DSPs themselves may offer varying degrees of processing ability, and need not be sized to accommodate the worst-case scenario of data conversion, as was formerly the case.



As an illustration of the DSP savings that can be achieved by the present invention, it is worthwhile to consider, for instance, a bank of 16 DSPs each capable of handling either 24 simultaneous mu-law-to-POTS conversions, 6 ISDN-to-POTS conversions or 1 DS-1-to-POTS conversion. If there exists a downstream service requirement for 192 POTS lines, 24 ISDN lines and 2 DS-1 lines, then the following setup of DSPs would be able to accommodate the service mix:



8 DSPs .times. 24 POTS lines/DSP .fwdarw. 192 POTS LIUs serviced 4 DSPs .times. 6 ISDN lines/DSP .fwdarw. 24 ISDN LIUs serviced 2 DSP .times. 1 DS-1 lines/DSP .fwdarw. 2 DS-1 LIUs serviced



Clearly, a total of 218 LIUs can be accommodated by a mere 16 DSPs sized to handle DS-1-to-POTS conversion. This is minute compared to the 218 DSPs of at least the same power (i.e., not counting combinations of services) that would be required in a prior art approach based on service-independent line cards.



Notwithstanding the benefits of the inventive system given the artificial service mix assumed above, the following more detailed analysis of realistic loading conditions will reveal that in a typical service mix, the usage of a shared set of DSP blocks indeed allows each DSP to be more optimally loaded. For instance, if a DSP is capable of processing "m" lines of service type A, "n" lines of service type B and "p" lines of service type C, then, on a system with a total need to service "w" LIUs, the total DSP count for full service across the entire system is w/m+w/n+w/p. In other words, with DSPs in the HDT that are dedicated to a particular type of processing, one must stock up enough DSPs to cover any and all of the three worst cases. Clearly, DSP savings are achieved when



(w/m+w/n+w/p)<w, or



Depending on the processing power of the DSPs in the HDT, this may require fewer resources than the prior art.



However, the advantages of centralizing the DSP resources become indisputable in the event that more than 3 lines of service on average (i.e., across all service types) can be processed in a DSP. Then m, n and p are all greater than 3 and the above inequality is satisfied, resulting in DSP savings due to "centralization" of DSP resources. Typical numbers for modern DSPs processing POTS, ISDN and DS-1 are even more encouraging, and are on the order of 24 POTS/DSP, 6 ISDN/DSP, 2.5 DS-l/DSP, yielding (1/m+1/n+1/p)=0.6083.



The analysis may be extended one step further by applying known practical traffic mix requirement limits into the process of dimensioning the DSPs. For instance, if only a certain maximum percentage (e.g., 10%) of lines will ever need DS-1 service and another maximum percentage of lines (e.g., 25%) will ever need ISDN service at one time (without knowing which lines are occupied by what service), then the above inequality becomes



for almost an order of magnitude savings (8.11:1) in the number of DSPs required.



On top of the added capacity, a further advantage of the present invention is that the DSPs are found in a centralized environment, which reduces the cost of provisioning and dimensioning the DSPs to meet future traffic demands. Moreover, the DSPs are flexible and their respective RAMs are reprogrammable by the control processor 119, either through a control bus 183 as illustrated in FIG. 4B or through one of the switch matrices 117, 131, thereby providing the ability to track the evolving demands of the network.



The control processor 119 in the HDT can also play a vital role in reducing the bandwidth taken up by the various LIUs, particularly in the case of ISDN and DS-1 services. For instance, an on-hook (unused) POTS line takes up very little a bandwidth, as does an unused DS-1 video conference line (i.e., the far end modem at the customer premises is in a quiescent mode), since the only requirement on that DS-1 loop is to detect the start up of the DS-1 Customer Premises Equipment. The control processor 119 can thus lower the sampling and output rates of the oversampling codecs and decimators on LIUs which are in an on-hook or quiescent condition to values much below that which the LIUs would require for an active delivery of POTS or DS-1 services.



Hence, assuming a service mix of 80% POTS at 640 kbps, 10% ISDN at 1.6 Mbps, and 10% DS-1 at 15 Mbps (all data rates are oversampled and decimated), and further assuming an average off-hook (in use) duty cycle of 25% along with 80% bandwidth reduction during on-hook (out of use) periods for both POTS and DS-1, then the average bandwidth per loop would be on the order of:



[(640 kbps * 25%) + (0,2 * 640 kbps * 75%)] * 80% + [(1.6 Mbps * 100%)] * 10% + [(15 Mbps * 25%) + (0.2 * 15 Mbps * 75%)] * 10% = 964.8 kbps per loop



This would allow up to 621 subscribers to be accessed with a single 600-Mbps PON, corresponding to the installation of up to sixteen 38-line ONUs or eight 77-line ONUs. A single fiber umbilical can thus serve a distribution area with over 600 customers, which is the norm for current North American telecommunications company serving areas.



The preceding example has assumed that decimated data are transmitted across the PON. This is achieved by an alternate embodiment of the present invention, in which the decimation and inverse functions are kept in the LIUs. Thus, considering the upstream path, a decimator would be placed between the codec 111 and the mux 105 instead of in the HDT. Optionally, decimators could be placed in both locations, whereby each upstream signal path would comprise one fully functional decimator and another operating in bypass mode. Clearly, analogous arrangements apply to the interpolators in the downstream path.



In another variant of the present invention, the functionality of the loop status processor 113 would be placed in each LIU 103, 127. Specifically, the loop status detector 10 may feed its signal 134 directly to the ONU control processor 126 or to an intermediate loop status processing block. The ONU control processor would perform the control functions of determining the condition of the line or decoding the dialled digits, relaying this information to the HDT via the upstream control channel. Similarly, the ringing generator 9 may be controlled from the ONU control processor 126, thus further liberating the mux 105, which is left with the task of simply routing the data to and from the LIUs.



It is also to be understood that many alternate embodiments of the present invention exist in which the processing chain in the HDT is configured differently than in FIG. 4B. Such is the case in FIG. 4A, wherein a single high-capacity switch matrix 195 replaces the switch matrices 117, 131 of FIG. 4B. In this case, hair pinning does not require a link external to the switch matrix. Instead, data both from the ONUs and from the core network are continuously routed to the DSP bank and back through the switch matrix 195 until the required number of processing operations have been performed.



There may also be a 125-.mu.s framed switch matrix 193 present at the core network side connected to the signalling processor which provides grooming of the frames leaving or entering the HDT at a 125 .mu.s frame rate. In all other respects, the HDT is identical to that of FIG. 4B.



Yet another example of an inventive HDT partitions the short-frame switch matrices of FIG. 4B into two, resulting in four STS switches 117U, 117D, 131U, 131D as shown in FIG. 4C. In this case, two hair pin connections 132U, 132D are required, one for each direction travelled by the data. The signalling processor 20 now provides independent grooming of the frames in both the downstream and upstream paths. However, there is no fundamental difference in operation of the embodiment illustrated in FIG. 4C with respect to what has already been described with reference to FIG. 4B.



Numerous other modifications and variations of the present invention are possible in light of the above teachings. It is therefore to be understood that within the scope of the appended claims, the invention may be practised otherwise than as specifically described herein.

PatentNumber=6202208,TECHNICAL FIELD



The present invention relates in general to modifying an executing computer program, and in particular to a method and system for modifying a Java Virtual Machine ("JVM") with a patch environment.



BACKGROUND OF THE INVENTION



Large-scale, complex computer systems, are brought into use through integration of software programs with a hardware platform. Simply put, the software program is a detailed plan or procedure for solving a problem, that is executed on a hardware platform. The hardware platform includes a microprocessor or microprocessors and associated support circuits such as electronic memory (such as random-access-memory or RAM, hard disk memory, or card memory) and input/output port circuits so that information can be passed between components of the system and users.



A telecommunication network is an example of such a complex system. Telecommunication networks facilitate communications between a large number of public and private communications systems by providing numerous functions such as switching, accounting, and time management. A telecommunications network provides these functions through network switches, or nodes, interconnected by links, or channels, of transmission media such as wire, fiber-optic cable, or radio waves. Some of the nodes are connected to one or more users.



Modern telecommunication networks require complex, automated switching and, to that end, software programs are written to increase switching efficiency in telecommunications systems, along with implementing service features and functions (for example, call waiting and caller id). A computer language for implementing such software programs is "Java." Java was introduced by Sun Microsystems, Inc., of Palo Alto, Calif., and has been described as a simple, object-oriented, distributed, interpreted, robust, secure, architecture neutral, portable, high-performance, multithreaded, and dynamic computer language.



As with most software programs, a Java software program undergoes a debugging process to eliminate errors or malfunctions, also known as bugs, in the "detailed plan" or "procedure" for solving a problem. In this example, the problem solved is telephone network switching.



It is common for extensive debugging procedures to be conducted on a software package before it is installed on hardware platforms in the field. Nevertheless, some software bugs arise in a real-world environment because not all of the real-world contingencies can be simulated in a testing environment. Rarely are large-scale software systems, such as telecommunications software, without some errors that escaped product development testing. Such bugs may arise or be revealed within a short time of installation, or only after a period of time sufficient for operational conditions to reveal or cause a bug to appear.



While most switches are capable of loading a new Java software upgrade without stopping to correct and replace defective software, such loading of new software may result in undesirable effects and, furthermore, may not be feasible in many situations, such as during busy-hour processing, when a system may not have sufficient bandwidth to provide telephony service and simultaneously engage in a Java software upgrade. In such a case, the act of correcting the software bug may result in a worse service outage than resulted by the software bug itself. Telephone customers may then have to suffer with the bug until a suitable maintenance window becomes available to perform a wholesale software upgrade. Such a situation, however, is not acceptable because telephone switches which rely on the software are expected to experience no more than three minutes of downtime per year.



Alternatively, conventional patching techniques may be used to correct defective software without having a large impact on the performance or workload of the system. Such patching techniques, however, are limited to correcting relatively minor software defects.



While there are drawbacks associated with software corrective techniques, such as the aforementioned loading and/or patching of software without stopping, such techniques are not even available with most large-scale complex computer systems outside of the telecommunications industry.



Accordingly, a continuing search has been directed to the development of methods by which a defective software program may be corrected or modified without stopping the program, and without degrading the performance or workload capacity of the system controlled by the program. Such a continuing search has been further directed to a method by which a defective software program may be corrected or modified without requiring the wholesale installation and/or upgrade of a software application program and the associated labor costs, even if the program must be stopped.



SUMMARY OF THE INVENTION



Accordingly, provided is an apparatus and method to implement controlled incremental changes to a Java software application while being executed. The controlled incremental changes to a Java Virtual Machine (JVM), which operates to execute the Java software application, is made through a patch environment. The patch environment may implement the changes while the program is executing on the host computer, or without reloading the entire Java software application.



BRIEF DESCRIPTION OF THE DRAWINGS



For a more complete understanding of the present invention, and the advantages thereof, reference is now made to the following descriptions taken in conjunction with the accompanying drawings, in which:



FIG. 1 is a block diagram illustrating a Java Virtual Machine ("JVM"); and



FIG. 2 is a block diagram illustrating a patch environment of the present invention for modifying a loader environment of the JVM;



FIG. 3 is a block diagram illustrating the patch environment of the present invention for modifying a method body of the loader environment of the JVM;



FIG. 4 is a block diagram illustrating the application of a patch to modify a method body of the loader environment of the JVM;



FIG. 5 is a block diagram illustrating the application of a patch to add a method body to the loader environment of the JVM; and



FIG. 6 is a block diagram illustrating synchronization of the application of a patch to modify a method body of the loader environment of the JVM in synchrony with execution of other code of the JVM.



DETAILED DESCRIPTION



The Java language is computer architecture neutral and portable. Java programs are compiled to an architecture neutral byte-code format, allowing a Java application to run on any computer platform as either a stand-alone program or as a program fully integrated with an operating system used by the computer platform, as long as that platform implements the Java Virtual Machine ("JVM"). Examples of such computer platforms are personal computers ("PC"), Macintosh computers, and Unix workstations. The operating systems, which are programs responsible for controlling the allocation and usage of hardware resources such as memory, central processing unit ("CPU") time, disk space, and peripheral devices, come in numerous varieties such as Unix, Windows 98, Windows NT for PCs and PowerPC Macintosh. Java programs can run on any of these operating systems.



The JVM has a clear mission: to run one Java application. When a Java application starts, a runtime instance is spawned. Each Java application runs inside its own JVM.



Referring to FIG. 1, illustrated is a JVM 100. The JVM 100 includes a main memory 102 with a heap 104, and a JVM internal memory 106. The main memory 102 is further partitioned to define a working memory 108. The main memory 102 is the environment in which a Java program runs. The JVM 100 also includes a function component 110 for providing a garbage collection function, a system interface, a loader environment, an execution engine, and the like, including threads defined by the architecture of the JVM 100, discussed below.



Generally, a thread is a process that is part of a larger process or Java program. The conventional JVM specification establishes a threading model that seeks to facilitate implementation on a wide variety of computer and software architectures. The Java threading model allows implementation designers to use native threads (threads belonging to underlying operating systems). Alternatively, designers can implement a thread mechanism as part of their JVM implementation. An advantage to using native threads on a multi-processor host is that different threads of a Java application can run simultaneously on different CPUs.



Threads can be either daemon and non-daemon. A daemon thread is a thread used by the JVM 100, such as a thread that performs garbage collection, discussed later in detail. The Java application, however, can mark any threads it creates as daemon threads. The initial thread of an application--the one that begins at main( )--is a non-daemon thread.



The JVM continues to exist as long as any non-daemon thread is running. When all non-daemon threads of a Java application terminate, the JVM instance will exit.



According to the JVM specification, the thread implementation of any JVM must support two aspects of synchronization: object locking, and thread wait-and-notify. Object locking helps keep threads from interfering with one another while working independently on shared data. Thread wait-and-notify helps threads to cooperate with one another while working together toward some common goal. Running-applications access the JVM locking capabilities via the instruction set, and its wait-and-notify capabilities via the wait( ), notify( ), and notifyAll( ) methods of class.



When the JVM 100 runs a Java program, memory is needed to store Java components, such as bytecodes and other information extracted from a loaded class file, objects the program instantiates, parameters to Java methods, return values, local variables, and intermediate results of computations.



Under the JVM Specification, the behavior of Java threads is defined in terms of variables, main memory, and working memory. The JVM Specification is a commercially-available document under the title "The Java Virtual Machine" by Tim Lindholm and Frank Yellin (1997), ISBN 0-201-63452-X, available from Sun Microsystems, Inc. or at Internet address http://www.aw.com/cp/javaseries.



The main memory 102, contains the Java program variables: instance variables of objects, components of arrays, and class variables. Each thread has a working memory 108, in which a JVM thread stores "working copies" of variables the thread uses or assigns. Local variables and parameters, because they are private to individual threads, can be logically seen as part of either the working memory 108 or the main memory 102.



When a class instance or array is created in a running Java application, the memory for the new object is allocated from the heap 104, which is in the portion of memory defined as the main memory 102. Because only one heap 104 exists inside a JVM 100, all threads share the heap 104. Also, because a Java application runs inside its "own" exclusive JVM instance, a separate heap 104 exists for every individual running application. In this manner, two different Java applications cannot corrupt the heap data of the other. However, two different threads of the same application could trample on the heap data of the other. For this reason, proper synchronization of multithreaded access to objects (heap data) in Java programs needs to be addressed.



The JVM 100 includes an instruction that allocates memory on the heap 104 for a new object but includes no instruction for freeing that memory. The JVM 100 is responsible for deciding whether and when to free memory occupied by objects that are no longer referenced by the running application. Usually, a JVM 100 uses a garbage collector thread to manage the heap 104.



The primary function of the garbage collector thread is to automatically reclaim the memory used by objects that are no longer referenced by the running-application. The garbage collector can also move objects as an application runs to reduce fragmentation of the heap 104. Fragmentation is the scattering of parts of an object in different areas of the heap 104, resulting in slower access and degradation of overall performance of memory operations.



A garbage collector is not strictly required by the JVM specification. The specification requires only that an implementation manage its heap 104 in some manner. For example, an implementation could simply have a fixed amount of heap space available and throw an OutOfMemory exception when that space fills up.



No garbage-collection technique is dictated by the JVM specification. Java designers can use whatever techniques seem most appropriate given their goals, constraints, and talents. Because program references to objects can exist in many places--Java Stacks, the heap, the loader environment, native method stacks--the choice of garbage-collection techniques heavily influences the design of the runtime data areas of an implementation.



A JVM 100 starts executing its solitary application by invoking the main( ) method of some initial class in a class file 124. The term "class" as used herein means a generalized category that describes a group of more specific methods that can exist within it, and are comparable in concept to the types of "pigeonholes" used to organize information. The term "method" as used herein means a procedure or a function. The data and methods, taken together, usually serve to define the contents and capabilities of some kind of object. Any class with such a main( ) method can be used as the starting point for a Java application. The main( ) method serves as the starting point for the initial thread of the application. The initial thread can in turn generate other threads.



The JVM 100 includes an execution engine which is a part of the object 110 and is a mechanism responsible for executing the instructions contained in the methods of loaded classes.



As shown in FIG. 1, the JVM internal memory 106 includes a loader environment 200 for loading types, i.e., classes and interfaces, having fully qualified names. The loader environment 200 is configured for storing metadata describing attributes about data types (or classes, such as data objects which go into the heap 104 and into the working memory 108) derived from the program and loaded through the class files and loader mechanism. These areas are shared by all threads running inside the JVM 100. When the JVM 100 loads a class file 124. the JVM 100 parses information about a "type" from the binary data contained in the class file 124. It places this type information into the loader environment 100. As the Java program runs, the JVM 100 places all objects the program initiates into the heap 104.



The JVM 100 computes by performing operations on data types. Both the data types and operations are strictly defined by the JVM Specification. The data types can be divided into a set of primitive types and a reference type. Variables of the primitive types hold primitive values, and variables of the reference type hold reference values. Reference values refer to objects but are not objects themselves. Primitive values, by contrast, do not refer to anything. They are the actual data themselves.



All the primitive types of the Java programming language, except boolean, are primitive types of the JVM 100. When a compiler translates Java source code into method bodies, it uses integers or bytes to represent booleans.



The primitive types of Java programming language other than boolean form the numeric types of the JVM 100. The numeric types are divided between the integral types (such as byte, short, int, long, and char) and floating-point types (such as float and double). The part of a Java Virtual Machine implementation that takes care of finding and loading types is the class loader subsystem, implemented through the loader environment 200 of the running, Java application.



Information about loaded types is stored in a logical area of memory called the loader environment 200. When the JVM 100 loads a type, it uses a class loader to locate the appropriate class file. The class loader reads in the class file 124 (a linear stream of binary data) and passes it to the JVM 100. The JVM 100 extracts information about the type from the binary data and stores the information in the loader environment 200. Memory for class (static) variables declared in the class is also taken from the loader environment 200.



The size of the loader environment 200 need not be fixed. As the Java application runs, the JVM 100 can expand and contract the loader environment 200 to fit the needs of the application. Implementations allow users or programmers to specify an initial size for the loader environment 200, as well as a maximum or minimum size.



The loader environment 200 can also be garbage collected by a garbage collection thread located in the function component 10. Because Java programs can be dynamically extended via class loader objects, classes can become "unreferenced" by the application. If a class becomes unreferenced, a JVM 100 can unload the class with the garbage collector thread to keep the memory occupied by the loader environment 200 at a minimum.



FIG. 2 is a block diagram representing the loader environment 200. The loader environment depicted is simplified for clarity for use in describing application and use of the invention herein. It can be readily appreciated that more complex JVM structures with larger class tables and associated memory structures can be deployed that can similarly deploy a patching environment for modifying the JVM 100 without the need to first halt the JVM.



A file of Java source code has the extension ".java" It consists of an optional package statement followed by any number of "import" statements followed by one or more "class" or "interface" definitions.



Each "class" or interface definition in a "java" file is compiled into a separate file. These files of compiled Java method bodies (bytecodes) are known as class files 124, and must have the same name as the class or interface they define, with the extension ".class" appended.



The Java class file 124 contains everything a JVM 100 needs to know about one Java class or interface, and is set out in a precise definition of the class file format to ensure that any Java class file can be loaded and correctly interpreted by any JVM 100, no matter what computer system produced the class file 124 or what system hosts the JVM 100. The class file 124 includes a what is known as a magic number--OxCAFEBABE--that designates it as a Java file. The class file also has a version number, a constant pool 130, a method.sub.13 info portion 132, and an attributes portion 134. The constant pool 130 contains the constants associated with the class or interface defined by the file. Constants such as literal strings, final variable values, class names, and method names are stored in the constant pool 130. After the constant pool 130 is the method.sub.13 info portion 132 that contains information about a method, including the method name and descriptor (for example, the return type and argument types). If the method is not abstract, the method.sub.13 info portion 132 includes the number of memory stack words (a word having sixteen bits) required for the local methods, the maximum number of memory stack words required for the operand stack of the method, a table of exceptions caught by the method, the method body sequence, and optional line number and local variable tables.



The last component in the class file 124 is the attributes portion 134, which gives general information about the particular class or interface defined by the class file 124. The attributes 134 has an attributes.sub.13 count field, and a count of the number of attribute_info tables appearing in the subsequent attributes list. The first item in each attributes portion 134 is an index into the constant pool 130 of a CONSTANT.sub.13 Utf8.sub.13 info table that gives the name of the attribute. Attributes come in many varieties. Several varieties are defined by the JVM Specification, discussed above, but varieties of attributes, according to well known rules, can be created and placed into the class file 124.



Upon loading, the class file 124 provides data to create a runtime version of the class file as a class object with a method table 208, or methods associated with the class object. The new class may refer to attributes of any previously-loaded class if it was compiled against that class.



For each class, as dictated by a class file 124, a constant pool 202 associated with that class stores the constants 130. A constant pool is an ordered set of constants used by the class, including literals (string, integer, and floating-point constants) and symbolic references to types, fields, and methods.



For each method 132 declared in the class file 124, the following information must be stored in the loader environment 200: (1) name of the method, (2) return type (or void) of the method, (3) the number and types (in order) of the method parameters, and (4) the method modifiers (some subset of public, private, protected, static, final, synchronized, native, abstract).



The method information taken from the class files 124 is divided into a class table 204, a class object set 206, a method table set 208, and a set of method bodies 210. The class table 204 points to a corresponding set of class objects 206. Each of the class objects T.sub.1, T.sub.2, T.sub.3, and T.sub.4 refer to a corresponding method table 208. Each method table 208 has pointers to point to a corresponding set of method bodies 210. As shown in FIG. 2, the loader environment has four classes in the class table 204. The address in the first class, ADDR(T1), points to the class_object(T1) of the set of class objects 206. The class.sub.13 object(T.sub.1) points to method_tb1 (A). Method.sub.13 tb1 (A) contains pointers ADDR(T.sub.1, B.sub.1), ADDR(T.sub.1,B.sub.2), and ADDR(T.sub.1,B.sub.3), which point to method bodies B.sub.1, B.sub.2, and B.sub.3, accordingly.



The data structures 204, 206, and 208 are used to allow ease of access to the method bodies B.sub.1, B.sub.2, B.sub.3, . . . B.sub.11, stored in the loader environment 200. An example of such a data structure is a method table. For each non-abstract class the JVM 100 loads into the class table 204, the JVM 100 generates a corresponding method table 208. A method table is an array of direct references to all the instance method bodies that may be invoked on a class instance.



Referring to FIG. 2, illustrated is a schematic diagram of a runtime patch environment 300 for the JVM 100. In systems that cannot be readily brought down in a controlled manner or take a large amount of time to bring down, it is preferred to modify or "patch" the program while the JVM is loaded onto its platform and operational to avoid the time and expense otherwise required.



An empty patch environment is part of the patch-capable JVM 100, and is acted on by the JVM 100 to create the patch environment 300, which is related to the loader environment 200. It should be noted that discrete memory regions can be allocated to the loader environment 200 and the patch environment 300, memory regions can be shared using conventional memory management techniques, or a hybrid memory structure can employ both allocation and memory management techniques.



For the block diagram representation shown in FIG. 2, the JVM 100 has defined a patch table data structure 302 in the patch environment 300. The data structure 300 is empty and has not yet been loaded with a patch through a patch file.



FIG. 3 is a block diagram illustrating the loading of a patch in the JVM 100. The shaded regions indicate the program structure additions generated by the JVM 100 based on the patch file 304. There are two primary patching implementations that can be conducted through the use of the patch file 304. First, altering an existing method body with a patch. Second, adding a method body with a patch.



For either of these forms of patching, a patch file 304 is generated by selecting changed, or patched, method bodies (bytecodes).



The changes are made to Java classes that are set out in the class table 204 of the loader environment 200. After making the desired changes to one or more Java classes, a patch file 304 is generated. The patch file 304 is sufficiently similar to the class file to generate a JVM patch structure similar to that in the loader environment 200. That is, the JVM 100, based on the patched-method information in the patch file 304, generates a patch object data structure 306, a patched-method table data structure 308, and a patched-method bodies data structure 310. The JVM 100 loads, in respective data structures, a patch class 302a, a class table entry 302a, a class object 306a, a patched method table entry 308a, and patched method bodies 310a and 310b. Accordingly, the patch class 302a has a pointer ADDR(T.sub.1 ') to the patch object T.sub.1 '. The patch object T.sub.1 ' refers to the patched method table 308. The patched method table 308 contains pointers ADDR(T', B.sub.1 ') and ADDR(T.sub.1 ', B.sub.2 ') to the patched method bodies 310a and 310b, accordingly. It should be noted that the use of the prime notation "'" indicates a Java patch that to a pre-loaded portion of a Java component in the JVM 100.



Once the Java strcuture, as dictated by the patch file 304, is generated, then the patched object bodies can be applied to the loader environment 200.



Altering a method body with a patched-method is shown in FIG. 4. To alter the method body, the pointers in the patched-method table 308 are exchanged with the pointers in the method table 208a in the loader environment 200. That is, the pointers ADDR(T.sub.1, B.sub.1) and ADDR(T.sub.1, B.sub.2) in the method table 208a are exchanged with the pointers ADDR(T.sub.1 ', B.sub.1 ') and ADDR(T.sub.1 ', B.sub.2 ') of the patched-method table 308.



As is illustrated in FIG. 5, following implementation of the patch, the method table 208a directs a call to the patched-method bodies B.sub.1 ' and B.sub.2 ' in the patched environment 300, as depicted through the double-dashed lines. In this manner, the method bodies for the previously-loaded classes are altered with the patched-method bodies, and any necessary compiling/linking of the new bodies can take place.



Referring to FIG. 6, in the alteration of the method bodies, the application of the patch is synchronized with respect to the execution of other code in the JVM 100 so that no interruption of function or service is necessary to apply the patch. Also, the old method bodies are retained so that the patched class can be removed by re-installing the original method bodies by reversing the swap of the pointers to the method bodies.



Referring to FIG. 6, the pointer ADDR(T.sub.1 ', B.sub.12) is appended as an element to the data structure 208a, which can be a table, array, or the like, to implement a patch adding a method body B.sub.12 to the patch environment 300. Accordingly, a call to the class at the class table 204, to the pointer ADDR(T.sub.1) points to the class_obj(T.sub.1). class_obj(T.sub.1) then points to the method table 208a. Dependent upon the action required to be taken by the class T.sub.1, the added method body B.sub.12 is pointed to by the pointer ADDR(T.sub.1 ', B.sub.12).



Although the invention has been described with reference to a specific embodiment, these descriptions are not meant to be construed in a limiting sense.



Various modifications of the disclosed embodiments, as well as alternative embodiments of the invention will become apparent to persons skilled in the art upon reference to the description of the invention. It is therefore contemplated that the claims will cover any such modifications or embodiments that fall within the true scope and spirit of the invention.

PatentNumber=6271835,FIELD OF THE INVENTION



The present invention relates to touch-screen devices for the input of alphanumeric data generally, and specifically to touch-screen devices with limited input space. In particular, the invention relates to methods and apparatus for inputting said data.



BACKGROUND OF THE INVENTION



It is well known to input alphanumeric data using a single stroke keyboard, for example, to a personal computer. A "QWERTY" keyboard is a well known keyboard wherein each key represents a particular character, the first six being labelled QWERTY from left to right. Disadvantages of such an input device include the amount of space required for the keyboard and the non-intuitive arrangement of the keys therein. The required space for a keyboard is typically limited by the number of keys necessary for the characters to be made available and the key space necessary to maintain reliable data input, i.e. to avoid multiple keys being depressed.



It is possible, however, to reduce the size of an input device, i.e. a keyboard, without reducing the number of characters which can be selected. This can be accomplished either by (i) reducing the size of the keys themselves or (ii) decreasing the number of keys and increasing the number of keystrokes. Reducing the size of the keys, however, is not a practical solution due to the aforementioned problem of multiple key depression. A "QWERTY" keyboard employed in a wireless handset, for example, would require the user to exhibit considerable accuracy in selecting the desired character. Therefore, in order to meet both requirements, one must use an input device that requires multiple keystrokes.



Prior art devices take advantage of the fact that the same number of characters on a single stroke keyboard can be made available on a keyboard with fewer keys by incorporating multiple keystrokes.



As an example of such a prior art device, the reader is directed to U.S. Pat. No. 5,003,503, issued Mar. 26, 1991, naming Lapeyre as inventor, the disclosure of which is hereby incorporated by reference. The Lapeyre patent provides for a 7 and 12 key input device that works on the general premise that a first key stroke identifies a group of characters from which a character is selected by a second key stroke. The drawbacks of such an arrangement are twofold.



First, the location of a character within its respective group of characters does not determine the second keystroke key which must be pressed to select the character. This arrangement, similar to the "QWERTY" keyboard, results in a non-intuitive method of data input in which the user must search for the appropriate selection key. Such a device therefore requires extensive use in order for a user to become familiar with its input arrangement, thus making the device cumbersome for a first time or periodic user.



Second, as a result of all available characters and their corresponding secondary keystroke number being labelled on the keys, the Lapeyre device is very cluttered and difficult to read. Again, this increases the input difficulty for a first time or periodic user.



There exists, therefore, a need for providing a clear and intuitive method of data input in an area of limited space.



SUMMARY OF THE INVENTION



It is an object of the present invention to provide a touch-screen device for the input of alphanumeric data in a manner which is intuitive to a first time or periodic user without requiring a separate key for every character. According to one aspect of the invention this objective is met by mapping sub-arrays or groups of characters to input keys wherein successive keystrokes can uniquely identify every character therein. Said input keys are not mechanical as are those on a traditional keyboard but are rather input surfaces selectable by pressing a pre-defined area of the touch-screen with one's finger. The characters mapped to said keys include alphanumeric characters, symbols and function characters; a function character being a character which represents a function such as backspace, tab or done for example.



One application of said touch-screen input device is for use in a wireless handset where there exists an obvious space limitation given the recent trend towards smaller handsets. In said application the keys necessary for the input of alphanumeric data must be large enough to be reliably selected by a user's finger. A touch-screen device utilizing a multi-stroke input sequence with a minimal number of keys is thus required--a typical 92 key keyboard being impractical in said application.



According to one embodiment, the input keys displayed on said touch-screen input device are divided into a plurality of elements, wherein the number of elements per key is less than or equal to the total number of input keys. Said elements are positioned within their respective input key to correspond to the relative position of the input keys within the input area of the touch screen. Individual characters are mapped to each individual element. Said characters include alphanumeric data, symbols and characters representing a function. To select a character a user would first select an input key displaying a group of characters, one of which is the desired character. Such a selection occurs when the user touches a plurality of elements on the same input key. Responsive to selecting a desired key, each input key is subsequently re-mapped with the characters contained within said selected key. The re-mapping process occurs such that each character is re-mapped to the key whose relative position within the input area corresponds to the relative position of said characters within the selected input key. The user then selects, with a subsequent keystroke, the desired character from the input keys re-mapped with the individual characters. This re-mapping provides a user friendly interface to first time and periodic users as the appropriate key is always labelled with the desired characters from each keystroke.



Preferably a second method of data input can be offered to the user. In addition to the two keystroke method previously discussed a single stroke method can also be employed. With respect to said single keystroke method a user can input a single character directly by touching only the individual element to which the desired character has been mapped without touching any other elements on the key. Given the size of the elements within the keys, such a single keystroke would typically require fine control by the user. This can be facilitated by means of a finely tipped instrument, for example a stylus.



First time and periodic users are further benefited by the present invention given that the character layout and the input sequence are intuitive i.e. user friendly.



One aspect of the invention provides for a touch-screen device comprising: a touch screen; means for displaying on said touch-screen a plurality of input keys; means for mapping a plurality of characters to each input key; means for determining whether an input designates a single character or a re-map command; means for re-mapping said input keys responsive to a re-map command input; means for selecting a character responsive to an input designating a particular character.



BRIEF DESCRIPTION OF THE DRAWINGS



The present invention, together with further objects and advantages thereof will be further understood from the following description of the preferred embodiments with reference to the drawings in which:



FIG. 1 is a block diagram showing the hardware and software components of a touch-screen input device according to a preferred embodiment of the invention.



FIG. 2 is a schematic diagram showing a touch-screen input device display layout according to a preferred embodiment of the invention.



FIG. 3 is a flow diagram illustrating the process carried out by the touch-screen input device software according to a preferred embodiment of the invention.



FIG. 4 is a series of schematic diagrams illustrating the input sequence, as the result of character key inputs, of a touch-screen input device according to an alternate embodiment of the invention.



FIG. 5 is a series of schematic diagrams illustrating the input sequence, as the result of element inputs, of a touch-screen input device according to an alternate embodiment of the invention.



FIG. 6 is a flow diagram illustrating the process carried out by the touch-screen input device software according to an alternate embodiment of the invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



The present invention will be described with respect to a preferred embodiment used in a wireless handset. It should appreciated by a person skilled in the art that the invention can also be utilized in other devices, for example, a personal organizer, a wrist watch, a pager, etc. which require periodic data input given a limited amount of space.



By way of example, FIG. 1 illustrates a touch-screen input device according to a preferred embodiment of the invention. Said device includes hardware 10 comprising a display 20, a touch screen digitizer 30, and a controller 40. Said controller further comprises a micro-processor 42, and associated memory 44, for example, operating memory (eg. RAM), and software storage 46. The function of said controller 40 is to control the touch screen digitizer 30 and the display 20, responsive to the software 50. Said software comprises eight sub-routines, five of which are used for operating the on-screen keyboard 60. The five sub-routines employed in the on-screen keyboard include: touch input to key mapping 62--which translates the location of a touch on the screen into an identification of which on-screen element(s) were pressed; key to action mapping 64--which, responsive to on-screen element(s) being pressed, performs the associated action; draw different keyboard 66--which re-displays the on-screen keys with new labels as determined by the key to action mapping sub-routine 64; generate character from key 68--which determine which particular character has been selected; and text stream insertion 70--which inserts the selected character into the devices keyboard input stream so that other software recognizes the character as coming from a regular keyboard. The remaining three sub-routines are part of the system software which is necessary to support the on-screen keyboard. These remaining sub-routines include: touch position recognition 72--which translates inputs to the touch-screen digitizer into screen co-ordinates; rectangle drawing 74--which draws the rectangles use to represent the various keys on the touch-screen; and text drawing 76--which draws the text characters onto the screen.



With further reference to FIG. 2, a preferred embodiment of the method steps expected by said controller as directed by said software will be described in detail.



An example of a touch screen input device layout 100 according to a preferred embodiment of the invention is shown in FIG. 2. Said input device is comprised of a text display area 110 and an on-screen keyboard 200 wherein said keyboard is divided into a plurality of keys. Said keys include four assignment keys 210, 212, 214, and 216; six character keys 220, 221, 223, 225, 227, and 229; and a "done" key 230 for terminating data input capabilities. With respect to the character keys, said keys are further divided into six elements each of which can preferably be individually selected. For example character key 220 is divided into elements 240, 242, 244, 246, 248, and 249 and is initially mapped with the characters A, B, C, D, E, and F respectively. The position of the elements within their respective character key corresponding to the relative positioning of the character keys themselves.



In operation the character keys are capable of being re-mapped either as a result of an assignment key being input or the input of more than one element of a specific character key when individual characters are mapped to the character elements. Assignment keys 210, 212, 214,and 216 determine which of the alternative character arrays 250, 252, 254 or 256 are mapped to the character keys. This results in a new group of six characters specific to the chosen character array 250 being displayed on each of the character keys. Note that in FIG. 2, the character array designated by assignment key 210 is shown mapped to the character keys. However, if assignment key 212 is pressed, a re-map command is issued to re-map the character keys with the lower case character array 252. Responsive to an input of a character key 223 wherein individual characters are mapped to each of the elements, said character keys are re-mapped with the individual characters included within said selected character key 223. In this example, key 223, the upper right most character key, will be re-mapped with the letter `O` 290, the character which was mapped to the element of the selected key 223 whose position corresponds to said character keys, i.e. the upper right most element. This re-mapping results from the input of multiple elements on the same character key 220. Once re-mapped in this manner a user could then select an individual character by the input of any number of elements on the character key 225 which has the desired individual character mapped to it.



Preferably, a user could alternatively select a specific character directly without a re-mapping step by limiting the input to a single element containing the desired character. This would occur at the stage when individual characters are mapped to said character key elements 240 and would by accomplished, for example, by means of a stylus which can be used to press a single element only.



FIG. 3 is a flow diagram outlining the data input steps implemented by the controller 40. With reference to FIG. 3, once the touch-screen input device is notified in a suitable manner that data input is requested by the user, the initialization sequence begins 500. The controller displays the touch-screen keyboard 510 and selects a default array of characters 520 which are mapped to the character key elements 530. At this stage the input sequence begins with the controller waiting for a user input 540. Upon receiving an input of any kind, i.e. the screen is touched, the micro-controller identifies the position of said input, via the touch screen digitizer and the touch position recognition software described in FIG. 2. From this the controller determines whether an on-screen key has been touched 550. If the position of the input, i.e. the user's finger or stylus, does not correspond to the position of a key, the waiting process 540 is re-initiated. Otherwise, the controller proceeds to determine whether the command key "done" was touched 560. If said determination is positive the data input sequence terminates 570. If said determination is negative the controller determines whether an assignment key was touched 580. Responsive to an assignment key being touched, controller selects the appropriate character array 590, and re-maps the characters included in said array to the elements of the character keys 530 and re-starts the input sequence by waiting for an input 540. An input of a key other than an assignment key will prompt the controller to inquire whether a key with a single character on it was input 600. If a key with a single character on it was input, the controller inserts that character into the text stream or performs the function associated with said character 610 and, after resetting the original mapping of the characters of the appropriate array to the input key elements 530, re-starts the input sequence 540. If the key input did not have a single character displayed on it, the controller determines whether a single element of a character key was input 620. If a single element was input the controller inserts that character into the text stream or performs the function associated with that character 630 and, after re-labelling 530 has occurred, re-starts the input sequence 540. If a single element was not input, the micro-controller maps single characters to the input keys 640 and restarts the input sequence by waiting for an input 540.



One should note that the assignment keys are not necessary for the functionality of the described invention. Said assignment keys merely offer the user an expanded number of available characters, analogous to a "shift" key on a "QWERTY" keyboard. Said keys could also be included as characters within the character keys as opposed to being distinct. One should also note that much like the assignment keys the "done" key shown in the aforementioned embodiment could be easily represented by a character mapped to a character key.



A person skilled in the art should appreciate that there are many ways of accomplishing the above described method of data input.



The description of the preferred embodiment disclosed above can easily be extended to include a multiple layer input method. This is beneficial where the constraint of space is greater than that previously discussed. For example, in small devices such as a pager, six keys may require more space then is available. A solution to this problem is achieved by increasing the number of input layers. Instead of having individual characters mapped to specific elements, arrays of characters could be used. For example, by using a four stroke touch-screen input device (two stroke if individual elements chosen) as shown in FIG. 4, three keys could provide 3.sup.4 or 81 characters. Although said keyboard is shown without the assignment keys as mentioned in the previous embodiment, said keys could be easily added to offer a greater number of available characters.



With respect to this alternate embodiment the hardware described previously in FIG. 1 would be the same. The software would contain similar sub-routines as those discussed previously but would be modified accordingly to implement the method that follows. A person skilled in the art should appreciate that the number of keys (and elements therein) and input layers chosen are for the purposes of example only. One could reduce the number of keys and increase the number of input layers or reduce the number of layers and increase the number of keys to obtain the optimum balance between key strokes and the number of keys--while maintaining a similar number of available characters.



FIGS. 4a, 4b, 4c, and 4d show four on-screen keyboards and demonstrate the input sequence as the result of character key inputs. One should recall that an input of a character key results from an input of a plurality of elements on the same character key. Each keyboard shown in FIGS. 4a, 4b, 4c and 4d comprise of a set of 3 character keys 1000, 1010, and 1020, wherein each character key is comprised of 3 elements. For example character key 1000 in FIG. 4a is divided into 3 elements 1030, 1040 and 1050, which are mapped with character sub-arrays A-I, J-R and S-.sub.-- respectively. Each set of character keys shown displays a different mapping of character to the character keys, each mapping representing a different input layer or order. FIG. 4a shows a keyboard displaying 3.sup.rd order character sub-arrays mapped to said character keys. The order of the sub-array refers to the number of successive character key input steps (as opposed to element inputs) a user would have to perform in order to have single characters displayed on said character keys. FIG. 4b, 4c and 4d show b 2.sup.nd order sub-arrays, 1.sup.st order sub-arrays and particular characters mapped to the character keys respectively. FIGS. 4a through 4d show the re-mapping and selection process which occurs as the result of successively inputting character key 1000. Referring to FIG. 4a responsive to an input of character key 1000 to which a 3.sup.rd order sub-array is mapped, the character keys are re-mapped with the corresponding 2.sup.nd order sub-arrays as shown in FIG. 4b. Note that the characters mapped to the keys in FIG. 4b are, A-I, J-R and S-_, are those characters which were included in the 3.sup.rd order sub-array of the selected character key 1000. At this stage, an input of the same character key 1000, which has the 2.sup.nd order sub-array A-I mapped to it, results in a re-mapping of said character keys with the corresponding first order sub-arrays as shown in FIG. 4c. Yet another input of the same character key 1000, now mapped with the first order sub-array A-C, results in the corresponding individual characters being mapped to said character keys. The process ends with the input of character key 1000 which has the individual character `A` mapped to it. Responsive to said input the character `A` is inserted into the text stream. After the selection of an individual character said character keys are re-mapped with the default 3.sup.rd order sub-arrays shown in FIG. 4a and the process begins again.



FIGS. 5a, 5b, 5c, and 5d show the same key layout as described in FIG. 4, but differ in that they demonstrate the method of re-mapping character keys as the result of a single element being input. Starting with 3.sup.rd order sub-arrays mapped to the character keys as shown in FIG. 5a, an input of the single element 1030 results in the re-mapping of said character keys with the 1.sup.st order sub-arrays which correspond to the selected element input. This is shown in FIG. 5c. Notice that the characters mapped to the selected character element 1030 in FIG. 5a (A-I) are now mapped to the character keys in FIG. 5c. At this stage an input of the same character element 1030 results in the selection of the character mapped to the selected element, which in this example is the letter `A`. Said selected character is then inserted into the text stream.



The character keys are then re-mapped with the default 3.sup.rd order sub-arrays as shown in FIG. 5a.



FIG. 6 is a flow diagram outlining the input steps for the multiple layer input of data. Similar to the discussion of FIG. 3, once the input device is notified that data input facilities are desired 2000, a keyboard is requested 2010, a default character array is selected 2020, and the base sub-arrays of the selected character array (default array initially) are mapped to the character keys 2030. At this point the micro-controller waits for a user input 2040. Upon receiving an input, i.e. the screen is touched, the micro-controller determines if the position of said input corresponds to the position of an on screen key 2050. If the screen was touched in a position which does not represent an on screen key, the micro-controller begins waiting for another user input 2040. However, once a key is selected, the micro-controller proceeds to the next step of determining whether said key which was input was the "done" key 2060. If said key input was the "done" key, the input sequence terminates 2070. Otherwise, the micro-controller must determine whether an assignment key was input 2080. If an assignment key was input, the appropriate character array is selected 2090 and the base sub-arrays of said character array are re-mapped to the character keys 2030. At this stage the input sequence starts over by waiting for a user input 2040. An input of a key other than an assignment key, prompts the micro-controller to determine whether a key with a particular character displayed on it is input 2100. If said determination proves positive, the character displayed on said key is inserted into the character text stream or the function associated with said character is performed 2110. Said character keys are then re-mapped with the base sub-arrays of the selected character array 2030. At this point the input sequence would re-initiate 2040. If particular characters were not displayed on said character keys, the next stage determines whether a single element was input 2120. If this determination is negative, i.e. multiple elements on the same character key were input, the micro-controller then determines whether the displayed sub-arrays were of 1.sup.st order 2130. If the sub-arrays were of 1.sup.st order the characters within said sub-array are mapped to the particular character keys 2150. If the sub-arrays were not of 1.sup.st order, sub-arrays of one order less are mapped to the character keys 2140. Referring back to the single element determination step 2120, if a single element was selected, the micro-controller must then determine if 1.sup.st order sub-arrays were displayed on said character keys 2160. If said 1.sup.st order sub-arrays were displayed on said keys, the character displayed on said selected element is inserted into the text stream or the function associated with said character is performed 2170. The character keys are then re-mapped with the selected base sub-arrays 2030, and the input sequence re-initiates 2040. If the sub-arrays were not of 1.sup.st order the micro-controller determines whether they were of 2.sup.nd order 2180. If said sub-arrays were of 2.sup.nd order, the characters within said input elements are mapped to the particular character keys 2190. If said sub-arrays were not of 2.sup.nd order, i.e. of an order greater than 2.sup.nd, the sub-arrays within the input element (two orders less) are mapped to the character keys 2200, and the input sequence starts over 2040.



Again one should note that the assignment keys are not necessary to the functionality of the invention, but are merely for providing a greater number of available characters. Also as mentioned previously said assignment keys, and said "done" key need not be distinct keys but could be easily represented by a character within the character arrays.



Numerous modifications, variations and adaptations may be made to the particular embodiments of the invention described above without departing from then scope of the invention, which is defined in the claims.

PatentNumber=6298057,BACKGROUND OF THE INVENTION



1. Field of the Invention



The present invention relates generally to the field of telecommunications and more particularly to the field of transmitting aural information through a wide area network.



2. Description of Background Art



Conventional aural communication is accomplished using a public switched network, e.g., the telephone network. Through the use of such a public switched network users can easily communicate with each other by transmitting aural signals from a first terminal to a second terminal through the public switched network. The aural signals can represent voice data, modem data, or facsimile (fax) data, for example. In order to transmit voice data, a user performs a conventional procedure for setting up a call, and for tearing-down a call. In one example of a conventional call setup procedure, a user lifts a handset on a first telephone, listens for a dial-tone, and then enters a code identifying a destination telephone. A user at the destination telephone is notified that a connection is pending, e.g., by hearing the destination telephone ring, and the user lifts the handset. After the handset of the destination telephone is lifted, a connection between the first telephone and the destination telephone is established. As each user speaks, the sound is transformed and then transmitted through the telephone, through a private branch exchange (if any), through the public switched network, and then to the destination telephone where the transformed signal is re-transformed into an audible signal that can be heard by the user at the destination telephone.



Recently, communication systems have been developed that enable aural data to be transmitted over a wide area network (WAN). In these systems a private branch exchange (PBX) is connected to a communication device, e.g., a router, switch, FRAD, or multiplexor, that connects two networks having different data formats, e.g., a local area network (LAN) and a WAN. An example of a data format is a packet. A packet is a group of bits having a header portion and a data portion. The format of a packet can be different for each LAN and WAN. For example, the maximum size of a packet and packet destination and routing information can differ between networks. A router or a switch, hereafter referred to as a router, that also handles aural data converts a packet from a first format that is compatible with the PBX to a second format that is compatible with a WAN. After receiving the aural signals from the PBX, the router converts the aural signals into packets, transmits the packets across a WAN where they are received by a second router that is connected to a second PBX, key system or telephone. The second router converts the packets into aural signals and transmits the signals to the PBX, key system or telephone. There are problems with connecting a source of aural information directly to a router. One problem is that the format of aural information and the format of information that can be received by the network router are typically incompatible and, in general, a specially developed router must be used to enable the PBX to transmit data through a WAN. A second problem is that routers are, typically, not capable of being inexpensively modified to receive telephony functionality, for example, it is difficult to add a circuit board having the required telephony functionality to a router. Accordingly, in order to add telephony compatibility and functionality to a WAN, a WAN user must replace the existing routers. This is an expensive solution. A third problem is routers that are compatible with a PBX or a KTS generally provide proprietary solutions that are not compatible with those of other routers. A fourth problem is that such solutions are not generally available in routers, thus limiting the options of a user.



Another technique for transmitting aural signals across a WAN is to connect a microphone and a speaker to a conventional personal computer (PC). A user loads and executes a software program that converts the received analog signal to a digital signal using the processor in the PC. The signal may be sent over a LAN to a router. The router transmits the signal over a WAN to a second router. The second router may transmit the signal over a second LAN, or directly, to a destination PC. If the destination PC is operating compatible software, the PC can convert the received signal back to an audible signal that is transmitted through the PC's speakers. While this technique is less expensive than the first technique, it also has limitations. One limitation is that such systems are currently incapable of providing a priority mechanism that would ensure that aural data arrives within a predetermined maximum time period. Most data currently transmitted through WANs are not time sensitive, i.e., a small delay in receiving data is acceptable if the data is accurate. However aural communication is time sensitive, i.e., it is generally more important for aural data to be received in a timely manner than it is for the data to be absolutely accurate. If, while a user is speaking into a microphone, another computer that is coupled to a router via the LAN requests a transfer of a large file, e.g., a computer aided design (CAD) file, the packets of voice data that are received by the first router after the first router begins transmitting the packets of the CAD file may incur a significant delay if the router transmits all of the packets of the CAD file before transmitting the aural packets. In this situation, the second user will experience a significant delay in the reception of aural signals.



A second limitation is that due to limitations on host processing capability, the quality of the received aural signal is significantly degraded when compared to the transmitted aural signal and cannot be characterized as a toll-quality or near-toll-quality signal. The public switched networks in the industrialized countries provide a toll-quality signal. A near-toll-quality-signal is within 0.5 point of the toll-quality signal as measured by the means-opinion-score (MOS) method, on a scale of five, as determined by listening tests. A signal that is 1.0 point below the toll-quality signal is generally characterized as a communications-quality signal. The MOS method is described in greater detail in ITU-T Recommendation P.83, Subjective Performance Assessment of Telephone-Band and Wideband Digital CODECS, (March 1993), that is incorporated by reference herein in its entirety.



A third limitation is that the software for converting an analog aural signal from the microphone into an aural packet that is compatible with the LAN requires significant computational power that is provided by the processor in the PC. As a result of this additional computational load on the processor, the processing capability of the computer that is available for processing other application programs, is significantly reduced.



A fourth limitation is that the call setup and conversation between two users is not transparent. That is, the quality of the received signal is not at a near-toll-quality standard, and the procedures used to initiate the connection and to maintain the connection are not conventional. Instead of lifting a handset, listening for a dial-tone, and entering a destination identifier on a telephone keypad, the user executes a software program, types a destination identifier using a computer keyboard and then talks into an external microphone and listens though speakers attached to the PC. Similarly, to receive the audible signals, the user must, for example, execute a software program, use a mouse to click on an "answer" button, and turn on the speakers. This lack of transparency requires users to re-learn how to communicate with a person at a remote location.



Accordingly, what is needed is a system and method: (1) for transmitting aural information as digital signals over a wide-area-data-network; (2) for transparently generating and receiving aural data; (3) that incorporates a robust error correction procedure that enables a receiver to recreate lost data; (4) that converts aural signals into a network compatible format, and that performs compression and decompression algorithms on the converted data without placing a significant computational load on a host processor; (5) that uses a router/switch priority system to minimize the end-to-end packet delay across a wide area network; (6) that adjusts the destination signal based upon packet delay variations; (7) that communicates with a router/switch over a standard LAN connection without requiring a specialized router/switch voice interface; and (8) that can connect to a LAN with a standard interface and can communicate over the LAN in standard data formats.



SUMMARY OF THE INVENTION



The invention is a system and method for transparently transmitting aural signals across a wide area network (WAN). The system of present invention is quickly and inexpensively installed in a server or a personal computer coupled to a local area network. The system is connected to one or more of a private branch exchange, a key telephone system, a telephone, a facsimile machine, and a modem. In the case of voice transmission, a user places a telephone call using the same procedure that is used when placing a telephone call over a conventional public switched network. The aural signals are translated into a format that is compatible with the local area network (LAN) and the translated signals are transmitted to a router or a switch that connects the LAN to the WAN. The data is transmitted across the WAN to a router or switch coupled to a second LAN. The data is then sent to a destination central site unit or PC which translates the signal into a format that is compatible with the telephone system connected thereto. The present invention provides a voice quality that approaches, equals, or exceeds the voice quality of conventional telephone switched networks. This high voice quality is achieved by utilizing a high quality voice digitization algorithm, by ensuring a low maximum network delay, by dynamically compensating for variations in network delay, and by using a forward error correction technique that can recreate lost or delayed signals in a manner that recreates the signal so the lost signal is typically not detectable by a user.



The benefits of the present invention include: (1) transmitting aural information as digital signals over a wide-area-data-network; (2) transparently generating and receiving aural data; (3) incorporating a robust error correction procedure that enables a receiver to recreate lost data; (4) converting aural signals into a network compatible format, and performing compression and decompression algorithms on the converted data without placing a significant computational load on a host processor; (5) utilizing a router/switch priority system to minimize the end-to-end packet delay across a wide area network; (6) adjusting the destination signal based upon packet delay variations; (7) communicating with a router/switch over a standard LAN connection without requiring a specialized router/switch voice interface; and (8) connecting to a LAN with a standard interface and communicating over the LAN in standard data formats.



BRIEF DESCRIPTION OF THE DRAWINGS



FIG. 1 is an illustration of a computer network environment in which the preferred embodiment of the present invention operates.



FIG. 2 is a more detailed illustration of a PC/file server, and a phone/fax server card installed therein, having an analog telephony interface according to the preferred embodiment of the present invention.



FIG. 3 is a more detailed illustration of a digital voice module component of the phone/fax server card according to the preferred embodiment of the present invention.



FIG. 4 is a more detailed illustration of a PC/file server memory module according to the preferred embodiment of the present invention.



FIG. 5 is a flow chart illustrating a call setup procedure according to the preferred embodiment of the present invention.



FIGS. 6A and 6B are flow charts illustrating an aural signal transmission procedure according to the preferred embodiment of the present invention.



FIG. 7 is an example of the forward error correction (FEC) process illustrating three voice packets, packet A, packet B, and packet C.



FIG. 8 is a more detailed illustration of a PC/file server and a phone/fax server card having a digital telephony interface according to an alternate embodiment of the present invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT



A preferred embodiment of the present invention is now described with reference to the figures where like reference numbers indicate identical or functionally similar elements. Also in the figures, the left most digit of each reference number corresponds to the figure in which the reference number is first used.



FIG. 1 is an illustration of a computer network environment in which the preferred embodiment of the present invention operates. FIG. 1 illustrates a first local configuration 102A coupled to a second local configuration 102B by a wide area network (WAN) 104. The first and second local configurations include a router 114, 132, file servers or personal computers (PCs) 112, 122, 130, and local area networks (LAN) 116, 134. Examples of LANs include an ethernet and a token ring network, an examples of a WAN include leased lines, frame relay, asynchronous transfer mode (ATM) networks, and the Internet. The present invention enables a user to transmit aural signals across a WAN using conventional telephones, facsimile machines (fax), and modems, i.e., in a transparent manner. It will be apparent to persons skilled in the relevant art that the present invention can operate on many different types of LANs and WANs without departing from the scope of the present invention. The first local configuration 102A includes two telephones 106, 108 coupled to a key telephone system (KTS) 110. In the present invention, the KTS 110 is coupled to a phone/fax server card (PFSC) located on a PC or a file server 112 via signal lines 107. In the preferred embodiment, the PFSC is located on a server. Accordingly, the description of the PFSC will be with respect to a file server. As described below, in an alternate embodiment, the PFSC is configured in a PC or other host processor system. The file server 112 and PFSC are described in greater detail below. The file server 112 is connected to the LAN via a network interface 113. The network interface 113 is coupled to the router 114 via the LAN 116. The router 114 receives data from devices in the first local configuration 102A, e.g., the file server 112. The data can be in the form of packets, as described below. The router transmits the packets from the local configuration 102A to the WAN 104 and then the packets are routed through the WAN 104 to a second router 132 in the second local configuration 102B. In an alternate embodiment of the present invention, a network switch or hub can be used in conjunction with, or in place of, the routers 114, 132.



The second local configuration 102B includes a second file server 122 having a phone/fax server card that is coupled directly to a telephone 118 and to a fax 120. The second LAN 102B is also coupled to a phone/fax server central site unit (CSU) 130. The CSU 130 is a PC that only performs operations related to the operation of the one or more phone/fax server cards located therein. The CSU 130 can contain multiple cards and is, generally, more reliable than either stand alone PCs or file servers because PCs and file servers typically also perform operations and run application programs not related to the PFSC. The CSU 130 is coupled to a conventional private branch exchange (PBX) 128 which in turn can be coupled to many telephones or faxes. In FIG. 1, two telephones 124, 126 are connected to the PBX 128. The second local configuration 102B includes a network interface 123 that is communicates through the LAN 134 to the router 132, the second file server 122, the CSU 130, and the remaining devices attached to the LAN 134. The second local configuration 102B is an example of a LAN connecting multiple devices, for example, each server 122, 130 can be connected to a hub in a different building.



The present invention is a system and method for enabling aural signals, e.g., voice signals, facsimile (fax) signals, and modem signals, to be transparently generated and transmitted to a phone/fax card located in a file server 112 coupled to a computer network or in a personal computer coupled to a first local configuration 102A. The file server 112 performs a setup operation to prepare a connection between two aural signal generation devices, e.g., between the first telephone 106 in the first local configuration 102A and the second telephone 126 in a second local configuration 102B. After setting up the connection, the PFSC in the file server 112 converts the received aural signals into digital signals and compresses the digital signals. Packets are generated from the compressed digital signals and these packets are transmitted to the router 114 via the LAN 116. The router transmits the packets across a wide area network (WAN), e.g., leased lines, frame relay, or the Internet, and the packets are received by the second router 132 in the second local configuration 102B. The second router 132 transmits the packets to the destination CSU 130. The destination CSU 130 converts the compressed digital signals in the packet into aural signals and transmits the aural information to the PBX 128 which transmits the signal to the second telephone 126. A more detailed description of the operation of the present invention is set forth below.



The present invention provides a cost-effective system and method for transmitting aural information from an aural signal generating device that is connected to a first local configuration 102A to an aural signal receiving device, e.g., the second telephone 126, connected to a second local configuration 102B, where the first local configuration 102A and the second local configuration 102B are both connected by a WAN 104. As described above, an aural signal generating device and an aural signal receiving device can be, for example, a telephone, a fax, or a modem. The present invention can reside in a server 112 or in a personal computer, for example. In contrast, previous systems couple a PBX, key system, or telephone, directly to a router 114. Routers are typically designed such that the user does not have the capability to add functionality thereto, other than that functionality provided by the manufacturer of the router. Accordingly, a router designer and manufacturer must include the aural transmission capability in the router. The user is thereby unable to modify an existing LAN environment to add voice communication capability without replacing the existing routers at a significant additional expense. The present invention enables a user of a LAN/WAN network to quickly and inexpensively add a near-toll-quality, transparent, aural transmission system to a network by installing hardware and software in a PC that are coupled to a LAN in the network. As described above, previous attempts at providing such functionality have provided solutions that are of lesser quality and are generally not acceptable for business use because the quality of the aural signal was low and the interface with the users was not transparent.



In the preferred embodiment, the present invention includes a phone/fax server card (PFSC) that is controlled by software, as described below. Preferably, the PFSC is located in one PC, one file server 112, or a dedicated CSU 130 per office or LAN site. File servers 112, or a CSU 130 are typically always operating. In contrast, a PC is generally less available because a user may turn off the PC or operate less robust programs than on a server 112 which can cause the PC to fail. However, in an alternate embodiment, one or more PFSCs can be installed in a PC that is connected to a LAN, e.g., for use in an office without a server on the LAN. For ease of discussion, the description set forth below will describe a telephone call between a user at a first telephone 106 and a user at a second telephone 126 wherein the user of the first telephone initiated the call and where the first telephone 106 is coupled to a file sever 112 via a KTS 110 and the second telephone is coupled to the CSU 130 via a PBX 128.



FIG. 2 is a more detailed illustration of a file server 112 and a PFSC 202 having an analog telephony interface according to the preferred embodiment of the present invention. With respect to the present invention, the CSU 130, the second file server 122, and a PC (not shown) each has a PFSC 202, and each operates in substantially the same manner as the file server 112. Any distinctions between the operation of the present invention and any of these devices are apparent to persons skilled in the relevant art. The file server 112 can be a conventional PC that is utilized as a file server. The file server 112 includes a network interface card (NIC) 218, a processor 216, a server memory module 214, and a PFSC 202. The NIC 218 can be a conventional NIC, for example, a 3C509 NIC that is commercially available from 3Com Corp., Santa Clara, Calif. The NIC 218 converts signals from the file server 112 into a format used by the LAN 116. A benefit of the present invention is that the PFSC 202 installs and operates in a standard manner that is compatible with the operating system of the server, e.g., Novell NetWare, Microsoft Windows 95, or Microsoft Windows NT server. The present invention utilizes the capabilities of the NIC 218 to convert the signals into the format used by the LAN 116. This simplifies the design and cost of the PFSC 202. The processor 216 of the file server 102A can be an x86 based processor or a Pentium Pro processor, for example, manufactured by Intel Corporation, Santa Clara, Calif. The server memory module 214 is a conventional random access memory (RAM) that includes an operating system and non-conventional application programs stored therein. The server memory module 214, and the non-conventional application programs are described in greater detail below.



The analog PFSC 202 includes a ring voltage power converter 220, two channel analog interfaces 204, two coder-decoders (codecs) 206, two digital voice modules (DVMs) 208, a PC interface module 210, and a PFSC memory module 212. Each channel analog interface 204 is connected to the trunk lines of the KTS 110. With respect to the PFSC in the CSU 130, the analog interface 204 is coupled to the trunk lines of a PBX. In general, each channel analog interface 204 connects to a telephony interface, e.g., a PBX, a KTS, telephones, faxes, and modems. Each channel analog interface 204 also provides ring voltages for foreign exchange station (FXS) interfaces and for ear and mouth (E&M) interfaces. If the analog interface 204 is connected to a foreign exchange office (FXO), the analog interface 204 performs conventional ring detection, loop closure, loop open detection, and 2 to 4 wire conversion using, for example, transformers or solid state circuitry. The operation of the channel analog interfaces 204 is described in greater detail below. The codec 206 is a conventional codec, for example, model number 3070, that is commercially available from National Semiconductors, Santa Clara, Calif. The codec receives analog signals from the channel analog interface 204 and converts these signals into a digital signal, e.g., a pulse code modulation (PCM) signal using a conventional conversion technique. The rate of the bit stream generated by the codec is 64 kilobits per second (kbps). These bits are sent to the DVM 208. The DVM determines the type of signal represented by the bits, e.g., a voice signal, a fax signal or a modem signal, then the bits are framed and sent to the PC/interface module 210. If the bits represent a voice signal, then the DVM 208 compresses the bits, generates correction information that is used to regenerate information that may be lost during transmission, organizes the bits and the correction information into frames, and transmits the frames to the PC/interface module 210. The PC/interface module 210 stores the frames in the PFSC memory module 202 and notifies the server 112 that a frame is available. The operation of the PFSC 202 is described in greater detail below.



FIG. 3 is a more detailed illustration of the DVM 208 according to the preferred embodiment of the present invention. The DVM 208 includes a digital signal processor (DSP) 302 coupled to a data bus 322. In addition, the DVM 208 includes an input/output (I/O) and bus logic unit 306 and a DVM memory module 304 each of which is coupled to the data bus 322. The DSP 302 is a conventional processor, e.g., a TI 320C52-80 DSP that is commercially available from Texas Instruments Inc., Dallas, Tex. The I/O and bus logic unit 306 includes conventional address decoding logic and bus interface logic. The DVM memory 304 is comprised of conventional memory, e.g., static random access memory (SRAM), and flash erasable programmable read only memory (EPROM). The DVM memory 304 stores a data buffer 314 and a Call ID Unit 308 that, when executed by the DSP 302, determines the type of signals received, e.g., voice, fax, or modem signals. Depending on the type of signals received, the Call ID Unit 308 instructs the DVM 208 to store various other functional modules in the DVM memory 304. If the received signals are either fax signals or modem signals, a framer 318 and a call management unit 310 are stored in the DVM memory 304 for creating data frames from the received data. If the received signals are voice signals, then the Call ID unit 308 instructs the DVM 208 to store a call management unit 310, a voice unit 312, a jitter buffer 316, a framer 318, and a voice enhancement unit 320 in the DVM memory 304.



The functional modules operate in conjunction with the DSP 302. The call management unit 310 receives signals representing server codes and destination address identifiers. The call management unit 310 also determines when a preferred number of signals, representing dialed digits, are received and transmits these digits to the PC/interface module 210. The call management unit 310 also performs other telephony functions including echo canceling, DTMF tone detection and generation, pulse dialing, modem and fax tone detection and generation, and generating instructions requesting the generation of a ring voltage. The voice unit 312 receives the 64 kbps bit stream from the codec 206A and converts the bit stream into an 8 kbps bit stream using a conventional compression technique. The voice unit 312 also decompresses a bit stream received from the PC/interface module 210 and transmits the decompressed signal to the codec 206, e.g., when the DVM 208 receives voice signals. The data buffer 314 temporarily stores data until the data is transmitted to either the codec 206 or the PC/interface module 210. The jitter buffer 316 is a variable length buffer that stores voice signals received from the PC/interface module 210. The size of the jitter buffer is dependent upon the variation in the end-to-end packet delay in the network and can be dynamically adjusted based upon, for example, this packet delay variation.



The voice enhancement unit 320 performs a forward-error-correction (FEC) operation to generate bits that can be used to recreate a lost packet. In an alternate embodiment, the voice enhancement unit can be a part of the server memory module 214. When receiving voice signals, the voice enhancement unit 320 performs the packet recreation process. The voice enhancement unit 320 also generates a time stamp that identifies the sequencing of packets, allowing the destination server to estimate when a subsequent packet of data is to be received. If this time expires before the subsequent packet is received, the voice enhancement unit of the destination server 320 recreates the packet. The packet recreation technique is described below. The voice enhancement unit 320 also dynamically measures the end-to-end delay in the network and adjusts the size of the jitter buffer 316 accordingly, as described above. The voice enhancement unit 320 can also dynamically adjust the rate of the bit stream from 8 kbps in the preferred embodiment to a slower rate, e.g., 6.4 kbps or 4.8 kbps. The framer 318 creates a frame that includes data representing a predetermined amount of voice signals, e.g., 20 milliseconds (ms). The framer 318 can also includes time stamp information, and, if selected, FEC information in a frame. The operation of the DVM 208 is described in greater detail below.



FIG. 4 is a more detailed illustration of the server memory module 214 according to the preferred embodiment of the present invention. The server memory module 214 is a conventional random access memory (RAM) that includes non-conventional application programs. These application programs include a communication management unit 402, a call setup/tear-down unit 404, a directory 406, a directory management unit 408, a network packetizer 410, a configuration unit 412, a voice/fax/modem program unit 414, a priority management unit 416, a standard network management protocol (SNMP) network management unit 418, a NIC interface unit 420, a PFSC device driver 422, and an overflow jitter buffer 424.



The communication management unit 402 determines the type of data that a received frame or packet represents, e.g., voice, fax, modem, or another type of data. Based upon this determination, the communication management unit 402 calls the other various functional programs to properly evaluate and transmit the data. The call setup/tear-down unit 404 performs and controls the call setup procedure and the call tear-down procedure, as described below. The directory includes server code identifiers and a network address associated with each server code identifier. The directory management unit 408 controls access to the directory. In addition, the directory management unit can request that a search be performed in a master directory for a server code that in not in the local directory, e.g., directory 406. The master directory is located at one server in the network 100 and typically contains the most current version of the network directory. In some network environments, the master directory transmits its contents periodically, e.g., daily, to all of the local directories in the network 100. When transmitting data, the network packetizer creates a packet of data that includes one or more frames and adds a packet header that includes the network address of the destination CSU. When receiving data, the network packetizer receives a packet, and removes the packet header. The configuration unit 412 includes information identifying each of the one or more PFSCs 202 on the server 112 and information identifying each channel address for each PFSC 202. In addition, the configuration unit 412 includes information identifying the type of dial tone, ring tone, and call progress tone, e.g., as used in a particular country, and the type of telephony service on each channel, e.g., FXO, FXS, or E&M.



The voice/fax/modem program unit 414 includes functional program modules that are transferred into the DVM memory 304, e.g., the voice unit 312 and the voice enhancement unit 320. The priority management unit 416 controls the data priority request process, as described below. The SNMP network management unit 418 controls the conventional SNMP for the server. The SNMP permits remote reporting of the server status and modification of server configuration parameters, e.g., modification of the jitter buffer size and enablement and disablement of the FEC process. The NIC interface unit converts the packets into a format that is compatible with the LAN attached to the server, e.g., ethernet or token ring. The format, e.g., the protocol, required by these LANs is known and the procedure for converting a data packet to a compatible format is apparent to persons skilled in the relevant art. The PFSC device driver 422 enables the server to communicate with the PFSC 202 by providing, for example, a conventional interrupt process to transfer data and management information between the server and the PFSC 202. The overflow jitter buffer 424 permits data to be temporarily stored when network delay variation is larger than what can be properly handled by the jitter buffer 316. The functions performed by the functional programs are described in greater detail below with reference to FIGS. 5-6.



FIG. 5 is a flow chart illustrating a call setup procedure according to the preferred embodiment of the present invention. For the example described below, the telephone call setup procedure provides a connection between the first telephone 106 and the second telephone 126. The first telephone is connected to a KTS 110 that is connected to a PFSC 202 via channel 1 and the second telephone is connected to a PBX 128 that is connected to a PFSC via channel 1. A user activates the telephone by, for example, lifting a handset and selecting the channel line in order to transition 502 to an off-hook state. The first channel analog interface 204A, using conventional procedures, detects the off-hook condition and generates a conventional dial tone that is transmitted to the KTS 110 and to the first telephone 106. A user, hearing a dial tone, dials a telephone number that is associated with the second phone. The procedure utilized by the user when placing a telephone call over the WAN 102 is the same as the procedure used by the user if he/she were to use a conventional public telephone system. That is, the user activates a telephone (or fax or modem), dials a number identified with the destination telephone (or fax or modem), speaks into a conventional microphone in a telephone and, when the other person speaks, or the fax or modem transmits the destination user receives a signal having a quality that approaches, equals, or exceeds the quality of an aural signal transmitted through a public switched network. That is, the procedure for using the present invention is "transparent" to the user. Accordingly, users do not need to re-learn how to use the present invention and do not notice any significant difference in the quality of the signal.



The user transparently enters 504 a telephone number that uniquely identifies the destination telephone using, for example, a keypad or a rotary dial on a telephone. In the preferred embodiment, the first set of digits identifies the destination CSU 130 through which the second telephone 126 is connected to the second LAN 134. This set of digits is called the server code. The number of digits in the server code is, generally, predetermined as a configuration parameter. However, in alternate embodiments, the number of digits in the server code can vary depending upon, for example, the destination CSU. In the preferred embodiment, the server code is from 1-16 digits in length and is fixed for the network as a network configuration parameter. The channel 1 analog interface 204A sequentially receives the digits and the codec 106A converts the received analog signal into a digital signal. The call management unit 310 in the DVM 208A receives the signals representing the digits and stores a digit representation in the data buffer 314. When the call management unit 310 receives 506 all digits of the server code, it transmits the server code to the PFSC memory module 212 and the PC/interface module 210 generates an interrupt signal to the server 112.



The PFSC device driver 422 receives the interrupt and notifies the communication management unit (CMU) 402 of the interrupt. The CMU 402 then notifies the call setup/tear-down unit 404. The call setup/tear-down unit 404 retrieves the server code from the PFSC memory module 212 and transmits the server code to the directory management unit 408. The directory management unit 408 searches the local directory 406 for a server that is identified with the server code. If no server matches 508 the received server code in the local directory 406, the directory management unit 408 generates a request to a master directory. A directory management unit for the master directory determines 510 if the received server code is identified with any server in the network. As described above, the master directory is more accurate than the local directory 406. If no server is identified with the server code, an error condition exists and the DVM 208A instructs the channel 1 analog interface 204A to transmit a trunk busy signal to the first telephone 106. If the server code is identified in the master directory, the network address of the destination CSU associated with the server code is transmitted to the directory management unit 408 along with a indication of the number of additional digits that the destination CSU uses to precisely identify an attached device, e.g., a telephone, a fax, or a modem. The number of additional digits can vary depending upon the number of channels and the number of aural devices the destination CSU supports. The directory management unit transmits the network address of the destination server and the number of addition digits to the call setup/tear-down unit 404. The call setup/tear-down unit 404 transmits the number of additional digits to the call management unit 310 of the PFSC 202 via the PFSC device driver 422.



The user continues dialing and the call management unit stores the digit information in the data buffer 314. After receiving the required number of additional digits or after a period without receiving any additionally dialed digits, e.g., 10 seconds, the call management unit 310 transmits these digits to the call setup/tear-down unit 404 using the technique described above with respect to transmission of the server code. The call setup/tear-down unit 404 determines 512 the destination channel (or telephone identifier) and transmits a call setup packet to the destination CSU 130. The destination CSU 130 receives the setup packet and determines 514 if the channel or telephone is available. If the channel (or telephone) is not available, the destination CSU 130 transmits a packet to the first server 112 indicating that the channel (or telephone) is busy. If the PBX 128 communicates with the destination CSU 130 digitally, e.g., using a T1 or E1 line then a single connection can be used for many telephones, e.g., up to 24 phones/channel for a T1 link. Therefore, the destination CSU 130 determines 514 if the destination telephone 126 is busy using a conventional detection procedure. An example of a PFSC operating with a digital telephone line is described below with reference to FIG. 8. The call setup/tear-down unit 404 receives the packet and notifies the call management unit 310 that the destination channel (or telephone) is busy. After receiving this notification, the call management unit 310 instructs the channel 1 analog interface 107A to generate and transmit 516 a busy signal to the first telephone 106.



If the channel (or telephone) is available, the destination CSU 130 transmits an acknowledgment packet to the first server 112 indicating that it is available. The call setup/tear-down unit 404 receives the acknowledgment packet and generates and transmits 518 a call request packet to the destination CSU 130. The call request packet includes an indication as to whether 520 a call priority is to be requested. The preferred embodiment uses the resource reservation protocol (RSVP) to reserve bandwidth across the WAN 104. The operation of the RSVP is known to persons skilled in the relevant art. A description of the RSVP is set forth in R. Braden et al, Resource ReSerVation Protocol (RSVP)--Version 1 Functional Specification, Internet Engineering Task Force (IETF), (Mar. 18, 1996), which is incorporated herein in its entirety. The call setup/tear-down unit 404 activates the priority management unit 416 to request a reservation of bandwidth across the WAN 104. The priority management unit 416 identifies the amount of bandwidth to be reserved. The destination CSU 130 receives the call setup packet and reserves the channel for the call. If a call priority is requested, the first server 112 and the destination CSU 130 implement RSVP to determine 522 if the requested bandwidth can be reserved by reservation requests transmitted to the network. A call acceptance packet is then returned to the first server 112 after the bandwidth reservation attempt. If the requested bandwidth cannot be reserved, the call setup/tear-down unit 404 can connect 524 the call anyway 524, albeit with a lower quality, or a busy signal can be generated 530 using the technique described above. In an alternate embodiment, router priority protocols, e.g., weighted fair queuing (WFQ) or traffic prioritization, can be used to assure priority across the WAN 104. If the call parameters, e.g., bandwidth reservation success, jitter buffer size, FEC characteristics are acceptable 528 to the first server 112, and the destination CSU 130, the destination CSU 130 instructs the channel 1 analog interface in its PFSC to ring 532 the destination telephone using the ring voltage power converter 220. The ring voltage power converter 220 is coupled to the power supply of the destination CSU 130 and converts the voltage from, for example, a 5 volt signal, to a ring voltage, e.g., a 160 volt signal, that when transmitted to the second telephone 126 will cause the second telephone 126 to ring. If the call is not acceptable, a busy signal is transmitted to the first telephone 106, as described above.



The procedure for setting up a call for fax or modem transmission is similar to setting up a telephone call, as described above, except that the end-to-end delay of the signal is, typically, not as important as it is for voice communication, and therefore, bandwidth across the WAN 104 does not need to be reserved. However, the present invention can reserve bandwidth for fax or modem communications.



FIGS. 6A and 6B are flow charts illustrating a voice signal transmission procedure according to the preferred embodiment of the present invention. After a connection is setup, aural traffic, e.g., voice, fax, or modem signal, can be transmitted between the first telephone 106 and the second telephone 126. A user transparently generates aural information that is received 602 by the channel 1 analog interface 204A. As described above, the aural information is transparently generated because the user operates the aural signal generating device, e.g., a telephone, a fax machine, or a modem, in the same manner used when communicating via a public telephone system. The transparent generation of voice signals is described above. The user transparently generates fax signals by, for example, placing a sheet of paper in a transmitting fax machine, dialing a code on the transmitting fax machine, e.g., on a keypad on the fax, that identifies a receiving fax machine, and pressing a "send" key. Similarly, data can be transmitted via a modem by identifying a file to be transmitted, inputting a receiving modem identification code, and transmitting the data. As described above, a feature of the present invention is that the technique used to operate the aural signal generating devices does not change. Accordingly, users do not need to be trained how to use these devices, e.g., users do not need to be trained to place a telephone call.



The channel 1 analog interface 204A receives the aural signal and transmits the signal to the codec 206A. The codec 206A converts 604 the analog signal to a PCM signal using a standard technique. The PCM signal is transmitted to the DVM 208A. The call ID unit 308 identifies 606 the type of aural signal that is received and determines if the signal is valid and supported, e.g., if it is voice, fax, or modem data, or if the modem rate is supported. The technique for identifying the type of signal is described in U.S. Pat. No. 5,187,591 entitled SYSTEM FOR TRANSMITTING AND RECEIVING AURAL INFORMATION AND MODULATED DATA, to Guy et al., that is incorporated by reference herein in its entirety.



If the aural signal is identified 608 as a fax signal, the call management unit 310 transmits a signal to the communication management unit 402 requesting that copies of the fax program modules be transmitted 610 to the DVM memory 304 from the voice/fax/modem program unit 414 if not already present in the DVM memory 304. The fax program modules includes a fax unit (not shown) and a framer (not shown). The fax unit performs fax signal modulation 612 and demodulation and the framer creates frames of data. Similarly, if the aural signal is identified 608 as a modem signal, the call management unit 310 transmits a signal to the communication management unit 402 requesting that copies of the modem program modules be transmitted 610 to the DVM memory 304 from the voice/fax/modem program unit 414 if not already present in the DVM memory 304. The modem program modules include a modem unit (not shown) and a framer (not shown). The modem unit performs modulation 612 and demodulation on the received modem signals and the framer creates frames of data from the demodulated signal. If the aural signal is identified 608 as a voice signal, the call management unit 310 transmits a signal to the communication management unit 402 requesting that copies of the voice program modules be transmitted 616 to the DVM memory 304 from the voice/fax/modem program unit 414 if not already present in the DVM memory 304. The voice program modules include a voice unit 312, a framer 318, and a voice enhancement unit 320. In addition, portions of memory are set aside as a data buffer 314 and as a jitter buffer 316. The jitter buffer 316 can be used for voice signals, fax signals, and modem signals, for example.



If the signal is a voice signal, the voice unit 312 compresses 618 the PCM signal from a 64 kbps signal to an 8 kbps signal using a conventional compression algorithm. In the preferred embodiment, the compression algorithm is the ITU G.729 compression algorithm and is described in International Telecommunication Union (ITU) Telecommunications Standardization Sector, Draft Recommendation G.729, Coding of Speech at 8 kbit/s using Conlugate-Structure Algebraic-Code-Excited Linear-Predictive (CS-ACELP) Coding, Ver. 6.1 (Jun. 21, 1995), that is incorporated by reference herein in its entirety. A benefit of the preferred embodiment is that functions that are computationally intensive, e.g., data compression and decompression, are performed by the DSP 302 in the PFSC 208 as opposed to the server's processor 216. Therefore, the computational load on the server's processor 216 is minimal. The server's processor 216 principally performs administrative functions for the PFSC system, e.g., setup, tear-down, priority reservation, and call accounting.



A forward error correction (FEC) function can be enabled automatically, if a predetermined percentage of packets are not being received by the second server 130 in a timely manner, or enabled manually either by the server 112 or remotely, using the SNMP network management unit 418. If enabled 620, the FEC function is performed by the voice enhancement unit 320. Performing FEC enables the destination CSU 130 to recreate packets of data that are lost in transmission or are not received by the second server by a particular time. In the preferred embodiment, the framer 318 generates a frame that includes approximately 20 ms of voice information. After generating the frame, the frame is transmitted to and stored in the server memory module 214. After receiving two frames, the network packetizer 410 creates a packet that includes approximately 40 ms of voice information, e.g., two 20 ms frames. The FEC information is included in the packet.



FIG. 7 is an example of the forward error correction (FEC) process illustrating three voice packets, packet A, packet B, and packet C. Each packet includes a packet header 702, two frames of voice data, F1 and F2, and FEC information 704. In the preferred embodiment, the FEC information 704 includes 622 reduced-quality voice data from the previous packet, e.g., approximately 25-50 percent of the data from the previous packet. For example, for Packet C in FIG. 7, the FEC information is in correction block FEC3 and includes partial information from the data portion of the previously transmitted packet, i.e., Packet B. This partial information is, generally, the frame-to-frame predictive information and pitch value for the first sub-frame of a G.729 implementation. A goal of the present invention is to enable aural information to be transmitted across a LAN 116, a WAN 104, and another LAN 134 transparently as an overlay on the existing IP capabilities of the LANs 116, 134 and WAN 104. This technique is also known as "Voice-over-IP". The quality of present invention is approaches, equals, or exceeds the quality of the public telephone systems. For example, in general, a user can detect a 40 ms gap in a conversation. That is, the loss of a single packet can be detected by the user. However, a 40 ms gap that is reconstructed from a reduced set of parameters of the missing signal is generally not detectable by the user. Accordingly, to increase voice quality, the present invention stores a reduced-quality version consisting of partial voice data from the previous packet as FEC information 704. If packet B is lost, packet B can be recreated by using the FEC information 704C in packet C to produce F1B' and F2B' signals similar to the lost F1B and F2B signals. As stated above, in the preferred embodiment, the frame-to-frame predictive information and pitch parameters of a G.729 implementation provides the partial data for forward error correction. FIG. 7 illustrates one technique for recreating a lost packet, e.g., Packet B. Using the FEC results in a slightly reduced quality signal to replace lost packet B. The loss of quality of the resulting signal is generally not detectable by the user for packet losses up to approximately ten percent. It will be apparent to persons skilled in the relevant art that other implementations of correction information can be used.



In heavy traffic conditions, the WAN 104 may be unable to provide the requested bandwidth. In this situation, for example, the present invention can, optionally, dynamically adjust the rate of data transmission with only a minor decrease in the voice quality. If enabled 624 the voice enhancement unit 320 reduces 626 the bit rate from approximately 8 kbps to approximately 6.4 kbps by eliminating twenty percent of voice data for each frame. For example, if each 20 ms frame includes 10 bytes of data, the last 2 bytes of data, or two non-consecutive bytes of data, are not included in the frame. The resulting frame has a size of 8 bytes and, accordingly, the bit rate is reduced 20 percent since only each frame is 20 percent smaller. Similarly, the voice enhancement unit 320 can reduce the bit rate by forty percent, to 4.8 kbps by not including forty percent of the voice data for each frame.



For every second frame, the call management unit 310 generates 628 a time stamp representing time as a counter which represents the number of voice samples processed. The time stamp is used to determine when a the subsequently transmitted packet is late, as described below. In an alternate embodiment, the time stamp can be provided by the server 112 as it forms the frames into packets.



The framer 318 creates 630 a frame that includes approximately 20 ms of voice data. In addition, every second frame of voice data is associated with time stamp information and, if enabled, the framer generates a FEC frame that includes a reduced quality representation of data from frames transmitted in the previous packet.



The frames are received by the network packetizer 410 that compiles two frames, the time stamp information, and, if enabled, FEC information. The network packetizer then adds a packet header 702 that includes the network address of the second telephone 126. For example, the network address of the second telephone 126 can include the network address of the destination CSU and information identifying the PFSC 202 channel or PBX 128 channel of the second telephone 126. The communication management unit 402 then transmits 632 the packet through the NIC 218 to the router 114 (or switch) of the first LAN 116. The router 114 transmits the packet through the WAN 104 and the packet is received by the router 132 (or switch) of the second LAN 134. The router 132 transmits the packet to the destination CSU 130. The destination CSU 130 can include many PFSCs 202. The operation of the destination CSU 130 will be described with reference to the PFSC 202 and the server memory module 214 of FIG. 2.



After receiving a packet, the network packetizer 410 removes the packet header and transmits the packet to the DVM 208. If the packet contains 636 fax data, the call management unit 310 instructs the communication management unit 402 to load 636 the fax program modules into the DVM memory 304, if the modules are not already present, using the technique described above. The fax unit then processes 638 the signal. If the packet contains 636 modem data, the call management unit 310 instructs the communication management unit 402 to load 636 the modem program modules into the DVM memory 304, if the modules are not already present, using the technique described above. The modem unit then processes the signal. Similarly, if the packet contains 636 voice data, the call management unit 310 instructs the communication management unit 402 to load 640 the voice program modules into the DVM memory 304, if the modules are not already present, using the technique described above. In an alternate embodiment the DVM memory 304 is large enough to store all of the voice, fax, and modem program modules and, therefore, these program modules are only transmitted to the DVM memory 304 once.



The voice enhancement unit 320 then dynamically determines 644 the end-to-end network delay. This variation in the delay can be used to modify the size of the jitter buffer 316, and the overflow jitter buffer 424. The size of the jitter buffer 316 and the overflow jitter buffer 424 are directly proportional to the expected variation in the network delay. Specifically, the jitter buffer 316 buffers frames that are received by the DVM 208. In an ideal network the network delay is constant. Therefore, when the DVM 208 receives a voice frame, the DVM 208 can decompress the voice frame and immediately transmit it to the second telephone 126. However, if a packet is delayed, then the resulting transmission of the aural signal to the second telephone 126 is also delayed. Such a delay is undesirable because of the resulting poor aural signal quality. Accordingly, the present invention utilizes a jitter buffer 316 to allow for fluctuations in the receipt of packets. In the preferred embodiment, the jitter buffer 316 is a first-in-first-out buffer that stores voice frames and has a size that is set in response to network end-to-end characteristics, e.g., network delay, that can be determined during the call set-up procedure. In an alternate embodiment, the jitter buffer 316 can also be adjusted dynamically during the call. If the jitter buffer 316 is too small, then a large network delay variation can result in an aural transmission gap at the second telephone 126. However, increasing the jitter buffer 316 also increases the end-to-end network delay since the jitter buffer 316 stores the voice frames for a time duration that is proportional to the size of the jitter buffer 316. The present invention adjusts the jitter buffer 316 by measuring 644 the network delay for each call and modifying the size of the jitter buffer 316 to reflect the network characteristics for that call.



If a packet is late 646, e.g., if the jitter buffer contents up to the packet have been used, then the voice enhancement unit 320 recreates 648 the late packet using the FEC information in the next packet. If the packet then arrives late, it is discarded, or if not all two frames of the packet have been recreated and transmitted to the second telephone 126, the actual data can be substituted for the reduced quality FEC data for the remaining frames in the packet. The technique for recreating the packet is described above.



The voice unit 312 then decompresses 650 the voice frame using the G7.29 decompression algorithm. The decompressed signal is transmitted to the codec 206 which converts 652 the decompressed signal to an analog signal. The codec 206 transmits the signal to the channel 1 analog interface 204 that transmits the signal to the PBX 128. The PBX 128 then transmits 654 the aural signal to the second telephone 126. The user of the second telephone transparently receives the aural signals, e.g., the second user hears the aural signals through a speaker in a telephone handset.



In the present invention, a call is terminated transparently. That is, a user terminates a telephone call by hanging up a telephone. The call management unit 310 detects this condition, performs a conventional tear-down procedure, and notifies the call management unit 402 which instructs the priority management unit 416 to release the reserved bandwidth.



The present invention typically provides an end-to-end network delay, with the FEC procedure enabled, of less than 200 ms. The present invention also has the ability to dynamically adjust the jitter buffer size and to recreate delayed or lost voice frames. The result is a system and method that provides an aural signal transmission quality that is close to or exceeds the transmission quality of conventional public switched networks.



In addition, the present invention has the ability to use an overflow jitter buffer to operate over networks, e.g., the Internet, having end-to-end delay up to several seconds when not utilizing a transmission priority technique , e.g., RSVP, and provides a recognizable voice signal that is generally of a lower quality.



FIG. 8 is a more detailed illustration of a file server 112 and a phone/fax server card 801 having a digital telephony interface according to the preferred embodiment of the present invention. The server includes a NIC 218, a processor 216, and a server memory module 214, that are described in detail above. The digital PFSC 801 includes two DVMs 208, a PC/interface module 210 and a PFSC memory module 212, that are described above. The digital PFSC 801 includes a T1/E1 interface module that receives digitized aural signals on a T1/E1 signal line. The T1/E1 interface module 802 multiplexes the signal from up to twenty-four DVMs 208 on a single T1 line or up to thirty DVMs 208 on a single E1 line. One embodiment of the present invention includes four DVMs on the T1/E1 interface card 801 and connects through expansion interface module 804 to T1/E1 channel expansion cards, each having an additional four DVMs. The T1/E1 interface module 802 provide higher density connection capabilities for the phone/fax server implementation.



While the present invention has been particularly shown and described with reference to a preferred embodiment, and several alternate embodiments, it will be understood by persons skilled in the relevant art that various changes in form and details can be made therein without departing from the spirit and scope of the invention.

PatentNumber=6310610,RELATED APPLICATIONS



This application is related to U.S. patent application Ser. No. 08/985,265, entitled NAVIGATIONAL TOOL FOR GRAPHICAL USER INTERFACE; and U.S. patent application Ser. No. 08/985,261, entitled CONTEXTUAL GESTURE INTERFACE, both of which are filed concurrently herewith, and both of which are hereby incorporated by reference.



BACKGROUND OF THE INVENTION



The present invention relates generally to graphical user interfaces (GUI), and more particularly to a touch-responsive user interface for graphical user interfaces.



Until relatively recently, software-based documents have been primarily viewed and manipulated on desktop or laptop computers with relatively large displays, typically 640.times.480 pixels or larger. These displays are often large enough to display a full page of standard size page or at least a significant portion of the page. Hence, on-screen graphical menus and controls displayed in window of an application did not greatly reduce the display area for the underlying document. Computers also have peripheral devices such as a keyboard or a mouse to control the display of content information. Thus, viewing and navigating around a single-page or multi-page document have not posed much difficulty.



Due to increasing focus on compactness of electronic devices, however, the displays especially in portable electronic devices are becoming smaller and smaller. Popular electronic devices with a smaller display area include electronic organizers, PDA's (personal digital assistants), and graphical display-based telephones. Also available today are communicators that facilitate various types of communication such as voice, faxes, SMS (Short Messaging Services) messages, e-mail, and Internet-related applications. These products can likewise only contain a small display area.



To enable users to navigate around a full page of content information, these devices typically provide hard-keys for arrows as shown in FIG. 1. The hard-keys, however, not only increase the size but also add to the cost of the devices. Also, hard-keys generally provide limited options for direction of movement, e.g., vertical or horizontal. They generally do not provide the freedom to move in any direction.



Some displays of these devices also require a separate stylus having peripheral technology that requires transmission of electromagnetic pulses or light to the display. These devices often require additional controllers such as buttons on the body or the tip of the stylus for activation. Furthermore, these styli require a power source, either through wire or battery, and their compatibility is generally limited to a specific device.



As shown in FIG. 2, other devices substitute hard-keys with graphical onscreen arrows or scroll bars that are typically used in full-size computer displays. The on-screen scroll bars, however, occupy valuable screen real estate and compound the limitations of small displays. Similar to the hard-keys, the onscreen arrows also generally restrict the navigational movement to horizontal or vertical direction.



In other forms of on-screen GUIs, e.g., pop-up menus, also take up valuable screen space, further reducing the available display area for content information. Additionally, on-screen pop-up menus typically provide available functions in multiple layers, thus requiring a user to move deeply into the hierarchy before reaching the desired function. This is time consuming and renders the GUI cumbersome and ineffective.



Therefore, it is desirable to provide navigation tools that allow small-size devices while maximizing the use of available screen real estate.



It is also desirable to provide tools to navigate within a document at any direction at varying speeds.



It is further desirable to provide navigation tools that can be activated without requiring specific electronic devices.



In addition, it is further desirable to provide an improved GUI that simplifies GUI by recognizing various characteristics of the touch input.



SUMMARY OF THE INVENTION



Systems and methods consistent with the present invention provide a graphical touch-responsive user interface for display devices.



Specifically, a method consistent with this invention of providing a touch-responsive user interface comprises several steps. Initially, the apparatus detects an object making contact with a physical viewing area, and determines a pointer size of the object. Thereafter, the system activates a function corresponding to the pointer size.



A system consistent for this invention for providing a touch-responsive user interface comprises detecting means, determining means, and activating means. The detecting means detects an object making contact with a physical viewing area. The determining means determines a pointer size of the object, and the activating means activates a function corresponding to the pointer size.



BRIEF DESCRIPTION OF THE DRAWINGS



The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate the invention and together with the description, serve to explain the principles of the invention.



In the drawings,



FIG. 1 shows conventional hard-key arrows for navigation control;



FIG. 2 shows conventional on-screen graphical navigation tool;



FIGS. 3A-3B are diagrams of an exemplary mobile telephone consistent with the principles of the present invention;



FIG. 4 is a block diagram showing the elements of the mobile telephone of FIG. 3A;



FIG. 5 is a block diagram showing the components of the memory of FIG. 4;



FIG. 6 is a block diagram of touch screen functionalities;



FIGS. 7A-7B show an exemplary inactive and active graphical navigation tool, respectively;



FIG. 8 is a sample screen showing an active navigation tool;



FIGS. 9A-9C show exemplary features of the navigation tool;



FIGS. 10A-10C are sample screens showing the navigation tool performing various navigation functions;



FIGS. 11A-11B show exemplary features of the navigation tool relating to speed of navigation;



FIG. 12 is a diagram illustrating a touch point distribution; and



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area.



FIG. 13A is a flowchart illustrating an alternate process of determining the size of the object making contact with the viewing area;



FIGS. 14A and 14B are graphs showing the touch characteristic of a pen and a finger, respectively.



DESCRIPTION OF THE PREFERRED EMBODIMENT



Reference will now be made in detail to the present preferred embodiment of the invention, an example of which is illustrated in the accompanying drawings. Where appropriate, the same reference numerals refer to the same or similar elements. The appended claims define the scope of the invention; the following description does not limit that scope.



The graphical navigation tool of the present invention may be implemented in a wide range of electronic devices mentioned above such as electronic organizers, PDA's, and graphical display-based telephones. Although the need to maximize the use of screen real estate is most critical in portable electronic devices with small displays, the present invention can also be implemented in full-size computers or electronic devices. For purposes of illustration, however, the present invention will be explained in detail in a mobile telephone environment.



Specifically, FIG. 3A shows a mobile telephone 310 and FIG. 3B shows an exemplary wireline telephone preferably having the graphical navigation tool consistent with the present invention. Mobile telephone 310 includes main housing 210, antenna 320, keypad 330, and display 340. FIG. 4 shows the hardware elements in mobile telephone 310 including antenna 410, communications module 420, feature processor 430, memory 440, sliding keypad 450, analog controller 460, display module 470, battery pack 480, and switching power supply 490.



Antenna 410 transmits and receives radio frequency information for mobile telephone 310. Antenna 410 preferably comprises a planar inverted F antenna (PIFA)-type or a short stub (2 to 4 cm) custom helix antenna. Antenna 410 communicates over a GSM (Global System for Mobile Communications) switching fabric using a conventional voice B-channel, data B-channel, or GSM signaling channel connection.



Communications module 420 connects to antenna 410 and provides the GSM radio, baseband, and audio functionality for mobile telephone 310. Communications module 420 includes GSM radio 421, VEGA 423, BOCK 425, and audio transducers 427.



GSM radio 421 converts the radio frequency information to/from the antenna into analog baseband information for presentation to VEGA 423. VEGA 423 is preferably a Texas Instruments VEGA device, containing analog-to-digital (A/D)/digital-to-analog (D/A) conversion units 424. VEGA 423 converts the analog baseband information from GSM radio 421 to digital information for presentation to BOCK 425.



BOCK 425 is preferably a Texas Instruments BOCK device containing a conventional ARM microprocessor and a conventional LEAD DSP device. BOCK 425 performs GSM baseband processing for generating digital audio signals and supporting GSM protocols. BOCK 425 supplies the digital audio signals to VEGA 423 for digital-to-analog conversion. VEGA 423 applies the analog audio signals to audio transducers 427. Audio transducers 427 include speaker 428 and microphone 429 to facilitate audio communication by the user.



Feature processor 430 provides GUI features and a Java Virtual Machine (JVM). Feature processor 430 communicates with BOCK 425 using high level messaging over an asynchronous (UART) data link. Feature processor 430 contains additional system circuitry, such as a liquid crystal display (LCD) controller, timers, UART and bus interfaces, and real time clock and system clock generators (not shown).



Memory 440 stores data and program code used by feature processor 430. Memory 440 includes static RAM 442 and flash ROM 444. Static RAM 442 is a volatile memory that stores data and other information used by feature processor 430. Flash ROM 444, on the other hand, is a non-volatile memory that stores the program code executed by feature processor 430.



Sliding keypad 450 enables the user to dial a telephone number, access remote databases, and manipulate the GUI features. Sliding keypad 450 preferably includes a mylar resistive key matrix that generates analog resistive voltage in response to actions by the user. Sliding keypad 450 preferably connects to main housing 210 (FIG. 3A) of mobile telephone 310 through two mechanical "push pin"-type contacts (FIG. 4).



Analog controller 460 is preferably a Phillips UCBL 100 device that acts as an interface between feature processor 430 and sliding keypad 450. Analog controller 460 converts the analog resistive voltage from sliding keypad 450 to digital signals for presentation to feature processor 430.



Display module 470 preferably includes a 160.times.320 pixel LCD 472 with an analog touch screen panel 474 and an electroluminescent backlight. LCD 472 operates in conjunction with feature processor 430 to display the GUI features. Analog controller 460 scans touch screen overlay 474 while feature processor 430 refreshes LCD 472.



Battery pack 480 is preferably a single lithium-ion battery with active protection circuitry. Switching power supply 490 ensures highly efficient use of the lithium-ion battery power by converting the voltage of the lithium-ion battery into stable voltages used by the other hardware elements of mobile telephone 310.



FIG. 5 is a block diagram illustrating the components of memory 440. Static RAM 442 stores data and other information used by feature processor 430. Flash ROM 444 contains various programs including a program 510, a touch screen program 520, a navigation program 530, and a drawing program 540. Program 520, preferably written in languages such as Java, C, or C++ for Macintosh, is a main program overseeing the operation of mobile telephone 310.



Touch screen program 520 facilitates processing of touch input on touch screen panel 474 using a typical touch input algorithm. Navigation program 530 handles navigation of the content information display. Drawing program 540 is a graphical drawing package. Programs 520, 530, and 540 may be one of any commercially available packages or a user-defined feature program or macro.



The present invention provides various features through tactile GUI. Initially, LCD 472 displays various GUI features. Referring to FIG. 6, a user touches touch screen panel 474 to provide user input, for example, to navigate around a document or invoke a desired function. Analog controller 460 scans touch screen panel 474 and reads the corresponding analog voltage of touch screen panel 474. Analog controller 460 then converts the analog values into corresponding digital values representing the Cartesian coordinates, which are transmitted to feature processor 430 for processing. The resolution of the touch input depends on the ability of analog controller 460 to discern among multiple levels of analog values, generally defined in bits.



FIGS. 7A-7B show an exemplary graphical navigation tool preferably used to navigate around documents that are too large to view within a single screen of a physical display (hereinafter referred as "viewing area"). The navigation tool may be used to view any kind of document including faxes, Web pages, or e-mail. In one embodiment consistent with the present invention, an inactive navigation tool is displayed and accessible to the user at all times (FIG. 7A). The user may activate the navigation tool by touching and holding the center of the navigation tool for a predetermined time period, for example, one to two seconds (FIG. 7B). An activated navigation tool is preferably transparent to avoid hindering the display of content information in the viewing area as shown in FIG. 8. Alternatively, the navigation star may change colors or other features of its appearance to indicate its active status. A solid line image, for example, may be used in greyscale displays that do not support transparency. The present invention may be designed such that feature processor 430 ignores any touch input on the navigation tool unless the navigation tool has been activated. Instead, the touch input may be interpreted as input to access control buttons in the underlying document, write on the underlying document, or invoke other functions related to the underlying document. This will prevent against unintentional navigation in the viewing window in case the user inadvertently touches touch screen panel 474. In an alternative embodiment, the present invention may accept stylus input to access the underlying document while a finger or non-electromagnetic touch on any part of the navigation tool invokes the navigation function.



Referring to FIGS. 9A-9C, once the navigation tool is activated, the user may navigate through the document by selecting the graphical arrows, e.g., up, right, left, and down arrows (FIG. 9A), or graphical page icons, e.g., previous or next page (FIG. 9B). One skilled in the art may vary the type and number of graphical tools significantly. For example, the navigation tool may provide graphical representations for forward, next document, back, or home functions (FIG. 9C).



FIGS. 10A-10C show exemplary screen displays while the user is touching the navigation tool. Upon touching the right arrow of the navigation tool, for example, the right arrow is highlighted and navigation program 530 moves the display to the right (FIG. 10A). Similarly, touching the down arrow moves the display down (FIG. 10B). Although the four arrows are presented to guide the users, navigation program 530 supports navigational movement at any direction.



If the user touches an area of the navigation tool equidistant between the up and right arrows, for example, navigation program 530 will move the display towards the upper-right portion of the underlying document at a 45-degree angle. Touching the arrows or any area in between, moves the display in the selected direction until navigation program 530 reaches the edge of the page.



Touching the next page icon moves the viewing window to the next page of the underlying document (FIG. 10C). If a particular document does not have a page corresponding to a previous or next page icon, navigation program 530 will not display the respective previous or next page icons. This would apply to one-page documents, or when the user is at the beginning or end of a multi-page document. In one embodiment consistent with the present invention, a momentary touch of the next page icon causes navigation program 530 to jump to the next page while a continuous touch on the next page icon causes navigation program 530 to continue scrolling through succeeding pages of the underlying document. The previous page icon may embody similar characteristics.



The user may also control the speed of the navigation. As shown in FIG. 11A, the speed of the navigation accelerates as the user touch moves from the center of the circle toward the circumference of the circle, i.e., tip of the arrow. Hence, the viewing window moves slowly when the user touches the blunt end of the arrow located at the center of the circle while the speed accelerates as the user moves the finger towards the tip of the arrow. The speed of navigation, therefore, is determined by the distance of the touch relative to the center of the circle. Likewise, similar principles apply to previous or next page/document icons where a touch closer to the outer edge of the previous or next page/document icons accelerates navigation through the document as shown in FIG. 11B.



Although the exemplary transparent tool discussed above is for navigation, transparent control tools may be implemented for a variety of functions. A transparent tool may, for example, be used for a Web browser application where the controls may be used for appropriate functions such as moving forwards or backwards through different Web pages or returning to home page. One skilled in the art may easily vary the design or the functionality of the graphical navigation tools described above without departing from the scope of the present invention.



In an exemplary embodiment of a navigation tool described above, a finger touch invokes navigational functions based on the feature selected and the location of the user touch. Alternatively, other objects making contact with touch screen panel 474 may invoke other tools or functions. A pointy stylus touch, for example, may invoke a menu with cardinal points representing multiple line widths, colors, or patterns.



In another embodiment consistent with the present invention, tools or application programs may be stored in flash ROM 444 to provide related interfaces to the user. The use of a finger may, for example, invoke tools or dialogues that are finger-touchable and large whereas the use of a sharp stylus may invoke a modified GUI with smaller touch targets. In a yet another embodiment, in a document viewing application normally navigable by a finger touch, use of a sharp stylus may automatically invoke a document annotation application for marking up the underlying document.



As described above, the touch-responsive GUI of the present invention are facilitated though various components including touch screen panel 474, analog controller 460, and feature processor 430. Specifically, analog controller 460 scans touch screen panel 474 to read the corresponding analog voltage of touch screen panel 474 activated by a user touch. Analog controller 460 then converts the analog values into a digital value representing the Cartesian coordinates, which is transmitted to feature processor 430 for processing according to the functionalities of the present invention.



When a user touches touch screen panel 474, program 510 initiates touch screen program 520 to determine the pointer size of the object making contact with touch screen panel 474 based on a touch point distribution or pointer size of the touch input. As shown in FIG. 12, touch screen program 520 can, for example, determine whether the pointer size of the object is a finger or a sharp object.



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area. Touch point program 520 first determines the individual points of contact made by the object (step 1310). It computes a centroid, or other average point, of the determined points of contact (step 1320). Touch program 520 then computes a standard deviation of the centroid as well as the variance (step 1330), and determines the pointer size based on the centroid and the standard deviation (step 1340). These computations are preferably performed on a real-time basis to provide immediate system response to the touch input. In order to achieve optimum results and accuracy, analog touch controller 460 preferably generates 150 points per second or more. Touch program 520 may also use the amount of pressure imposed on touch screen panel 474 as a function of time to determine the size of object. As shown in FIG. 14A, for example, if the amount of pressure increases or decreases sharply at a particular instant in time, touch point program 520 may determine that the touch corresponds to a pen. A finger touch, on the other hand, results in a gradual increase and decrease in pressure as illustrated by a smoother curve in FIG. 14B



FIG. 13A is a flowchart illustrating the process of determining the size of the object making contact with the viewing area, and implementing selected functions based on the determined size, in accordance with the embodiment described with reference to FIGS. 14A and 14B. Touch point program 520 first detects and determines the individual points of contact made by the object (step 1310A). As described above, touch controller 460 generates at least 150 points per second in order to more accurately detect contact points on the viewable area. Touch program 520 then determines the amount of pressure imposed on the viewable area by the object (step 1320A), and the amount of time the object makes contact with the viewable area (step 1330A). The pressure and time data is utilized by program 520 to compute the pointer size of the object, similar to the exemplary process described in FIGS. 14A and 14B, above (step 1340A).



Program 510 can also be programmed to correlate certain pointer size to certain objects and invoke corresponding functions or tools (step 1350). Such GUI provides a richer, yet simplified interaction between the user and mobile telephone 310. If program 510 determines that the pointer size of the object corresponds to the size of a finger (step 1350A), program 510 may initiate a navigation tool (Step 1360A). If the pointer size corresponds to the size of several fingers, program 510 may invoke a drag function of the navigation tool. On the other hand, if program 510 determines that the pointer size of the object corresponds to size of a sharp point or pen (Step 1350A), program 510 may initiate a drawing tool supported by drawing program 540 (step 1370A). Similarly, if program 510 determines that the pointer size of the object corresponds to size of a pencil eraser (step 1350A), program 510 may initiate an erase function of the drawing tool (step 1380A). One skilled in the art may easily vary the functions or tools initiated by program 510. Additionally, the functions or tools may be commercial software packages, predetermined functions, or user-defined macros.



In addition to using the pointer size to determine the desired GUI, program 510 can also incorporate other characteristics of the user touch, e.g., gestures or movements, to simplify GUI and maximize screen real estate. A gesture recognizing interface extends the ability of the present invention to distinguish between different sized pointers to track gestures and movement of user input based on vector direction and magnitude, all in the context of active user application. This type of contextual gesture interface can infer by context, the implement, and the gesture chosen by the user what functions the user wishes to invoke. Accordingly, all these functions are available without menus or scroll bars and do not require additional screen areas to display the functions.



Program 510 recognizes other characteristics of the touch input including the context of the input, namely the task or sub-task applications running when the GUI is invoked. If a user is in a document navigation application, for example, program 510 interprets a quick drag to the right as a next page function. If the underlying task is an editing application, program 510 may interpret the same gesture as a highlight function and highlight a portion of the document touched by the user. Similarly, in graphics application, a quick drag to the right may invoke a drawing tool to draw from the starting point to the ending point of the touch points. In a document viewing application, the same touch may invoke a navigation tool to move the view of the document in the direction of the finger drag.



All of the above functions and features described above focuses on providing intuitive GUIs and minimize the need for users to memorize complicated, hierarchical menus or procedures. Additionally, the present invention maximize available screen real estate while providing a wide array of GUI and tools.



It will be apparent to those skilled in the art that various modifications and variations can be made in the system of the present invention and in construction of this system without departing from the scope or spirit of the invention. Other embodiments of the invention will be apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. The specification and examples should be considered as exemplary only, with the true scope and spirit of the invention indicated by the following claims.

PatentNumber=6340979,RELATED APPLICATIONS



This application is related to U.S. patent application Ser. No. 08/985,265 entitled NAVIGATIONAL TOOL FOR GRAPHICAL USER INTERFACE; and U.S. patent application Ser. No. 08/985,264 entitled INTELLIGENT TOUCH DISPLAY, both of which were filed on Dec. 4, 1997, and both of which are hereby incorporated by reference.



BACKGROUND OF THE INVENTION



The present invention relates generally to graphical user interfaces (GUI), and more particularly to contextual gesture interface for graphical user interfaces.



Until relatively recently, software-based documents have been primarily viewed and manipulated on desktop or laptop computers with relatively large displays, typically 610.times.480 pixels or larger. These displays are often large enough to display a full page of standard size page or at least a significant portion of the page. Hence, on-screen graphical menus and controls displayed in window of an application did not greatly reduce the display area for the underlying document. Computers also have peripheral devices such as a keyboard or a mouse to control the display of content information. Thus, viewing and navigating around a single-page or multi-page document have not posed much difficulty.



Due to increasing focus on compactness of electronic devices, however, the displays especially in portable electronic devices are becoming smaller and smaller. Popular electronic devices with a smaller display area include electronic organizers, PDA's (personal digital assistants), and graphical display-based telephones. Also available today are communicators that facilitate various types of communication such as voice, faxes, SMS (Short messaging Services) messages, e-mail, and Internet-related applications. These products can likewise only contain a small display area.



To enable users to navigate around a full page of content information, these devices typically provide hard-keys for arrows as shown in FIG. 1. The hard-keys, however, not only increase the size but also add to the cost of the devices. Also, hard-keys generally provide limited options for direction of movement, e.g., vertical or horizontal. They generally do not provide the freedom to move in any direction.



Some displays of these devices also require a separate stylus having peripheral technology that requires transmission of electromagnetic pulses or light to the display. These devices often require additional controllers such as buttons on the body or the tip of the stylus for activation. Furthermore, these styli require a power source, either through wire or battery, and their compatibility is generally limited to a specific device.



As shown in FIG. 2, other devices substitute hard-keys with graphical on-screen arrows or scroll bars that are typically used in full-size computer displays. The on-screen scroll bars, however, occupy valuable screen real estate and compound the limitations of small displays. Similar to the hard-keys, the on-screen arrows also generally restrict the navigational movement to horizontal or vertical direction.



In other forms of on-screen GUIs, e.g., pop-up menus, also take up valuable screen space, further reducing the available display area for content information. Additionally, on-screen pop-up menus typically provide available functions in multiple layers, thus requiring a user to move deeply into the hierarchy before reaching the desired function. This is time consuming and renders the GUI cumbersome and ineffective.



Therefore, it is desirable to provide navigation tools that allow small-size devices while maximizing the use of available screen real estate.



It is also desirable to provide tools to navigate within a document at any direction at varying speeds.



It is further desirable to provide navigation tools that can be activated without requiring specific electronic devices.



In addition, it is further desirable to provide an improved GUI that simplifies GUI by recognizing various characteristics of the touch input.



SUMMARY OF THE INVENTION



Systems and methods consistent with the present invention provide a contextual user interface for display devices.



Specifically, a method consistent with this invention of providing a contextual user interface comprises several steps. Initially, a system detects an object making contact with a physical viewing area, and determines characteristics of the contact. Thereafter, the system activates a function corresponding to the contact characteristics and current user task.



A system consistent for this invention for providing a contextual user interface comprises detecting means, determining means, and activating means. The detecting means detects an object making contact with a physical viewing area, and determining means determines characteristics of the contact. Finally, activating means activates a function corresponding to the contact characteristics and current user task.



BRIEF DESCRIPTION OF THE DRAWINGS



The accompanying drawings, which are incorporated in and constitute a part of this specification, illustrate the invention and together with the description, serve to explain the principles of the invention.



In the drawings,



FIG. 1 shows conventional hard-key arrows for navigation control;



FIG. 2 shows conventional on-screen graphical navigation tool;



FIGS. 3A-3B are diagrams of an exemplary mobile telephone consistent with the principles of the present invention;



FIG. 4 is a block diagram showing the elements of the mobile telephone of FIG. 3A;



FIG. 5 is a block diagram showing the components of the memory of FIG. 4;



FIG. 6 is a block diagram of touch screen functionalities;



FIGS. 7A-7B show an exemplary inactive and active graphical navigation tool, respectively;



FIG. 8 is a sample screen showing an active navigation tool;



FIGS. 9A-9C show exemplary features of the navigation tool;



FIGS. 10A-10C are sample screens showing the navigation tool performing various navigation functions;



FIG. 11A-11B show exemplary features of the navigation tool relating to speed of navigation;



FIG. 12 is a diagram illustrating a touch point distribution; and



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area.



FIGS. 14A and 14B are graphs showing the touch characteristics of a pen and a finger, respectively.



DESCRIPTION OF THE PREFERRED EMBODIMENT



Reference will now be made in detail to the present preferred embodiment of the invention, an example of which is illustrated in the accompanying drawings. Where appropriate, the same reference numerals refer to the same or similar elements. The appended claims define the scope of the invention; the following description does not limit that scope.



The graphical navigation tool of the present invention may be implemented in a wide range of electronic devices mentioned above such as electronic organizers, PDA's, and graphical display-based telephones. Although the need to maximize the use of screen real estate is most critical in portable electronic devices with small displays, the present invention can also be implemented in full-size computers or electronic devices. For purposes of illustration, however, the present invention will be explained in detail in a mobile telephone environment.



Specifically, FIG. 3A shows a mobile telephone 310 and FIG. 3B shows an exemplary wireline telephone preferably having the graphical navigation tool consistent with the present invention. Mobile telephone 310 includes main housing 210, antenna 320, keypad 330, and display 340. FIG. 4 shows the hardware elements in mobile telephone 310 including antenna 410, communications module 420, feature processor 430, memory 440, sliding keypad 450, analog controller 460, display module 470, battery pack 480, and switching power supply 490.



Antenna 410 transmits and receives radio frequency information for mobile telephone 310. Antenna 410 preferably comprises a planar inverted F antenna (PIFA)-type or a short stub (2 to 4 cm) custom helix antenna. Antenna 410 communicates over a GSM (Global System for Mobile Communications) switching fabric using a conventional voice B-channel, data B-channel, or GSM signaling channel connection.



Communications module 420 connects to antenna 410 and provides the GSM radio, baseband, and audio functionality for mobile telephone 310. Communications module 420 includes GSM radio 421, VEGA 423, BOCK 425, and audio transducers 427.



GSM radio 421 converts the radio frequency information to/from the antenna into analog baseband information for presentation to VEGA 423. VEGA 423 is preferably a Texas Instruments VEGA device, containing analog-to-digital (A/D)/digital-to-analog (D/A) conversion units 424. VEGA 423 converts the analog baseband information from GSM radio 421 to digital information for presentation to BOCK 425.



BOCK 425 is preferably a Texas Instruments BOCK device containing a conventional ARM microprocessor and a conventional LEAD DSP device. BOCK 425 performs GSM baseband processing for generating digital audio signals and supporting GSM protocols. BOCK 425 supplies the digital audio signals to VEGA 423 for digital-to-analog conversion. VEGA 423 applies the analog audio signals to audio transducers 427. Audio transducers 427 include speaker 428 and microphone 429 to facilitate audio communication by the user.



Feature processor 430 provides GUI features and a Java Virtual Machine (JVM). Feature processor 430 communicates with BOCK 425 using high level messaging over an asynchronous (UART) data link. Feature processor 430 contains additional system circuitry, such as a liquid crystal display (LCD) controller, timers, UART and bus interfaces, and real time clock and system clock generators (not shown).



Memory 440 stores data and program code used by feature processor 430. Memory 440 includes static RAM 442 and flash ROM 444. Static RAM 442 is a volatile memory that stores data and other information used by feature processor 430. Flash ROM 444, on the other hand, is a non-volatile memory that stores the program code executed by feature processor 430.



Sliding keypad 450 enables the user to dial a telephone number, access remote databases, and manipulate the GUI features. Sliding keypad 450 preferably includes a mylar resistive key matrix that generates analog resistive voltage in response to actions by the user. Sliding keypad 450 preferably connects to main housing 210 (FIG. 3A) of mobile telephone 310 through two mechanical "push pin"-type contacts (FIG. 4).



Analog controller 460 is preferably a Phillips UCB 1100 device that acts as an interface between feature processor 430 and sliding keypad 450. Analog controller 460 converts the analog resistive voltage from sliding keypad 450 to digital signals for presentation to feature processor 430.



Display module 470 preferably includes a 160.times.320 pixel LCD 472 with an analog touch screen panel 474 and an electroluminescent backlight. LCD 472 operates in conjunction with feature processor 430 to display the GUI features. Analog controller 460 scans touch screen overlay 474 while feature processor 430 refreshes LCD 472.



Battery pack 480 is preferably a single lithium-ion battery with active protection circuitry. Switching power supply 490 ensures highly efficient use of the lithium-ion battery power by converting the voltage of the lithium-ion battery into stable voltages used by the other hardware elements of mobile telephone 310.



FIG. 5 is a block diagram illustrating the components of memory 440. Static RAM 442 stores data and other information used by feature processor 430. Flash ROM 444 contains various programs including a program 510, a touch screen program 520, a navigation program 530, and a drawing program 540. Program 520, preferably written in languages such as Java, C, or C++ for Macintosh, is a main program overseeing the operation of mobile telephone 310.



Touch screen program 520 facilitates processing of touch input on touch screen panel 474 using a typical touch input algorithm. Navigation program 530 handles navigation of the content information display. Drawing program 540 is a graphical drawing package. Programs 520, 530, and 540 may be one of any commercially available packages or a user-defined feature program or macro.



The present invention provides various features through tactile GUI. Initially, LCD 472 displays various GUI features. Referring to FIG. 6, a user touches touch screen panel 474 to provide user input, for example, to navigate around a document or invoke a desired function. Analog controller 460 scans touch screen panel 474 and reads the corresponding analog voltage of touch screen panel 474. Analog controller 460 then converts the analog values into corresponding digital values representing the Cartesian coordinates, which are transmitted to feature processor 430 for processing. The resolution of the touch input depends on the ability of analog controller 460 to discern among multiple levels of analog values, generally defined in bits.



FIGS. 7A-7B show an exemplary graphical navigation tool preferably used to navigate around documents that are too large to view within a single screen of a physical display (hereinafter referred as "viewing area"). The navigation tool may be used to view any kind of document including faxes, Web pages, or e-mail. In one embodiment consistent with the present invention, an inactive navigation tool is displayed and accessible to the user at all times (FIG. 7A). The user may activate the navigation tool by touching and holding the center of the navigation tool for a predetermined time period, for example, one to two seconds (FIG. 7B). An activated navigation tool is preferably transparent to avoid hindering the display of content information in the viewing area as shown in FIG. 8. Alternatively, the navigation star may change colors or other features of its appearance to indicate its active status. A solid line image, for example, may be used in greyscale displays that do not support transparency.



The present invention may be designed such that feature processor 430 ignores any touch input on the navigation tool unless the navigation tool has been activated. Instead, the touch input may be interpreted as input to access control buttons in the underlying document, write on the underlying document, or invoke other functions related to the underlying document. This will prevent against unintentional navigation in the viewing window in case the user inadvertently touches touch screen panel 474. In an alternative embodiment, the present invention may accept stylus input to access the underlying document while a finger or non-electromagnetic touch on any part of the navigation tool invokes the navigation function.



Referring to FIGS. 9A-9C, once the navigation tool is activated, the user may navigate through the document by selecting the graphical arrows, e.g., up, right, left, and down arrows (FIG. 9A), or graphical page icons, e.g., previous or next page (FIG. 9B). One skilled in the art may vary the type and number of graphical tools significantly. For example, the navigation tool may provide graphical representations for forward, next document, back, or home functions (FIG. 9C).



FIGS. 10A-10C show exemplary screen displays while the user is touching the navigation tool. Upon touching the right arrow of the navigation tool, for example, the right arrow is highlighted and navigation program 530 moves the display to the right (FIG. 10A). Similarly, touching the down arrow moves the display down (FIG. 10B). Although the four arrows are presented to guide the users, navigation program 530 supports navigational movement at any direction. If the user touches an area of the navigation tool equidistant between the up and right arrows, for example, navigation program 530 will move the display towards the upper-right portion of the underlying document at a 45-degree angle. Touching the arrows or any area in between, moves the display in the selected direction until navigation program 530 reaches the edge of the page.



Touching the next page icon moves the viewing window to the next page of the underlying document (FIG. 10C). If a particular document does not have a page corresponding to a previous or next pace icon, navigation program 530 will not display the respective previous or next page icons. This would apply to one-page documents, or when the user is at the beginning or end of a multi-page document. In one embodiment consistent with the present invention, a momentary touch of the next page icon causes navigation program 530 to jump to the next page while a continuous touch on the next page icon causes navigation program 530 to continue scrolling through succeeding paces of the underlying document. The previous page icon may embody similar characteristics.



The user may also control the speed of the navigation. As shown in FIG. 11A, the speed of the navigation accelerates as the user touch moves from the center of the circle toward the circumference of the circle, i.e., tip of the arrow. Hence, the viewing window moves slowly when the user touches the blunt end of the arrow located at the center of the circle while the speed accelerates as the user moves the finger towards the tip of the arrow. The speed of navigation, therefore, is determined by the distance of the touch relative to the center of the circle. Likewise, similar principles apply to previous or next page/document icons where a touch closer to the outer edge of the previous or next page/document icons accelerates navigation through the document as shown in FIG. 11B.



Although the exemplary transparent tool discussed above is for navigation, transparent control tools may be implemented for a variety of functions. A transparent tool may, for example, be used for a Web browser application where the controls may be used for appropriate functions such as moving forwards or backwards through different Web pages or returning to home page. One skilled in the art may easily vary the design or the functionality of the graphical navigation tools described above without departing from the scope of the present invention.



In an exemplary embodiment of a navigation tool described above, a finger touch invokes navigational functions based on the feature selected and the location of the user touch. Alternatively, other objects making contact with touch screen panel 474 may invoke other tools or functions. A pointy stylus touch, for example, may invoke a menu with cardinal points representing multiple line widths, colors, or patterns.



In another embodiment consistent with the present invention, tools or application programs may be stored in flash ROM 444 to provide related interfaces to the user. The use of a finger may, for example, invoke tools or dialogues that are finger-touchable and large whereas the use of a sharp stylus may invoke a modified GUI with smaller touch targets. In a yet another embodiment, in a document viewing application normally navigable by a finger touch, use of a sharp stylus may automatically invoke a document annotation application for marking up the underlying document.



As described above, the touch-responsive GUI of the present invention are facilitated though various components including touch screen panel 474, analog controller 460, and feature processor 430. Specifically, analog controller 460 scans touch screen panel 474 to read the corresponding analog voltage of touch screen panel 474 activated by a user touch. Analog controller 460 then converts the analog values into a digital value representing the Cartesian coordinates, which is transmitted to feature processor 430 for processing according to the functionalities of the present invention.



When a user touches touch screen panel 474, program 510 initiates touch screen program 520 to determine the pointer size of the object making contact with touch screen panel 474 based on a touch point distribution or pointer size of the touch input. As shown in FIG. 12, touch screen program 520 can, for example, determine whether the pointer size of the object is a finger or a sharp object.



FIG. 13 is a flowchart illustrating the process of determining the size of the object making contact with the viewing area. Touch point program 520 first determines the individual points of contact made by the object (step 1310). It computes a centroid, or other average point, of the determined points of contact (step 1320). Touch program 520 then computes a standard deviation of the centroid as well as the variance (step 1330), and determines the pointer size based on the centroid and the standard deviation (step 1340). These computations are preferably performed on a real-time basis to provide immediate system response to the touch input. In order to achieve optimum results and accuracy, analog touch controller 460 preferably generates 150 points per second or more. Touch program 520 may also use the amount of pressure imposed on touch screen panel 474 as a function of time to determine the size of object. As shown in FIG. 14A, for example, if the amount of pressure increases or decreases sharply at a particular instant in time, touch point program 520 may determine that the touch corresponds to a pen. A finger touch, on the other hand, results in a gradual increase and decrease in pressure as illustrated by a smoother curve in FIG. 14B.



Program 510 can also be programmed to correlate certain pointer size to certain objects and invoke corresponding functions or tools. Such GUI provides a richer, yet simplified interaction between the user and mobile telephone 310. If program 510 determines that the pointer size of the object corresponds to the size of a finger, program 510 may initiate a navigation tool. If the pointer size corresponds to the size of several fingers, program 510 may invoke a drag function of the navigation tool. On the other hand, if program 510 determines that the pointer size of the object corresponds to size of a sharp point or pen, program 510 may initiate a drawing tool supported by drawing program 540. Similarly, if program 510 determines that the pointer size of the object corresponds to size of a pencil eraser, program 510 may initiate an erase function of the drawing tool. One skilled in the art may easily vary the functions or tools initiated by program 510. Additionally, the functions or tools may be commercial software packages, predetermined functions, or user-defined macros.



In addition to using the pointer size to determine the desired GUI, program 510 can also incorporate other characteristics of the user touch, e.g., gestures or movements, to simplify GUI and maximize screen real estate. A gesture recognizing interface extends the ability of the present invention to distinguish between different sized pointers to track gestures and movement of user input based on vector direction and magnitude, all in the context of active user application. This type of contextual gesture interface can infer by context, the implement, and the gesture chosen by the user what functions the user wishes to invoke. Accordingly, all these functions are available without menus or scroll bars and do not require additional screen areas to display the functions.



Program 510 recognizes other characteristics of the touch input including the context of the input, namely the task or sub-task applications running when the GUI is invoked. If a user is in a document navigation application, for example, program 510 interprets a quick drag to the right as a next page function. If the underlying task is an editing application, program 510 may interpret the same gesture as a highlight function and highlight a portion of the document touched by the user. Similarly, in graphics application, a quick drag to the right may invoke a drawing tool to draw from the starting point to the ending point of the touch points. In a document viewing application, the same touch may invoke a navigation tool to move the view of the document in the direction of the finger drag.



All of the above functions and features described above focuses on providing intuitive GUIs and minimize the need for users to memorize complicated, hierarchical menus or procedures. Additionally, the present invention maximize available screen real estate while providing a wide array of GUI and tools.



It will be apparent to those skilled in the art that various modifications and variations can be made in the system of the present invention and in construction of this system without departing from the scope or spirit of the invention. Other embodiments of the invention will be apparent to those skilled in the art from consideration of the specification and practice of the invention disclosed herein. The specification and examples should be considered as exemplary only, with the true scope and spirit of the invention indicated by the following claims.

PatentNumber=6594822,BACKGROUND



1. Field of the Invention



This invention relates to a process of patching by comparing object files. In particular, this invention relates to a method and apparatus for creating a software patch using the object files of two software sources to create individual reduced program dependency graphs and comparing these reduced program dependency graphs to determine a minimal set of changes for the patching process.



2. Description of the Problem Solved



"Software patch" is a term which refers to a software file, generally a binary file, that comprises data or instructions to upgrade an old version of a software program to a new version of that same software program. The existing process of producing patches for computer programs such as C/C++ traditionally is very tightly coupled to a particular process and the particular behavior of a specific toolset, i.e., compiler, linker and assembler. There is little cohesiveness amongst toolsets available for development. For example, they may not support the same syntax for C or assembly, may not generate object files in the same format, and may not provide the same functionality. Lack of uniformity of standards causes problems in portability of applications among toolsets. Also, software developers will typically develop software patches specific to code written in C/C++ languages rather than developing the patches to be language independent. While technology exists that is used to create patches for a variety of manufacturers, it is future limited, difficult to maintain and requires parallel strategies and processes to support patching code written in other languages even for the same product or the same logical in-field update.



In general, a patch-writer, the person who develops a patch, typically is creates a patch by comparing the code of an old software program with the code of an updated version of the program and determining the upgraded changes. The resulting software patch, therefore, essentially comprises only the changes contained in the new software program that are not found in the old software program. Typically, a patch-writer will create the software patch at his desktop computer or workstation. The patch is then physically taken to a computer system, installed on a disc or storage medium having the old software program to be upgraded, and is installed or downloaded onto the computer. Alternatively, a patch may be electronically delivered to a computer system through a communications network, e.g., the Internet.



A patch, when applied to a computer system, will change the behavior of the computer system from the old version of the software to the upgraded or new version of the software. A patch can be installed, downloaded or delivered to a computer system and thereby upgrade the software without taking the computer system off-line. Patching, therefore, as defined above, is typically used to upgrade existing software of a computer system in the field, where changes must be made without interrupting the operations of the computer system. For example, a computer at a telephone switch is in constant use, i.e., connecting telephone calls, and therefore, cannot be conveniently pulled off-line to have its software upgraded. Thus, the software patch may be utilized to upgrade the computer software without interrupting its operations.



The benefits, therefore, of patching software versus updating a computer system's software in its entirety are several. First, patching produces a small fix for a small software error and thus is a quick way to deliver and administer "quick fixes," particularly in emergency situations. Patching also provides a way to change the software on-the-fly, so that the entire system need not be taken out-of-service and reloaded. Finally, patching can be implemented to provide a mechanism called "activatable patches". The term, activatable patches, as used herein means patches which may be turned on and off while the program is being utilized as deemed appropriate by a patch-writer. This essentially allows the system to have two possible behaviors for a particular functionality, patches that are either in the on or off state. Computer programs are generally written in high level languages, such as FORTRAN, C/C++, Pascal, and BASIC. A computer programmer writes programs in a high level language to direct the computer to execute certain commands. Commands in a high level language are relatively easy to learn and users can run many programs on many different computers using the same high level language commands. Computers, on the other hand, cannot execute commands from a high level language. Typically, the microprocessor understands and executes commands using only a set of commands unique to the computer. The high level language must be compiled, that is, translated, from the high level language to a machine readable language computers can understand.



Compiling a program written in a high level language to machine executable object code is well known in the art. After the entire program is written in the high level language, the user requests that the program be compiled for execution in machine language. A software program known as a compiler reads the commands and data in the high level language and generates an object file having machine readable code corresponding to the commands of the high level language.



Traditionally telecommunications companies had control over the software that was used on computer systems in the field. Telecommunications companies wrote their own proprietary software tools to control the computer systems and developed their own internal compilers to translate software into machine code which can be understood and acted upon by a computer. Such companies, therefore, had total control over the computer system hardware, the software, and the process of developing and upgrading software, including creating patches.



However, with the evolution of new software languages and the rapidly improving technology of compilers producing faster and smaller code, many companies now do not have the luxury of developing and using their own proprietary languages to control computer systems, but have had to yield to market pressure and use languages, such as C/C++, which are today's mainstream programming languages. This has made the job of controlling a computer system's software and creating patches more difficult. Given that C/C++ is the preferred and commonly used software language and that telecommunications companies generally purchase off the shelf compilers for programs written in C/C++, there is no direct way to develop and create a patch for software programs written in C/C++ languages.



The known method of creating patches for software modules written in C/C++ languages is very difficult to maintain and time consuming. For example, to create a patch for programs written in C/C++ languages, a patch-writer must: 1) compile the software into an intermediate language, the assembly language, and 2) perform an analysis on that language. Under this method, the patch-writer would have to take the entire software package and analyze all of the software programs to determine the changes for the patching process. In addition, to create a patch using the assembly language, the patch writer must compare each textual line in the old software program to each corresponding textual line in the upgraded version of the software program. Because of numerous branching sequences which jump to various places in a program, it is difficult to create a patch by making line-by-line comparisons of programs with branching sequences. For example, the assembly language of an old software program may comprise a first function and a second function in numerical order. Although the assembly language of the new upgraded software program might comprise the same first and second functions, they might be in reverse order. The patch writer, therefore, might not be able to readily determine that the functions in the old assembly language and the new assembly language are the same. As the need for software patches has increased, the sophistication of the development of processes to create patches has not kept pace.



What is needed is an efficient and reliable method and apparatus for creating a patch for software by determining a minimal set of changes known as deltas. Optimally, the process will permit source-language target processor and compiler vendor independence. The method and apparatus is needed to create patches from the assembly language of software by comparing the object files, the actual machine language of the software. The foregoing problems are solved by a method apparatus that function to compile an old version of a software program and an upgraded version into separate object files. The object files then are decomposed into nodes or "cantles", and are used to generate separate reduced program dependency graphs (RPDG) for both software programs. The RPDG include a plurality of nodes that are linked together. The two RPDG's are compared to determine the minimal upgraded changes and create a patch therefrom comprising of the changed or added functions.



It is therefore an object of this invention to provide a method and apparatus that creates a patch using object files of programs written in high level languages such as C/C++ instead of creating a patch from a processor and compiler vendor specific intermediate representation such as assembly.



It is another object of this invention to provide a method and apparatus that creates a patch by decomposing object files into nodes or cantles.



It is another object of this invention to provide a method and apparatus that creates a patch by comparing RPDG's.



It is another object of this invention to provide a method and apparatus that creates a patch by comparing functions of an object file of an old software program component to functions of an object file of a new upgraded software program component.



It is another object of this invention to provide a method and apparatus that is source-code independent and can be applied to code written in C/C++, Pascal or even to specific proprietary languages.



It is another object of this invention to efficiently create a patch to update existing software on a computer system without having to pull the computer off-line.



SUMMARY



The present invention solves the above mentioned problems by providing a method and apparatus for creating software patches for software programs written in C/C++, Pascal or specific proprietary languages so long as they compile to a standard object file format. Functions of a compiled version of an existing software program are compared with an updated version that is compiled in separate object files to discover a minimal set of changes, or "deltas" (for the patching process). Object files themselves typically include a single module for a larger program. Because the software has already been compiled into object files, the invention is source-code independent and can be applied to code written in C/C++, Pascal or even to specific proprietary languages. The process for creating a patch from the object file, includes, first, decomposing each object file into cantles, partitioning relocation information (which we call fix-up information or fix-ups), and associating it with the various cantles. Next, the steps of examining each cantle and adding fix-ups for any references to other cantles, constructing a reduced program dependency graph (RPDG) from the cantles (nodes) and their fix-ups (edges) for each object file, and comparing the two RPDG's to determine the differences between their functions are performed. Finally, a listing of differences between the functions of the two RPDG's is developed and a patch comprised of the listed differences between the functions of the two RPDG's is developed.



With the present invention, the old software and new software are compiled into individual object files as commonly known. The object files of the old software code and new software code contain data, constants, and various artifacts of the source code. The term "cantles" as used in this invention refers to the product produced from "cantlization." Each object file undergoes a process called cantlization. The term "cantlization" generally means the process of structuring of the object files into uniformed cantles (sub-parts) so that individual RPDG's can be constructed for the old and new software codes. The cantles are actual functions from the original source (i.e., the code), variables and constants. Other information in the object files, called fix-ups, sometimes known in the art as relocations, are used to determine the dependencies between the various cantles.



A patch created under this invention is composed of mutually dependent functions. A function is actually a segment code in the object files. Since software patches will typically contain functions, in the preferred embodiment, the invention determines which functions are represented by is which cantles. From the fix-up information present in the object file, the invention can determine the dependencies of each function with respect to all other functions, variables, constants, etc., of the larger, whole program.



Individual reduced program dependency graphs are developed for the old and new object files. Each reduced program dependency graph is comprised of nodes. These nodes represent functions, variables, etc. The interconnections of the nodes are determined from fix-up information from the object file. The RPDG's for the new and old software are compared to determine the differences between functions of the old and new software. As the RPDG's are compared, the nodes are marked to determine which functions have changed in the old software code and/or which functions have been added to the new software code. These changes are captured, controlled, and the patch is automatically produced, generally, in a binary file format comprised of the changed functions only. The resulting patch produced in this manner can be sent to a computer in the field to upgrade the old version of a computer's software.



These and other features, and advantages, will be more clearly understood from the accompanying drawings. However it will be appreciated that there may be many other embodiments of the present invention, which are not specifically illustrated.



BRIEF DESCRIPTION OF THE DRAWINGS



FIG. 1 is a diagram that illustrates object files of an old software code and a new software code that has been individually decomposed into cantles.



FIG. 2 is a diagram that illustrates reduced program dependency graphs (RPDG's) developed from the cantles in FIG. 1.



FIGS. 3A-3C are flow charts which describe the steps of creating a patch in accordance with the present invention.



FIGS. 4A-4D are sub-flow charts illustrating the specific steps of comparing the RPDG's for the old software code and new software code as described in FIG. 3A.



FIG. 5 is a block diagram illustrating the basic components of a computer system that is utilized by the preferred embodiment to create a patch in accordance with the invention.



DETAILED DESCRIPTION



The process to create a patch using this invention is applied to upgrade software on mainstream computers that use, for example, MOTOROLA'S Power PC processors, as well as other manufacturer's processors commonly known in the art, e.g., INTEL, AMD, etc. FIG. 1 is a diagram that illustrates the way object files are decomposed into "cantles". The object file of old software code 120, and the object file of new software code 134, are depicted after each has been decomposed into "cantles". This term "cantles", as used in this invention, refers to the product produced from "cantlization." The old software code 120 includes information which can be divided into related groups of information as follows: code 122, data 124, constant 126, symbol table 128, debug information 130, and fix-up information 132. Similarly, the new software code is also divided into sub-parts: code 136, data 138, constants 140, symbol table 142, debug information 144, and fix-up information 146. The term "cantlization" generally means the process of decomposing the object files into typed cantles so that individual RPDG's can be constructed for the old and new software codes.



FIG. 2 is a diagram that illustrates RPDG's for old software code and new software code that are constructed from cantles. The RPDG for the old software code 150 comprises functions f1 and f2, which are also referred to as nodes. Functions f1 and f2 are linked together, shown by line 152. Function f1 is connected to T.sub.1 via A, which are also referred to as nodes. Function f2 is linked to T.sub.2 and T.sub.3 via B and C, respectively. A, B, C, T.sub.1, T.sub.2 and T.sub.3 are all part of the old software code and generally are variables, constants and the like. The RPDG for the new software code 155 comprises f1' and f2', which are linked together, shown by line 158. Function f1' is linked to T.sub.4 via D and is also linked to T.sub.2 ' and T.sub.3 ' via B' and C', respectively. Functions f1' and f2' in the RPDG for the new software code 155 will be compared to functions f1 and f2 in the RPDG for the old software code 150 to determine the upgraded changes between the old and new software codes. Once the changes between the new software code and old software code are determined, a patch file 160 is created. The patch file is comprised of changed and added functions and their interdependencies. The patch illustrated in FIG. 2 will be comprised of the changes for f1. In the old software code, f1 was linked to A and T.sub.1. In the new software code f1' is linked to D and T.sub.4. The patch, therefore, will contain only the replacement code for f1, which is shown as f1', which includes D and T.sub.4. Function f2 will not be added to the patch since it did not change.



FIGS. 3A-3C are flow charts that illustrate the method of creating a patch in accordance with the present invention. The method may be implemented through programming instructions stored in a processor computer-readable storage medium. A processor computer-readable storage medium containing a set of instructions may be any type of digital storage device such as RAM, ROM, disc, diskette, Magnetic Tape, Flash Memory, or CD-ROM.



Referring now to FIG. 3A, the process of creating a patch begins at step 202 wherein an old software code is compiled into object files. The old software code is compiled into a standard object file format. It is appreciated that this invention will work with any vendor compiler so long as it will compile the old software code into a standard object file format. Examples of standard formats include ELF-Dwarf, IEEE, and COFF. Still referring to FIG. 3A, in step 204, the object file for the old software code is decomposed into constituent cantles as illustrated in FIG. 1. These cantles comprise logical structures from the original source, i.e., the code, variables and constants. Decomposed information of the same type, such as variables, may be grouped into sections. These sections include logical structures for symbol tables, debug, code, ready-only data, read-write data, zero data, data objects, fix-up records, string tables, and possibly other information when it is used to create cantles. For example, the information in a symbol table is used to recover all the logical structures, i.e., cantles, from the object file. The symbol table(s) is parsed and cantles are extracted during patch development. The debug section(s) are also parsed to locate potential cantles and any missing information on the cantles from the symbol table. In the debug section(s), records that reflect information about source files, functions, data-objects and type information may be examined. The invention uses this information to locate functions of static linkage, names of data objects not in the symbol table, and type information about cantles in the object file.



Functions will have an offset, size, and value in the object file. Constants and pre-initialized static variables will have an offset, size, and value. Static variables will have an offset and size value. The invention ignores automatic (stack allocated) data-objects. The offset and size values are used to scan the table of fix-ups and make the proper association between those fix-ups which operate on a particular cantle. All of the fix-ups are maintained in a list associated with a particular cantle. The symbol table provides a mechanism to associate a particular label (symbol) with a particular recovered cantle from the object file. The symbol table, however, is not sufficient to determine all characteristics of a cantle. Information from the fix-ups is utilized to provide "requires-type" information needed to develop the relationship between cantles in the entire program.



Still referring to FIG. 3A, the fix-ups for the cantles are examined in step 206. The fix-ups are part of the object file and contain information of the dependencies of the functions. Essentially, the fix-ups contain information as to how the functions and their requires-type interdependencies in an object file are linked together. Constants need not be symbolic and, therefore, the constant area may have to be "diced" to determine the size of a "new cantle" which resides in the constant section of memory. To dice a memory section, areas that are known to have cantles are marked. The set of all fix-ups to a particular memory section is examined and if they point to a block which is not already marked, a boundary marker is placed at that location. After this operation, the size of a "new cantle" is assumed to be the size of the block between the two boundary markers. For example, if there are two constant tables of ten integers in a constant memory area, there may be a block, which is a total length of twenty integers long. After adding the boundary markers, one at the beginning of the first table and one to the beginning of the second table, then it can be determined that the size of the first table is ten integers.



Once the fix-ups for the cantles are examined, step 208 determines whether each cantle's dependencies have been checked. If each cantle's dependencies have not been checked, or if there are more cantles to be checked, the process returns back to step 206 to examine the fix-ups for the remaining cantles. However, if each cantle's dependencies have been checked and there are no more cantles to be checked, proceeding to step 210, a reduced dependency program graph (RDPG) for the old code is created. Creating a RPDG, in the manner illustrated in FIG. 2, is relatively easy once the cantles are identified and the interdependencies have been extracted. The RPDG created from the old code exits step 210. A RPDG is merely a graphical depiction of cantles (nodes) and their relationship to one another (edges) based on information contained in the object file.



Referring specifically to FIG. 3B, in step 212, the new software code is compiled into object files, wherein at step 214 the object files for the new software code are decomposed into constituent cantles as previously described for the old software code in step 204. The fix-ups for these new software cantles are examined in step 216. Step 218 determines whether each of the cantle's dependencies have been checked. If each cantle's dependencies have not been checked, the process returns back to step 216 to examine the fix-ups for the remaining cantles. Once all the cantle's dependencies have been checked, the process continues to step 220 wherein the RPDG for the new code is created.



Referring specifically now to FIG. 3C, at step 222, the RPDG's for the new code and old code are compared. The RPDG from the old code is routed there from entry point Q. (See FIG. 3A). The RPDG from the new code is routed there from entry point R. (See FIG. 3B). After RPDG's from the old code and the new code have been compared, a list of changes between the old and new software code is stored in X, as shown in step 224. X represents a collection of the changes or deltas noted in the new software code. Once these changes or deltas are collected, a patch file composed of the change functions is generated as shown in step 226.



FIGS. 4A-4D are a sub-flow chart to illustrate a detail of step 222 in FIG. 3C. FIGS. 4A-4D show process steps whereby the RPDG's for the new software code and the old software code are compared to determine the changes between the new and old software codes. Referring specifically to FIG. 4A, the new code RPDG is routed to step 228 via entry point R. Step 228 determines whether each node in the RPDG for new software code is a function. Each node is checked individually in step 228. If the checked node is a function j, it is inserted in J at step 230. J is a list of functions located in the RPDG for the new software code. Regardless of whether the checked node is a function, the invention proceeds to step 232 to determine whether the other nodes in the RPDG have been checked. If all of the nodes in the RPDG have not been checked, the process proceeds to step 234 where the next unchecked node in the RPDG is located, then, returns to step 228 and repeats this sequence until all nodes in the RPDG have been checked. Once all the nodes in the new RPDG have been checked, the process continues at step 244 in FIG. 4C from step 232 to an entry point S.



Referring now to FIG. 4B, step 236 determines whether each node in the old RPDG is a function. The old code RPDG is routed to step 236 via entry point Q. Each node is checked individually in step 236. If the checked node in the old RPDG is a function, then that function, g, is inserted in G in step 238. G is a list of functions found in the RPDG for the old code. If the checked node is not a function, the process proceeds to step 240 to determine whether the remaining nodes in the RPDG for the old software code have been checked. If all the nodes in the RPDG have not been checked, the process proceeds to step 242 wherein the next unchecked node in the RPDG is located and proceeds back to step 236. Similarly as for the new software code, this sequence of steps is repeated until all of the nodes in the RPDG have been checked. Once all the nodes in the RPDG have been checked, the process continues at step 244 in FIG. 4C via entry point S.



Referring now to FIG. 4C, at step 244, for each function, j in J, step 244 determines if there is a nominal matching function, g in G. If there is a nominal matching function, the assignments of n=j and m=g are made, as shown in step 246. If there is no nominal match, then step 248 adds function j to X. In Step 250 the process determines whether there are any more functions to be checked. If there are still functions to be checked the process returns to step 244 via entry point S. If there are no additional functions to be checked, then the process proceeds to step 224, as shown in FIG. 3C. At step 252 the process determines whether n and m have been compared, and if so, the process proceeds to step 250 via entry point T. If m and n have not been compared, then step 254 determines whether n and m are on the working stack, as commonly known in computer science technology. If n and m are on the working stack, the comparison of m and n is skipped in step 256 and returns to step 250 via entry point T. If m and n are not on the working stack, step 258 compares n and m based on types of nodes culminating at point V.



Referring specifically to FIG. 4D, from step 258 of FIG. 4C, n and m are pushed onto the working stack at step 258 via entry point V. Step 262 compares the edges of n and m. In Step 264 the process determines whether the edges of n and m are strong. If the edges of n and m are not strong, the process proceeds to step 250 as shown in FIG. 4C via entry point T. If the edges are strong, the process compares the nodes between the old and new graphs recursively in step 266. The term "weak edge" as used in this invention means any edge linked between two nodes of a function type. All other edges are considered to be strong. Continuing to step 268, the process determines whether the compared nodes are the same. In order to determine whether the compared nodes are the same, this invention checks to see if each node has the same number of edges. If the number of edges are different, the nodes are different.



This invention also determines whether each edge has the same fix-up type, same offset, same to-cantle, same to-offset. If the edge is strong, the nodes are compared recursively. If the nodes are the same, they are checked until all edges are found. If the to-nodes differ, they are marked as being different. If the edge is weak, the to-nodes are tested to determine if they have the same name. If they have different names, they are marked as being different. If the nodes are the same, and the edges are the same, then the nodes are marked as being "the same." If the nodes that are to be compared are functions, they are compared by their lengths, hash values and the content of the functions to determine if they are the same. Symbols are compared by their names. Variables are compared by name, size and, if known, content. Types are compared by size, layout, and by sub-types, if the variable has any. If the nodes are not the same, step 270 adds the node to the list of changes in X. Once again return to step 250 as shown in FIG. 4C via entry point T. If the compared nodes are the same, at step 272, n and m are marked as being the same. Return to step 250 via entry point T. At step 250, if there are no more functions to be checked, proceed to step 224 of FIG. 3C via entry point U. The list of changes in X at step 224 are listed. Step 226 generates a patch file composed of only these changed functions and their interdependencies.



In the preferred embodiment described herein,the computer system that is used to develop a patch in accordance with the invention is a HEWLETT PACKARD workstation, model B-180. The HP B-180 computer system of the preferred embodiment is described with reference to FIG. 5. The HP B-180 generally comprises a bus or other communication means 301 for communicating information and a processor 302 coupled with bus 301 for processing information. The HP B-180 workstation uses a HP/PARisc microprocessor, which is a commonly used HEWLETT PACKARD microprocessor. A random access memory (RAM) or other storage device 304 (commonly referred to as a main memory) is coded with bus 301 for storing information and instructions for processor 302, a read only memory (ROM) 306 coupled with bus 301 for storing information and instructions for processor 302. The HP B-180 also includes a data storage device 308, such as a magnetic disk or hard drive coupled with bus 301 for storing information and instructions. The HP B-180 also includes a disk drive (not shown) for receiving diskettes or CD-ROM's. An alpha numeric input device 310, including alpha numeric and other keys, is coupled with bus 301 for communicating information and command selections to processor 302. A cursor control device 312, such as a mouse, track ball, or cursor control keys, is coupled to bus 301 for communicating information and command selections to processor 302 and for controlling cursor movement and display device 314. Display device 314 is coupled to bus 301 and displays textual and graphical information. Additionally, it is useful if the system includes a hard copy device 316, such as a printer, for providing permanent copies of information. The hard copy device 316 is coupled with the processor 302 through bus 301. The HP B-180 may be connected to a network via an Ethernet connection.



The program of the invention is stored on the hard drive 308 in a file system, as commonly known. The old software program and the upgraded version of that software program are stored on a diskette (not shown). However, those programs could be stored on hard drive 308. The program of the present invention reads in the old and new software codes from the appropriate files of a diskette. These files are transferred via bus 301 to another program stored on data storage device 308, the compiler, for translation into separate object files. This translation reads the source files from the disk, processes them in core memory, and writes the result back to the disk.



The program reads in the object files from disk and cantlizes the information from those files in core memory. These cantles are then used to construct the RPDG in memory. The program compares the two RPDG's and marks the changes made by the patch writer. Using this list of information, knowledge of which functions changed, as well as other packaging information (provided by the patch writer), the patch file is constructed and written to disk. This file can then be downloaded to the target computing device (computer or switch) and used in the field to correct problems, revise or upgrade old software. I have described specific embodiments of my invention which provides a way in which patches can be developed by comparing object files of two software programs. One of ordinary skill in the art will quickly recognize that the invention has other applications in other environments. In fact, many embodiments and implementations are possible. The following claims are in no way intended to limit the scope of the invention to the specific embodiments described.

PatentNumber=6631368,BACKGROUND OF THE INVENTION



The present invention relates to methods and apparatus for operating on messages, and more particularly for operating on non-text messages, such as voice and facsimile messages, including, for example, searching such messages.



Modern communications technology has produced voice mail, faxes, e-mail, video conferencing and many other ways to send messages.



The growth in voice mail systems has been explosive. In 1996, telephone company revenues generated by providing Voice Mail service exceeded one billion dollars. While business users typically buy voice mail systems, residential customers buy this service from telephone companies. The residential market accounts for 82% of telephone company voice mail subscribers and 69% of revenues generated. Thus, voice mail and faxes are fully part of the daily communications fabric.



In the last twenty years the use of facsimile messaging (fax) has also exploded. The cost of fax machines has decreased steadily, and with the advent of computer telephony (CT), faxes can be received and sent via local area networks (LANs) directly to computers on the user's desktop, eliminating the need to even walk down the hall to the fax machine.



Known systems will collect all digital communications, display the time of receipt, the source of the message, and indicate whether it is voice mail, a fax, or e-mail.



With known systems, a user with a telephone system and a computer can quickly become inundated with information. As such, it is important to be able to separate important messages, or messages which contain key information, from routine messages or electronic junk mail. With known systems this is difficult. In addition, finding key elements of messages can be time consuming and difficult, if not impossible. Known systems provide functions for finding, filtering, filing and re-directing textual messages (e.g., e-mail) but do not do so for voice or facsimile messages.



SUMMARY OF THE INVENTION



The present invention solves these problems by providing a way for searching for, or through, non-text messages to find certain information, or to determine if certain information is included therein, and/or for performing other operations thereon. In conjunction with the present invention, a search is undertaken for one or more signal samples having pre-defined characteristics by comparing one or more signal samples of non-text messages with these pre-defined characteristics. For example, the predefined characteristics may comprise one or more templates for voice samples which make up a specific word (e.g., "urgent"). In that case, these voice templates may be compared with signal samples of a voice message in a search for signal samples which match these voice templates. In addition, and in accordance with the present invention, a non-text message having pre-defined characteristics may be operated upon to provide a desired result (e.g., forwarded).



Therefore, in accordance with the present invention, there is provided a method for operating on a non-text message including searching the message for one or more signal samples having pre-defined characteristics by comparing one or more signal samples with the pre-defined characteristics.



In accordance with a further aspect of the invention, there is provided a method for operating on a non-text message, including searching the message for one or more signal samples having pre-defined characteristics and upon finding one or more signal samples having the pre-defined characteristics, operating on the message.



In accordance with another aspect of the invention, there is provided an apparatus for operating on a non-text message, including a non-text search engine for searching the message for one or more signal samples having predefined characteristics by comparing one or more signal samples with the pre-defined characteristics.



In accordance with another aspect of the invention, there is provided apparatus for operating on a non-text message, including: a unit for searching the message for one or more signal samples having pre-defined characteristics; and a unit for, upon finding one or more signal samples having the pre-defined characteristics, operating on the message.



BRIEF DESCRIPTION OF THE DRAWINGS



In the figures, which illustrate example embodiments of the invention,



FIG. 1 is a block diagram of an apparatus in accordance with this invention connected to a network,



FIG. 2 is a block diagram of a processor which is part of the apparatus of FIG. 1,



FIG. 3 is a schematic diagram of a message structure created by the apparatus of FIG. 1, and



FIGS. 4a, 4b, and 4c are flow diagrams of methods in accordance with the invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



FIG. 1 shows an apparatus 10 in accordance with the invention which can search for information in one or more non-text messages and perform other operations thereon. Apparatus 10 is connected via its processor 12 for two-way communication with a digital network 14. Network 14 has non-text based message traffic and may also have text-based message traffic. The network 14 may comprise any communications network, including, for example, an internet, intranet, or telephone network.



The non-text messages may be voice messages, video messages with a voice component, or facsimile messages (which, as will be understood by those skilled in the art, are graphics messages which typically include text in graphical form). As will be appreciated by those skilled in the art, the messages with a voice component comprise quantised analog voice signals. The text-based messages are digital messages according to the text standard of the network, which is typically the ASCII standard such that the text-based messages comprise ASCII characters.



The processor 12 is also connected for two-way communication with a user interface 20 and with a memory 26. Memory 26 may comprise any appropriate kind of volatile and/or non-volatile memory.



As seen in FIG. 2, the processor 12 includes an enveloped message creator 28 which receives inputs from the network and outputs to a non-text search engine 30 and a memory interface 36. The non-text search engine 30 is connected for two-way communication with the memory interface 36. The memory interface interfaces with the memory 26 (FIG. 1) and is also connected for two-way communication with an interpreter 37 and a text-based message operations engine 38. The interpreter 37 interfaces with the user interface. The text-based message operations engine 38 also interfaces with the user interface and is connected for two-way communication with a text-based envelope search engine 40.



The memory 26 (FIG. 1) stores an envelope shell. Briefly referencing FIG. 3, the format of this shell (which will be detailed hereinafter) is illustrated at 52. Memory 26 also stores sets of predefined characteristics. Each set of pre-defined characteristics comprises voice templates or facsimile graphics templates along with an arrangement for the templates. Text-based equivalents are associated with each template (for example, the text-based equivalent associated with a template may be a letter, a collection of letters, a number, or a collection of numbers). Thus, where a set of pre-defined characteristics comprises voice templates, an equivalent text-based letter, collection of letters, words, number, or numbers to which such voice templates map is stored in association therewith. Alternatively, where the set of pre-defined characteristics comprises facsimile graphics templates, equivalent text-based words, numbers, etc. to which the graphics templates map are stored therewith.



FIG. 4a provides a flow chart of a method in accordance with this invention for handling new messages; the operation of this method may be carried out by processor 12 in the system of FIGS. 1 and 2. In conjunction with the invention, multi-media messages may be received by the enveloped message creator 28 of processor 12 (S110) from network 14. Typically, a header for these messages indicates their type--i.e., voice, fax, e-mail. (In this regard, it will be appreciated that a message may be of multiple types with a multipart header to indicate each type.) In other instances, the type may be implicit based on the source (e.g., messages arriving from a fax application will be fax messages). In this regard, a simple look-up table may be employed to associate message sources with default types. The message type determines whether the message is natively text-based or natively non-text based (or partly natively text and partly natively non-text).



If a new message is natively text-based (S ill), the enveloped message creator 28 associates an envelope shell with the message which merely indicates in message type area 60 (FIG. 3) of the shell 52 (FIG. 3) it has a text-based native form (S112). Then, the processor passes the message directly to memory 26 for storage (S114) as well as updating a message log and prompting the user that a new message has arrived (S116) in accordance with a manner known to persons skilled in the art.



If the message is a natively non-text message (or has a non-text component) (S111), the enveloped message creator associates an envelope shell with the message, and indicates in area 60 (FIG. 3) the message contains voice or facsimile graphics. The message creator then passes the enveloped message to non-text search engine 30 (S118). The non-text search engine 30 accesses a set of pre-defined characteristics found in memory 26. If the incoming message is a voice message, the accessed set of pre-defined characteristics comprises voice templates; if the incoming message is a facsimile message, the accessed set of pre-defined characteristics comprises facsimile templates (S120). For example, if the incoming message is a voice message, the set of pre-defined characteristics may comprise voice templates for the digits 0 to 9, arranged so that all digit strings of seven and ten digits in length (i.e., a phone number) match the set. The search engine then searches through the message for one or more (sequential) voice samples matching one of the digit templates. If a match is found, the engine looks to the next sample(s). If the next sample(s) also match a digit template, the search looks to the following samples and so on until either sequential voice samples are found to match seven or ten digit templates or this number of matches is not found, in which case searching continues for the next place in the message to have one or more voice samples matching one of the digit templates. By way of a further example, the incoming message may be a fax message, the set of pre-defined characteristics may comprise facsimile templates aranged to make up the word "urgent" and each facsimile template may comprise one letter. The search engine then searches through the fax message for one or more (sequential) fax samples matching the facsimile template for the letter "u". If this is found, the engine looks to the next one or more samples for a facsimile sample matching the letter "r", and so on. Techniques for speech and facsimile graphics recognition are well known in the art.



If the new message is found to contain one or more signal samples falling within a set of pre-defined characteristics (S122), then the text-based equivalent of the corresponding template(s) is added to slot 62 (FIG. 3) of a field 56 (FIG. 3) in the envelope of the message (S123). In addition, for found signal sample(s), one or more signal sample pointers are stored in a slot 64 (FIG. 3) in the field which points to the location in the non-text message of the found signal samples (S124).



If the new message does not contain one or more signal samples falling within a given set of pre-defined characteristics, then the slots for the text based equivalent 62 and signal sample pointer 64 of the field 56 for the relevant search are set to null. This process is repeated for each of the sets of pre-defined characteristics in memory (S125). Thereafter, the non-text search engine 30 passes the enveloped message to the memory interface 36 for storage in memory 26 (S126) and the message log is updated and the user is prompted (S116).



Sets of pre-determined characteristics may be accessed sequentially from the memory 26. The results of sequential searches following from sequentially accessed sets of pre-defined characteristics may be stored in sequential fields of the envelope so that each field ID 58 is an ordinal representing a search number. Alternatively, each field ID may be populated by the non-text search engine with a description of the search and a pointer to the memory area in which the set of pre-defined characteristics is found.



The sets of pre -defined characteristics are handled as standing search requests which are applied to each new message which is received. When a new set of pre-defined characteristics is added, optionally, a search of all existing messages may be undertaken based on the new set.



A new set of pre-defined characteristics may be specified by a user as follows. Referencing FIG. 4b along with FIGS. 1 and 2, a user may enter information in order to specify a set of characteristics through user interface 20--which may comprise a keyboard, mouse, microphone, or other input device along with a display and a speaker (S100). Interpreter 37 interprets the information input by the user to facilitate the creation of a set of pre-defined characteristics (S102). For example, the interpreter 37 may present a graphical user interface (GUI) to the user. The user could then use the GUI to indicate, for example, that a specific word (e.g., "urgent") is to form the basis of a set of pre-defined characterics whereupon the GUI would allow entry of the word. The user could also specify whether the set is to apply to voice messages, facsimile message, or both voice and facsimile messages. The interpreter then obtains the necessary templates and arranges these appropriately to create the new set of pre-defined characteristics (S104). In the case of an entered word to be applied to both voice and facsimile messages, the resulting set of characteristics constitutes voice templates and facsimile templates arranged to make the specific word. Preferably, the search interpreter 37 obtains the necessary templates from memory 26 which may store templates for voice and facsimile graphics. The search interpreter also associates each template with a text-based equivalent (S105). Memory 26 also preferably stores the text-based equivalent to which each template maps to facilitate an association of any given set of templates with text-based equivalents. The new set of characteristics is then stored in memory 26 along with an association to the text-based equivalents (S106), and a field is added to the envelope shell for this set which has a field ID pointing to the set in memory (S108).



FIG. 4c provides a flow chart of a method in accordance with this invention for the handling of user message operations requests. Referencing FIG. 4c, along with FIGS. 1 and 2, through user interface 20, a user may input a message operation request to processor 12 (S130). For example, the user may ask that any telephone number which might be part of a specified message be dialled or placed in a directory (i.e., stored separately from the message), that any URL found in a message from a certain sender be added to a bookmark file or sent to a browser program to allow access to an internet resource (e.g., web page), or that all messages containing certain keywords (e.g., messages containing the words "low priority") be deleted or played back. The message operation request is input to the text-based message operations engine 38. If the request involves a search for a text-based string (e.g., the word "urgent") (S132), the search parameters (e.g., message number of a specified message or an indication all messages are to be searched, along with an indication of the text-based string or strings which will satisfy the search) are passed to the text-based envelope search engine 40. The search engine searches the envelopes of all or specified messages for any text-based strings falling within the search parameters (S133). On finding such a string (or strings) (S134), the engine identifies the message number and string(s) to the text-based operations engine 38. The operations engine then operates on the message in accordance with the user's request (S136). This could involve, for example, automatically dialling a telephone number found in the envelope for a specified message or deleting, filing, or playing specified messages or messages from a specified sender. Also, the message, or a copy thereof, could be forwarded. In addition, where the message has a voice component, the system may be configured so that the operations engine 38 utilises the signal sample pointers 64 (FIG. 3) in the envelope field for a found string to call up the voice signal sample(s) represented by the string and play this on a speaker which is part of the user interface (S138, S140). Similarly, a fax message may have a sample called up and displayed. This would be useful where, for example, the search was for digit strings representing telephone numbers.



Optionally, the signal sample pointers 64 may be omitted and, where a message comprises a voice component, the message operations engine may pass the text-based equivalent to a voice synthesizer (which may be part of the user interface) to play a voice equivalent.



As will be appreciated by those skilled in the art, the automatic dialling may be effected by sending a message on network 14 (or other communication path) to an automatic dialler or computer telephony interface.



If no matches are found, the processor simply reports this to the user (S135). If the message operations request does not have search parameters, but instead identifies a specific message or messages, program control passes from S132 to S136.



As should be apparent from FIG. 3, the envelope 52 may be added as a header to the non-text message 54. Thus, the enveloped message 50 comprises a text-based envelope 52 and a non-text (or text-based) message 54. Many existing messaging systems, such as MICROSOFT EXCHANGE.TM., include an expandable envelope structure for messages. In such a case, the existing envelope structure may be used and the enveloped message creator 28 may be unnecessary. Additional fields may then be associated with the existing envelope structure.



In an alternate and simplified embodiment, only the signal sample pointers 64 may be stored in a message envelope field on finding one or more signal samples falling with a set of pre-defined characteristics (and not the text-based equivalent). In this case, a user could request the system to play/display the signal samples pointed to by the sample pointers. For example, a set of pre-defined characteristics may identify messages from one of several specified company departments. The user could then, on request, hear/see these departments and then decide upon further action based on this information.



In another embodiment, messages may be enveloped and searches for sets of pre-defined characteristics conducted and ensuing operations undertaken as aforedescribed in conjunction with FIGS. 1 to 4. However, additionally, a user may define a set of pre-defined characteristics which, instead of being stored in memory for use in conjunction with new messages, is searched for immediately in an existing message or group of messages specified by the user. Any message containing this set of pre-defined characteristics may then be further operated upon based on an operation entered by the user or recalled from memory.



In a further embodiment, it is not necessary to envelope new messages. In this embodiment, non-text messages are searched for sets of pre-defined characteristics, and after finding one or more signal samples falling within a set of pre-defined characteristics, the apparatus immediately performs an operation on the message (e.g., the message is deleted). This operation could be one entered by the user or recalled from memory. In another aspect of this embodiment, after finding one or more signal samples falling within a set of pre-defined characteristics, the one or more signal samples are mapped to a text-based equivalent and the apparatus then takes action based on the text-based equivalent (e.g., dial a telephone number) rather than storing the text-based equivalent and/or pointer thereto in an envelope for the message.



Other modifications in accordance with the spirit of the invention will be apparent to those skilled in the art.

PatentNumber=6633564,FIELD OF THE INVENTION



This invention relates generally to the transmission of data in telecommunications networks and more particularly to the insertion of packets into an existing stream of data.



BACKGROUND ART



In the vast majority of conventional communication networks, data is often arranged into packets so that it can be manipulated more easily. Packets are typically provided with sufficient identification information to be handled independently from one another. This identification information is usually contained in a header which is appended to each packet. With this information, packets generated by different users can be transmitted in any order and reassembled at the intended destination. This flexibility allows schedulers used in today's networks to interleave packets and concurrently service transmission requests from different users.



For the transmission of data packets in a communication network, it is often convenient to subdivide each packet into smaller "chunks" known as physical layer blocks. By subdividing each data packet into smaller physical layer blocks, the data packets can be more easily manipulated by the transmission equipment and coding techniques can be used to ensure their safe transmission. For example, in order to ensure the error-free (low-error rate) transmission of data packets on a particular communication link, the packets may be subdivided into blocks and encoded with a forward error correcting code (FEC). Typically, this is done using a common block size as this allows the use of standardized encoding and decoding equipment at each end of the communication link which is independent of the size of the data packets to be transmitted.



While some physical layer protocols allow physical layer blocks for different higher-protocol-layer packets to be interleaved, other physical layer protocols require the physical layer blocks to be transmitted consecutively for a given packet. This is the case, for example, where only the first physical layer block for a given packet contains information about the identity of the packet. In such protocols an existing packet (or its associated blocks) cannot be "interrupted" to transmit other packets which may have a priority higher than that of the packet in the process of being transmitted. As the packets may be of varying size, depending of the user's application, high priority packets may be inappropriately delayed while waiting for long lower priority packets to complete their transmission.



This problem is exacerbated if the packets are of widely varying sizes. The presence of long user packets in the data stream can significantly increase the jitter or variation in the arrival time of other packets in the stream and seriously affect the overall performance.



For example, in a commonly used transmission scheme known as the ATSC A/53 Digital data/television standard, the user data is grouped into blocks of 188 bytes and transmitted at a rate of 10.7 mega-symbols per second or 21.4 Megabits/second. Thus, the transmission of each block with this standard requires approximately 76 micro-seconds (psec). User packets typically range from a few bytes to over 1500 bytes, and in accordance with this particular standard, may require anywhere from 1 to 9 blocks for transmission, depending on their length. This translates into a transmission time of at least 76 .mu.sec (1 block) and as high as 684 .mu.sec (9 blocks) for each packet. As a result, the jitter (or variability in arrival time) observed for speech or video packets interspersed with other large packets may fluctuate from 76 .mu.sec to 684 .mu.sec which leads to a substantial degradation in performance.



In conventional systems, it is up to the scheduler process in the transmitter to try to organize the transmission of the packets such that the higher priority packets are not unduly delayed by other less important packets which have a lower priority. In so doing, the scheduler must leave enough room on the communication link to allow for the transmission of higher priority packets when necessary. However, this often results in an inefficient use of the communication links which can also seriously affect the overall performance of the communication network.



In view of these problems, it would be desirable to be able to "interrupt" the transmission of an existing packet. As noted above, there may be situations where some packets are more important than others and may require transmission without being unduly delayed. This would occur where, for example, time sensitive data such as a speech packet must be transmitted while a long data packet is in the course of being transmitted. The speech packet may be time sensitive in the sense that if it does not arrive in time at the receiver, there will be an audible interruption to the received speech. The longer data packet is typically of lower priority as it may be part of computer-to-computer communication in which a protocol such as the Transmission Control Protocol/Internet Protocol (TCP/IP) is being used to control the transport of a larger message composed of a number of packets which may arrive slowly (over an interval of a few milliseconds or seconds) at the intended destination.



Accordingly, there is a need to provide a communication network with an efficient method for interrupting the transmission of existing (low-priority) packets to insert one or more new (higher priority) packets.



SUMMARY OF THE INVENTION



It is an object of the present invention to obviate or mitigate one or more of the above-identified disadvantages.



For systems in which packets are each transmitted as a series of consecutive physical layer blocks, this invention provides a method and apparatus for efficiently interrupting the transmission of an existing packet to send one or more interrupting packets which may have a higher priority than that of the existing packet. When an interrupting packet must be sent, the transmission of physical layer blocks used for the existing packet is interrupted to allow the transmission of at least one new block for the interrupting packet. The presence of the interrupting packet within the new block is efficiently denoted by existing fields which are already used for a different function when there is no interrupting packets.



In a preferred embodiment, the invention is used in connection with common transmission schemes known as the Data Over Cable Service Interchange Specification (DOCSIS) or the Asynchronous Transfer Mode (ATM) adaptation layer 2 (AAL2) format of the International Telecommunications Union (ITU) recommendation I363.2. In these schemes, the presence of a new packet in a physical layer block is indicated as part of the block format. In the DOCSIS specification, the presence of a new packet is indicated by a Payload Unit Start Indicator (PUSI) and a Pointer Field (PF). In the ATM AAL2 I.363.2 format, an OffSet Field (OSF) is used. The presence of an new interrupting packet in a physical layer block is denoted by setting the PUSI/PF or OSF to an unused value (and formely invalid) to flag the new packet as an interrupting packet.



Advantageously, the method provided by the present invention can be practised recursively to accommodate multiple levels of interruption. As such, an interrupting packet can itself be interrupted by another, perhaps more important packet. When the transmission of an interrupting packet is complete, the transmission reverts back to the preceding level of interrupted packets until all levels of interruption are completed. With this method, multiple levels of interruption may be realized to efficiently regulate the transmission of packets with different priorities.



By comparison with existing methods, another advantage of the present invention is that the scheduling of packets is significantly simplified. Because data packets can be interrupted whenever necessary, they can be transmitted anytime without delaying the transmission of higher priority packets. As a result, the idle periods are reduced and the communication links present in a network are more efficiently used.



Yet still another advantage of the present invention is that the jitter in the arrival time of higher priority packets can be better controlled which results in a significant improvement in transmission performance.



Other aspects and features of the present invention will become apparent to those ordinarily skilled in the art upon review of the following description of specific embodiments of the invention in conjunction with the accompanying figures.



BRIEF DESCRIPTION OF THE DRAWINGS



Preferred embodiments of the invention will now be described with reference to the attached drawings in which:



FIG. 1 is a block diagram of a communications network and subtending user equipment;



FIG. 2 is a diagram of a data packet defined by the data over cable service interchange specification (DOCSIS) which is used to carry ISO8802 data packets in the network of FIG. 1;



FIG. 3A is a diagram of a Motion Picture Experts Group (MPEG) block used for transmitting packets such as the ISO8802 data packet illustrated in FIG. 2;



FIG. 3B is a diagram of an Asynchronous Transfer Mode (ATM) adaptation layer 2 (AAL2) cell defined by the International Telecommunications Union (ITU) recommendation I363.2;



FIG. 4 is a diagram of three MPEG blocks used for transmitting a longer packet;



FIG. 5 is a diagram of an MPEG block showing the insertion of an interrupting packet into an existing packet of the data stream according to an embodiment of the invention;



FIG. 6 is a diagram of two MPEG blocks showing the insertion of an overlapping interrupting packet into an existing packet of the data stream according to an embodiment of the invention;



FIG. 7 is a diagram of two MPEG blocks showing the insertion of an overlapping interrupting packet before a new packet of the data stream according to an embodiment of the invention;



FIG. 8 is a diagram of three MPEG blocks showing the insertion of three interrupting packets into an existing packet of the data stream according to an embodiment of the invention;



FIG. 9 is a diagram of two ATM cells showing the insertion of an overlapping interrupting packet into an existing packet of the data stream according to another embodiment of the invention;



FIG. 10 is a flow chart of a conventional scheduler process used for packet transmission;



FIG. 11A is a flow chart of a first portion of a block assembly algorithm for packet transmission according to the invention;



FIG. 11B is a flow chart of a second portion of the block assembly algorithm of FIG. 11A;



FIG. 11C is a flow chart of a third portion of the block assembly algorithm of FIG. 11A; and



FIG. 11D is a flow chart of a fourth portion of the block assembly algorithm of FIG. 11A.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



This invention provides a network with a method to interrupt the transmission of an existing packet to insert one or more packets of a higher priority. The invention can be incorporated in any network topology or configuration. For simplicity however, the invention will now be described only in relation to a communications network (hereinafter referred to as "the network"). An example of a network is shown in FIG. 1 as generally indicated by 14.



The network 14 illustrated therein is composed of a plurality of nodes indicated by 1, 2, 3, 4 (only four shown) Each of these network nodes 1, 2, 3, 4 is linked to others of the network nodes 1, 2, 3, 4 by one or more communication links X respectively 7, 8, 9, 10, 11.



The network 14 is also interconnected with other networks 19 to provide network users with a variety of services such as Internet-based services, cable TV or access to the public switched telephone network (PSTN). These services are remotely available to users by way of access connections 12, 13 (only two shown) to the nodes 1, 2, 3, 4. As is the case with most network access connections, these connections 12, 13 may be implemented with coaxial cables, telephone lines or alternatively implemented with radio. As such, the connections 12, 13 have a limited bandwidth and efficient use of them is quite important.



FIG. 1 shows a typical connection arrangement for multi-service access which consists of terminating each access connection 12, 13 by a respective set-top-box (STB) 105, 106 with connections to a personal computer (PC) 5, 6 for access to Internet-based services, a telephone set 15, 17 for voice services and a television set 16, 18 for video services. The STBs 105, 106 are shown on FIG. 1 as stand-alone devices. It is understood that the STBs 105, 106 could alternatively be implemented within the PCs 5, 6 or in the further alternative, within any other device which can be modified to incorporate the STB functionality.



The user information exchanged on either connection link 12, 13 may consist of voice, video, data or a combination thereof, depending on which services are operational. For example, a user at the PC 5 may connect to the network 14 for down loading a file from an Internet site and at the same time, talk on the phone 15 to another user on the phone 17 also connected to the network 14 through the STB 106, in which case both data and voice information would be exchanged on the communication link 12.



In FIG. 1, each STB 105, 106 provides the necessary interface for the exchange of user information between the network 14 and the telephone sets 15, 17 for voice services, the television sets 16, 18 for video services and the service applications loaded in each PC 5, 6 (not shown) for computer-based services. As such, the STBs 105, 106 convert the user information received into a suitable format and forward the converted information to the intended destination. For example, in the course of a telephone conversation between two users connected through the network 14 with the phones 15, 17, the speech information generated by the telephone set 15 which is intended for the other set 17 is first converted by the corresponding STB 105 into a format for transmission to the network 14 over the associated communication link 12. The converted information traverses the network 14 and reaches the other STB 106 where the information is converted back into a format suitable for use by the other telephone set 17. The same process also applies in respect to speech information travelling from the telephone set 17 to the set 15 and also to any other types of information travelling through the STBs 105, 106. The manner in which this information is converted by the STBs 105, 106 is well-known in the art and is not described here in any detail.



The user information exchanged between the STBs 105, 106 and the network 14 is arranged in the form of packets which are each packaged with a header containing identification information such as the packet type and length. The packets are formatted according to the Data Over Cable Service Interchange Specification (DOCSIS). DOCSIS is a well-known transmission scheme which is widely used to access networks for the exchange of multi-media information as it has defined a number of different packet formats. These packet formats can be used for the transmission of video or data.



FIG. 2 shows as an example the format specified by the DOCSIS standard to carry an ISO8802 data packet. For simplicity, the data packet shown in this figure is hereinafter referred to as a DOCSIS packet. The DOCSIS packet is only representative of a particular format specified by DOCSIS and it is to be noted that DOCSIS also specifies other formats to carry different types of data packets. It is to be understood in this description that by referring to a DOCSIS packet, reference to other formats is also implied.



The format for the DOCSIS packet shown in FIG. 2 is formed of a payload 21 to contain the ISO8802 data packet and a six byte header 20. The ISO8802 data packet contained in the payload 21 is itself comprised of a destination address (DA) 22 specifying the address of the intended destination of the ISO8802 packet, a source address (SA) 23 specifying the source address of the packet, a type/length field 24 specifying the type and length of the payload 21, the 0 to 1500 bytes of user data 25 carried by the packet and a cyclic redundancy code (CRC) 26 which acts as an error detection code to detect the occurrence of transmission errors in the payload 21. The ISO8802 data packet in the payload 21 is used for carrying a portion of the user data to be transmitted and is packaged with the header 20 which contains a number of standard DOCSIS fields to properly identify the ISO8802 packet and its contents. Of particular interest are the fields identifying the packet type 27 (ISO8802) and length 28 which, for an ISO8802 packet, can range from 18 bytes (just the DA 22, the SA 23, the type/length field 24 and the CRC 26) to 1518 bytes (full length).



For the transmission of packets such as the DOCSIS packet illustrated in FIG. 2, it is often convenient to block each packet into smaller chunks known as physical layer blocks. By subdividing each packet into smaller blocks, the packets can be more easily manipulated by the transmission equipment. Moreover, coding techniques can be used to improve the reliability of the transmission and enhance performance. For example, in order to reliably transmit data packets between the STB 105 and node 4 of the network 14 over the communication link 12 (see FIG. 1), the packets are first subdivided into blocks and then are encoded with a forward error correcting code (FEC). Typically, this is done using a common block size as this allows the use of standardized encoding and decoding equipment at each end of the communication link 12 which is independent of the size of the data packets to be transmitted.



An example of this is the DOCSIS transmission of data or video information between the STBs 105, 106 and the network 14. For this, DOCSIS specifies a common block size of 188 bytes. As is well known, the 188 byte block size specified was selected to be compatible with a common video image coding scheme developed by the Motion Picture Experts Group (MPEG) so that the encoding and decoding of the physical layer blocks could be standardized. The physical layer blocks formatted in accordance with the MPEG standard are commonly referred to as MPEG physical layer blocks or simply MPEG blocks.



As noted above, the common block size of 188 bytes defined by DOCSIS for the transmission of data or video packets permits the use of standard coding techniques to improve the reliability of transmission. Accordingly, the MPEG blocks used for the transmission of DOCSIS packets between the STBs 105, 106 and the network 14 are encoded with a FEC referred to as the Reed Solomon (RS) code (188,204). The RS coding scheme encodes the 188-byte block to a physical layer block of 204 bytes with the ability to correct up to 10 bytes of errors in transmission. To further describe the format of the MPEG blocks used for transmitting DOCSIS packets, reference is now made to FIG. 3A which shows, as an example, the format of an MPEG physical layer block encoded with the RS code (188,204).



The MPEG physical layer block shown therein is comprised of a data payload 30 for carrying DOCSIS packets or a portion thereof, a 16 byte RS-FEC code 31 for correcting potential transmission errors and an optional pointer field 32 to identify the beginning of each included DOCSIS packet (further details below). According to the MPEG standard, the optional pointer field 32 uses one byte and the data payload 30 is 183 or 184 bytes long, depending on whether or not the pointer field 32 is present in the MPEG block to signify the beginning of a new DOCSIS packet (further details below). The MPEG block is packaged with a 4 byte header 33 which mainly serves to mark the block's boundaries and control its transmission.



As is well known, DOCSIS packets are of varying sizes and do not fit perfectly into the fixed length MPEG block size. As such, the transmission of a DOCSIS packet may require several MPEG blocks or alternatively, one MPEG block may be sufficient to transmit several DOCSIS packets. As multiple MPEG blocks can be used to transmit a DOCSIS packet or alternatively, as a single MPEG block can be used to transmit several DOCSIS packets, it becomes desirable for a receiver used in the network 14 or in either the network or one of the STBs 105, 106 (see FIG. 1) to have the ability to locate the beginning of every DOCSIS packet received for the purpose of reassembly and processing. If there were no errors in transmission, the receiver might choose to find any DOCSIS packet by decoding all the incoming packets from the MPEG physical layer blocks and watching their length fields. As was described above, these length indicators show the length of the DOCSIS packets, and hence may be used to find the starting place of the next packet in an incoming stream of data.



However, if there are errors in transmission or one of the MPEG physical layer data blocks is lost, the receiver will be unable to find the beginning of the next DOCSIS packet as it re-synchronizes itself to correctly receive and decode the MPEG physical layer blocks. The DOCSIS packet headers are generally indistinguishable in the data stream from the data they carry and thus cannot easily be found by simply looking at the data stream. Some data transmission systems make use of a packet header that is distinguishable from the data, but doing so is inefficient and substantially reduces the number of possible data patterns for transport and, as a result, is not the preferred method for this application.



In order to identify the beginning of each DOCSIS packet transmitted, the MPEG block is packaged with the optional pointer field 32 and a payload unit start indicator (PUSI) bit 34 which is contained in the header 33. In addition to the PUSI 34, the MPEG header 33 also includes synchronization fields (not shown) and information relating to service identification and transport priority (not shown). This additional data contained in the MPEG header 33 is well-known in the art and is not be described here in any detail.



According to the DOCSIS standard, the begining of DOCSIS packets may be placed anywhere within the payload 30. While at the beginning of a transmission, the first MPEG block sent will typically coincide with the start of the first DOCSIS packet to be transmitted, after a few MPEG blocks and with a mixture of sizes of DOCSIS packets, there is no fixed relation between the MPEG physical layer block boundaries and the DOCSIS packets. That is, for any given MPEG block, a DOCSIS packet (and its corresponding header) may start anywhere within the payload 30 portion and, as a result, may overlap the block boundaries to extend into subsequent MPEG blocks.



As noted above, the PUSI bit 34 is part of the MPEG block header 33. If the PUSI bit 34 is set, it indicates that the MPEG block contains the start of a DOCSIS packet, and that the first byte after the MPEG header 33 contains a pointer (the pointer field 32) to the beginning of the DOCSIS packet. In between the pointer field 32 and the beginning of the DOCSIS packet, there may be either the tail end of a previous DOCSIS packet, or in some cases, some fill (unused) bytes. As such, a receiver may examine the MPEG block header 33 and learn where the next DOCSIS packet starts within the MPEG block. If the PUSI bit 34 is not set, it indicates that the payload 30 is the continuation of a packet started in a previous block and that this continuation fills this entire block. In this way, the variable sized DOCSIS packets can be efficiently placed into the standard size MPEG physical layer blocks.



According to the MPEG standard, the pointer field 32 is one byte. As such, the pointer field 32 may accomodate numbers in the range 0 to 255. The maximum payload size in the MPEG block is 183 bytes, which leaves the pointer field values from 184 to 255 unused.



The Asynchonous Transfer Mode (ATM) adaptation layer 2 (AAL2) format of the International Telecommunications Union (ITU) recommendations I363.2 makes use of a similar technique to pack data packets in standard physical layer blocks. To further illustrate this, reference is now made to FIG. 3B which shows the format of an example of an ATM physical layer block (hereinafter referred to as an "ATM cell") used for that particular ATM communications protocol.



The ATM cell shown therein is comprised of a data payload 110 for carrying data packets or a portion thereof and an offset field (OSF) 113 to identify the beginning of any included data packet. According to the ATM AAL2 standard, the data payload 110 is 47 bytes long while the optional OSF 113 shares a byte with a one bit sequence number 112 and a one bit parity field 111. The ATM cell is packaged with a 5-byte header 114 which serves to mark the block's boundaries and control its transmission.



The role of the OSF 113 within the ATM cell is similar to that of the pointer field 32 and the PUSI bit 34 within the MPEG block illustrated in FIG. 3A. As such, the OSF 113 is also used to indicate the presence of a new data packet in the ATM cell. More specifically, the OSF 113 is used to signal the presence of any new data packet and point to the beginning of the data packet within the ATM cell payload 110. With its 6-bit size, the pointing values that the OSF 113 can accomodate range from 0 to 63. However, as the ATM cell payload 110 is only 47 bytes long, only values up to 47 are used. According to the ATM AAL2 standard, the values in the range of 48 to 63 are not used.



Considering again the transmission of data with MPEG physical layer blocks, reference is now made to FIG. 4 which further illustrates how DOCSIS packets may be placed into multiple MPEG blocks by the use of the PUSI bit and the pointer field. In particular, this figure shows a DOCSIS packet 35 extending over three MPEG blocks respectively numbered 36, 37 and 38. For this example, it is assumed that the first MPEG block 36 coincides with the start of the DOCSIS packet 35 illustrated therein.



Similarly to the MPEG block described above in reference to FIG. 3A, the first MPEG block 36 is formed of a 16 byte RS-FEC code 39, a data payload 40 and a pointer field 41 all packaged with an MPEG header 42 which includes a PUSI bit 50. It can be observed that the PUSI bit 50 is set to one to signal the start of the new DOCSIS packet 35 and indicate that the first byte following the MPEG header 42 contains a pointer (the pointer field 41) to the beginning of this packet 35. As this block 36 corresponds to the start of the DOCSIS packet 35, it can also be observed that the value contained in the pointer field 41 is zero which points to the first byte of the data payload 40 where the beginning of the DOCSIS packet 35 is located. It can further be observed that the presence of the pointer field 41 reduces the capacity of the data payload 40 by one byte. As a result, the payload 40 only contains the first 183 bytes of the DOCSIS packet 35.



The second MPEG block 37 shown in FIG. 4 also has a 16 byte RS-FEC code 43 and a data payload 44. This block 37 is packaged with an MPEG header 45 which also includes a PUSI bit 51. It can be observed that contrary to the first MPEG block 36, this block 37 does not have a pointer field as there is no start of packet to flag. It can also be observed that the PUSI bit 51 is set to zero to indicate that this block 37 is a continuation of the DOCSIS packet 35 initiated in the first MPEG block 36 and that this continuation fills the entire block 37. It can further be observed that since there is no pointer field in this block 37, the payload 44 contains the next 184 bytes of the DOCSIS packet 35 following the first 183 bytes of that packet 35 which were placed in the first MPEG block 36.



The third MPEG block 38 is used to transmit the remainder portion of the DOCSIS packet 35 and initiate the transmission of a new packet 53. Similarly to the first and second MPEG blocks 36, 37, this block 38 also has an RS-FEC code 46, a data payload 47 and a header 49 which contains a PUSI bit 52. In addition, the block 38 also has a pointer field 48. It can be observed that the PUSI bit 52 here is set to one to flag the beginning of the new DOCSIS packet 53 and indicate that the first byte following the MPEG header 49 contains a pointer (the pointer field 48) to the beginning of this new packet 53. In contrast to the first block 36, the value contained in the pointer field 48 of this block 38 is set to M which points to the Mth byte of the data payload 47 where the beginning of the new DOCSIS packet 53 is located.



In conventional systems, the use of MPEG blocks together with the PUSI bit and the pointer field such as shown in FIGS. 3 and 4 works well for data services when there is not much urgency for the delivery of packets. Under these conditions, the transmission of any packet must be completed before any other packet can be sent. As a result, once a transmitter starts sending a long user data packet which overlaps several physical layer blocks, it will delay the transmission of all other packets until all of its physical layer blocks have been transmitted. As the transmission of a user packet cannot be interrupted, high priority packets are delayed every time a long packet is transmitted.



According to an embodiment of the present invention, instead of delaying high priority packets when an existing packet of, perhaps, a lower priority is in the process of being transmitted, the existing packet is "interrupted" and the high priority packets (hereinafter also referred to as "interrupting packets") are inserted into the data stream. More specifically, if a high priority packet is to be sent while an existing packet is being transmitted, the transmission of the MPEG blocks of that packet is interrupted, and the high priority packet is inserted into the data stream for transmission.



According to the present invention, the insertion of a high priority packet is preferably initiated with a new MPEG block. If a block is in the process of being transmitted at the time a decision is made to send a high priority packet, the transmission of that block is completed before the high priority packet is sent. Consequently, a high priority packet cannot be delayed any longer than the time necessary to complete the transmission of an existing physical layer block. This represents a substantial improvement over conventional methods since the transmission delay experienced by a high priority packet is effectively reduced from the time required to transmit a packet to the time necessary to transmit a physical layer block. As the transmission delay is reduced, the jitter in the arrival time of higher priority packets is better controlled which results in a significant improvement in transmission performance.



In a preferred embodiment, for the DOCSIS/MPEG standard, the presence of a high priority (interrupting) packet in an MPEG block is signalled by the PUSI bit together with the pointer field. More specifically, when a high priority packet is sent, the PUSI bit is used as described above to denote the presence of a new packet (the high priority packet) while the pointer field is set to indicate that the new packet signalled by the PUSI bit is in fact an interrupting packet and not the end of a low priority packet or the beginning of a new packet of the data stream.



In order to flag the interrupting packets, the present invention utilizes values of the pointer field which are not used for the transmission of non-interrupting packets. It will be recalled that the pointer field is normally used in the MPEG transmission scheme described above to denote the start of a new packet within a physical layer block. The pointer field as defined in MPEG is one byte long which allows pointing up to 255 possible locations within the block data payload. According to the MPEG format, the size of the block payload is only 184 bytes (or 183 bytes when a pointer field is present) which, as a result, leaves the values from 184 to 255 unused. According to the present invention, any of these unused values may be used in the pointer field to indicate the presence of an interrupting packet in the data stream.



To further illustrate this, FIG. 5 shows as an example, an MPEG block 63 in which an existing packet 56 is interrupted (hereinafter the "interrupted packet") for inserting an interrupting DOCSIS packet 58 with a pointer field 59 set to 255. From this Figure, a number of observations can be made. First, in can be observed that in addition to the pointer field 59, this particular MPEG block 63 is also formed of an RS-FEC code 55, a data payload 62 and an MPEG header 60 which includes a PUSI bit 61. It can also be observed that the PUSI bit 61 of this block 63 is set to 1 to flag the presence of the interrupting packet 58 as a new packet. It can also be observed that the pointer field 59 is set to 255 which indicates that the new packet 58 flagged by the PUSI bit 59 is in fact an interrupting packet. It can still be further observed that the interrupting packet 58 is inserted at the beginning of the MPEG block payload 62.



In order to resume transmission of the interrupted packet 56 or alternatively flag the presence of a further interrupting packet (not shown), the MPEG block 63 used for transmitting the interrupting packet 58 is provided with a continuation field 57, preferably of a length of one byte, which is used as follows: if it is set to zero, the next byte in the MPEG block payload 62 is the continuation of the original interrupted packet 56. If it is not zero, it indicates that the next byte is the first of a following interrupting packet (further details below). In the example of FIG. 5, as there is only one interrupting packet 58, the continuation field 57 of the MPEG block 63 is set to zero to signal that what follows thereafter in the block payload 62 is the continuation of the interrupted DOCSIS packet 56. A receiver may use the length indication in the header of the interrupting packet 58 to determine the exact location of the continuation field 57 in the payload 62.



When an interrupting packet is small enough to be contained in a single physical layer block such as illustrated in FIG. 5, the pointer field used to signal the presence of the interrupting packet and the continuation field used for indicating whether there are any other interrupting packets following limit the capacity of the block payload to 182 bytes. As a result, any interrupting packet which is more than 182 bytes in length will extend into the next block and possibly into subsequent blocks, depending on the length of the interrupting packet to be inserted.



To illustrate this, FIG. 6 provides an example where two MPEG blocks 65, 66 are required to transmit a new packet 67 which is more than 182 bytes in length. With respect to the first block 65, it can be observed that it has an RS-FEC code 68, a data payload 69, a pointer field 70 and a header 71 which contains a PUSI bit 78. It can also be observed that the PUSI bit 78 of the header 71 is set to one to flag the presence of the new (interrupting) packet 67 within the block payload 69. It can further be observed that the pointer field 70 is set to 255 for indicating that the new packet 67 flagged by the PUSI bit 78 is an interrupting packet. It can still further be observed that the interrupting packet 67 extends into the second MPEG block 66 since it is more than 182 bytes in length.



With respect to the second block 66, it can be observed that it is formed of an RS-FEC code 72, a data payload 75 and a header 76 which contains a PUSI bit 77. It can also be observed that the PUSI bit 77 is set to zero to indicate that this block 66 is a continuation of the interrupting DOCSIS packet 67 initiated in the first MPEG block 65 and that it does not contain any new packet. In contrast with the first block 65, it can further be observed that this block 66 does not have a pointer field as there is no start of packet to flag. Considering the block data payload 75 in particular, it can be observed that the interrupting packet 67 is followed by a continuation field 74 which is set to zero to indicate that the remainder portion of the block data payload 75 does not contain any more interrupting packets and instead is used to resume transmission of the interrupted packet 73.



In a situation where the remainder portion of the interrupted packet 67 is less than the free space available in the data payload 75 of the second block 66, the unused room in the payload 75 may be used to initiate the transmission of a new packet in accordance with the MPEG standard. This situation is illustrated in FIG. 7 where the example shown in FIG. 6 is reproduced with two variants. The first variant relates to the second block 66 which is now shown with the PUSI bit 77 set to one and with a pointer field 79. The second variant is with respect to the remainder portion of the interrupting packet 67 contained in the payload 75 of the second block 66 which is now shown to be less than the free space available. With respect to these variants, it can be observed that the unused room of the second block 66 is used for initiating the transmission of a new packet 80 in accordance with the MPEG standard. Accordingly, the PUSI bit 77 of the second block 66 is set to one to denote the presence of this new packet 80 and the associated pointer field 79 is set to point to the beginning of the new packet 80.



The examples described above in reference to FIGS. 5, 6 and 7 all relate to the insertion of a single interrupting packet into the data stream. There may be situations where it is desirable to send more than one interrupting packet. According to the present invention, the non-zero values of the continuation field can be chosen to notify a receiver that there are more interrupting packets to come and in particular, provide an indication as to the number of interrupting packets to follow. As an example, in a situation where three interrupting packets must be sent, the continuation field used after the transmission of the first interrupting packet could initially be set to two, indicating that two interrupting packets are yet to be transmitted. After the transmission of each remaining interrupting packet, the continuation field would be decremented by one to reflect the number of interrupting packets left to transmit. Accordingly, after the last interrupting packet, the continuation field would be set to zero indicating the resumption of the interrupted packet.



To further illustrate this, FIG. 8 shows as an example, a situation where an existing packet 100 is interrupted and three interrupting packets 87, 85, 93 are inserted into the data stream using three MPEG blocks 81, 82, 83. With respect to the first block 81, it can be observed that it has an RS-FEC code 84, a data payload 91, a pointer field 88 and a header 89 which contains a PUSI bit 90. It can also be observed that the PUSI bit 90 and the pointer field 88 are respectively set to one and 255 for denoting the presence of the first interrupting packet 87 located at the beginning of the block payload 91 immediately following the pointer field 88. It can further be observed that the first interrupting packet 87 is followed by a continuation field 86 which is set to two for indicating that there are two further interrupting packets 85, 93 to follow. Immediately after the continuation field 86, the second interrupting packet 85 follows and extends into the second MPEG block 82.



The second block 82 is similarly arranged to the first block 81 described above and as such, has an RS-FEC code 92, a data payload 98 and a header 96 which contains a PUSI bit 97 set to zero. With respect to this block 82, it can be observed that in contrast to the first block 81, the second block 82 does not have a pointer field. It can also be observed that the data payload 98 contains the remainder portion of the second interrupting packet 85. This is followed by a continuation field 94 which is set to one to indicate that the next packet 93 (the third interrupting packet) is also an interrupting packet. It can also be observed that the third interrupting packet 93 begins immediately after the continuation field 94 and extends into the third MPEG block 83.



The third block 83 is similarly structured to the first and second blocks shown second MPEG block shown in this Figure and, as such has an RS-FEC code 99, a data payload 104 and a header 102 which contains a PUSI bit 103. With respect to this block 83, it can be observed that the PUSI bit 103 is set to zero to indicate that this block 83 is a continuation of the third interrupting packet 93 initiated in the second block 82 and that it does not contain any new (regular or interrupting) packet. As such, no pointer field is used. Considering the block data payload 104, it can be observed that the third interrupting packet 93 is followed by a continuation field 101 which is set to zero to indicate that the remainder portion of the block data payload 104 does not contain any more interrupting packets and instead is used to resume transmission of the interrupted packet 100.



The use of a continuation field (see FIG. 8) to indicate the number of following interrupting packets is useful when the number is known at the time the interruption begins. However, in some cases, an additional packet of the same priority level as the interrupting packet may arrive at a scheduler for transmission while the current interrupting packet is being transmitted. If the continuation field was being used to indicate the number of following interrupting packets, this new interrupting packet would not have been included in the count sent earlier. The newly arriving packet could not be sent until the resumption of transmission of the interrupted packet is complete. Generally, it would be preferable for the scheduler to simply send this new (additional) interrupting packet after transmission of the current interrupting series of MPEG blocks is complete. In order to do this, the scheduler may need to send a greater number of interrupting packets than may have been previously indicated by the continuation field. Preferably in this case, a non-zero value of the continuation field is used to indicate a following interrupting packet of the same priority level, and a zero value of the continuation field is used to indicate the continuation of a previously interrupted packet.



The above examples have described how the present invention can be used with the DOCSIS/MPEG transmission format to insert interrupting packets into a data stream. A similar method may also be used to allow insertion of interrupting packets in the ATM AAL2 (ITU I.363.2) transmission format. In order to flag the interrupting packets with this standard, the present invention utilizes values of the OSF which are not used for the transmission of non-interrupting packets. It will be recalled that the OSF as defined in ATM AAL2 (ITU I.363.2) is 6 bits long which allows pointing up to 63 possible locations within the ATM cell payload. According to the ATM AAL2 (ITU I.363.2), the size of the cell payload payload is only 47 bytes which, as a result, leaves the values from 48 to 63 unused (the value of 47 being used to indicate that no new packet is present within the cell). Any of these unused values may be used in the OSF to indicate the presence of an interrupting packet in the data stream.



To further illustrate this, reference is now made to FIG. 9 which shows as an example, a situation where an existing packet 120 is interrupted and an interrupting packet 122 is inserted into the data stream using two ATM cells 123, 124. The first ATM cell 123 has a data payload 129, a parity bit 125, a sequence number 126, an OSF 127 and a header 128. The OSF 127 is set to (the conventionally unused value of) 63 to flag the start of a new interrupting packet 122 in the ATM cell 123 following the parity bit 125. In this particular example, the interrupting packet 122 extends into the next physical ATM cell 124 as it is more than 47 bytes in length.



The second ATM cell 124 is also formed of a data payload 140, a parity bit 136, a sequence number 137, an OSF 138 and a header 139. It can be observed that the OSF 138 is set to 47 to indicate that this ATM cell 124 is a continuation of the interrupting packet 122 initiated in the first ATM cell 123 and that it does not contain any new packet. Considering the ATM cell payload 140 in particular, it can be observed that the interrupting packet 122 is followed by a continuation field 135 which is set to zero to indicate that the remainder portion of the cell data payload 140 does not contain any more interrupting packets and instead is used to resume transmission of the interrupted packet 120.



In the above example, the second ATM cell 124 does not contain any new interrupting or non-interrupting packets following the transmission of the interrupting packet 122. In situations where more interrupting or non-interrupting packets must be transmitted, the OSF 138 defined in the ATM AAL2 (ITU I.363.2) format and the continuation field 135 are used in the same general manner as the pointer field and the continuation field described above in relation to the MPEG format.



According to the present invention, the interrupting process described above is recursive. As such, it is possible for an interrupting packet that extends across a physical layer block to be itself interrupted by another packet with perhaps a higher priority than that of the original interrupting packet being interrupted. In order to insert an interrupting packet (hereinafter referred to as a "higher priority interrupting packet") into another existing interrupting packet (hereinafter referred to as a "lower priority interrupting packet"), the method described above for interrupting the transmission of an existing packet and inserting a high priority packet is simply repeated.



According to the present invention, the insertion of a higher priority interrupting packet into a lower priority interrupting packet is preferably initiated with a new physical layer block. If a block of the lower priority interrupting packet is in the process of being transmitted at the time a decision is made to send the higher priority interrupting packet, the transmission of that block is completed before the higher priority packet is sent. The presence of the higher priority packet in a block is signalled in the same manner a single interrupting block is denoted in a block (i.e. with the PUSI/pointer field indicators or the OSF indicator, depending on which transmission format is used). This was described in details above and is not repeated here. Following completion of the transmission of the higher priority packet, the transmission of the interrupted lower priority interrupting packet is resumed.



For situations where multiple levels of interruptions are required, the above-described recursive method is repeated for each interrupting packet to be inserted. In these situations, it is up to the receiving device to keep track of the interrupting and interrupted packets and assemble them all together when the interruptions are completed. In order to accomplish this, the receiver must be designed with the ability to collect the packets received into different stacks according to their level of interruption so that the packets can be subsequently reassembled for processing. The manner in which this is implemented would be obvious to a person skilled in the art and, as such, is not described here in any detail.



According to the invention, the above-described method of interrupting packets to insert higher priority packets in the data stream can be implemented in various ways. Preferably, the method is implemented as part of the scheduling process responsible for the transmission of data packets at the physical layer level. There are many ways to implement the scheduling process. Typically, the scheduling process is carried out by a scheduler but can also be carried out by any other network device (e.g. router) which incorporates the necessary functionality for scheduling data packet transmission.



One example of the scheduling process necessary for interrupting packets in accordance with the present invention will now be described. The scheduling process used with the DOCSIS/MPEG standard is similar to that necessary for use with the ATM AAL2 (ITU I.363.2) format. As such, only the scheduling process used with the DOCSIS/MPEG standard will be described below in reference to FIGS. 11A, 11B, 11C, and 11D. To begin, the process flow involved in assembling physical layer blocks from a series of incoming data packets of different priorities and lengths will be described as this is required for an understanding of the scheduling of interruptions.



Referring to FIG. 10, there is illustrated a flow chart of a typical process flow used for packet transmission. At the top of the flow chart, there is indicated the event of the arrival at a scheduler 150 of new data packets to be transmitted. As is well known, each new packet will have a respective priority designated for it which indicates whether it should be sent before or after other packets awaiting transmission. Each new packet is stored in a particular logical queue (Q) which corresponds to the packet priority level. The flow chart of FIG. 10 shows a plurality N of these queues Q1, Q2, QN (only three shown), each with a respective priority level where 1 is the highest transmission priority and N represents the lowest priority. The queues Q1, Q2, QN are each connected to the scheduler 150 which operates to assemble physical layer blocks based on the packets fetched from the queues Q1, Q2, QN and header information received from a block header unit 151.



The bottom section of the flow chart of FIG. 10 shows the transmission process of the physical blocks assembled by the scheduler 150. A buffer 153 (hereinafter the "current block buffer") is used to store a block in transmission. Connected to this current block buffer 153 is another buffer 152 (hereinafter the "next block buffer") where the next block to be transmitted may be assembled. This double buffer scheme enables the next block to be assembled during the time interval the current block is being transmitted. At the end of the transmission of the current block, the next block is transferred to the current block buffer 153 for transmission and the scheduler 150 can begin to assemble another block in the (now empty) next block buffer 152.



Without any interrupting operations, the scheduler 150 functions to select packets with the highest priority. In the flow chart example of FIG. 10, the highest priority packets are located in the Q1 queue. For each packet selected, the scheduler 150 operates to assemble blocks in the next block buffer 152 together with the appropriate block header and transmit them in sequence through the current block buffer 153. Once the scheduler starts to process a packet in one of the queues Q1, Q2, QN, it must complete the transmission of that packet before selecting a packet from another queue Q1, Q2, QN. This may cause delays in the transmission of other higher priority packets that arrive after the start of transmission of the lower priority packet.



By implementing the interrupting process described above to allow interruption of a packet, the scheduler 150 may begin the transmission of a higher priority packet anytime it begins the assembly of a new block, even if it has already started the transmission of another packet. For the purpose of describing the scheduling process necessary for interrupting packets in accordance with the present invention, a block assembly algorithm by which the scheduler 150 can select packets from the queues Q1, Q2, QN and assemble blocks for transmission in accordance with the invention is described below in reference to FIGS. 11A, 11B, 11C and 11D.



This block assembly algorithm is carried out each time a new block is assembled by the scheduler 150 in the next block buffer 152. Referring first to FIG. 11A, there is illustrated a flow chart of a first portion of the block assembly algorithm carried out by the scheduler 150. This particular portion deals with the assembly of blocks with non-interrupting packets stored in the queues Q1, Q2, QN (collectively denoted as "Q" in FIGS. 11A, 11B, 11C and 11D).



The algorithm makes use of two memory elements to keep track of the filling of the next block buffer 152. These elements consist of an interrupt level and a current Q pointer. The interrupt level element is used to denote the number of packet interruption levels. For example, when the interrupt level is zero, it indicates that there are no pending interrupting packets. The current Q pointer is used to denote the queue Q1, Q2, QN of the packet in transmission. The current Q pointer is also used to indicate whether there are any packets awaiting transmission. In particular, when set to zero, the current Q pointer indicates that all the queues. Q1, Q2, QN are empty.



According to the invention, the data packets (or portions thereof) waiting transmission are stored in the queues Q1, Q2, QN until the scheduler 150 begins to fill the next block 152. (see FIG. 10) in accordance with the block assembly algorithm. The block assembly algorithm operated by the scheduler 150 begins at point 1 in the flow chart of FIG. 11A. At that particular point, the algorithm initiates the process of filling the next block buffer 152 with a new block as follows. First, the algorithm checks the current Q pointer to determine whether there are any packets awaiting transmission. If there are none, the algorithm sets the current Q to idle (current Q=zero) and also sets the interrupt level to zero to signal a no-interrupt condition. The algorithm then fills the next block buffer 152 with an idle block and exits back to point 1. These steps are repeated until there is at least one packet in the queues Q1, Q2, QN awaiting to be transmitted.



When an incoming packet is detected, the current Q pointer is set to the queue Q1, Q2, QN in which the incoming packet is located (hereinafter the "current Q"). When it is time to fill another block, the other queues Q1, Q2, QN are then examined by the algorithm to see if there is any other packet in a queue Q1, Q2, QN of a priority higher than that of the current Q. If so, the block assembly algorithm jumps to a further execution point for inserting and transmitting the higher priority packet found. This further execution point is denoted by point 3 on FIG. 11A. The execution of the block assembly algorithm following point 3 is further explained below with reference to FIG. 11D.



If there is no other packet with a higher priority, the algorithm fetches the incoming packet from the queue Q1, Q2, QN designated by the current Q and begins assembling a first block in the next block buffer 152 to initiate transmission of the new packet (see FIG. 10).



The algorithm only fetches from the queue Q1, Q2, QN designated by the current Q as much of the incoming packet as will fit into the next block buffer 152. As data packets received in the queues Q1, Q2, Qn are of varying sizes (lengths), some will be bigger and some smaller than the block size used form transmission. If the incoming packet is too long to fit completely into the next block buffer 152, only a fitting portion will be fetched and the remainder is left in the queue Q1, Q2, Qn to await the next time the algorithm needs to fill the next block buffer 152. If the incoming packet is smaller and does not fill the next block buffer 152, then a following packet from the queue Q1, Q2, QN designated by the current Q or another queue Q1, Q2, QN may be selected to fill the remainder of the block. According to the invention, it is the role of the block assembly algorithm to efficiently select and pack the varying size packets into the next block buffer 152.



The algorithm then proceeds to determine whether the first block in assembly is in fact the first block of the new packet or whether it is instead a continuation block of a packet initiated in a previous block. In order to do this, the algorithm examines the current Q and the interrupt level as follows. If the current Q indicates that the scheduler 150 was previously idle or if the interrupt level is zero at the time the first block is assembled, the block assembly algorithm jumps to a further execution point, point 6 in the algorithm, where the transmission of new non-interrupting packets is handled (the execution of the block assembly algorithm following point 6 is further explained below with reference to FIG. 11B).



If neither of these two conditions is true, the first block in assembly is assumed to be a continuation block of a packet initiated in a previous block. The algorithm then checks to determine whether the new packet fills the first block in assembly. If so, the algorithm completes the assembly of the first block by setting the block header PUSI to zero without any pointer field therefore labeling the block assembled as a continuation block of a packet initiated in a previous block. The assembled block is then forwarded to the current block buffer 153 for transmission and the block assembly algorithm exits to point 1 to proceed with the assembly of another block.



If the new packet does not fill the first block in assembly, then the algorithm will check to see if the scheduler 150 is operating in an interrupt mode (interrupt level.noteq.zero). If the scheduler 150 is operating in an interrupt mode signalling the presence of an interrupting packet, the execution of the block assembly algorithm jumps to a further execution point, point 2 in the algorithm for the transmission of the interrupting packet in the remainder portion of the first block in assembly (the execution of the block assembly algorithm following point 2 is further explained below with reference to FIG. 11C). If the scheduler 150 is not operating in an interrupt mode, no interrupting packet is present and the remainder portion of the first block in assembly can be filled instead with another packet.



In order to signal the presence of a new packet in the first block, the header PUSI bit of the first block is set to one and the block pointer field is set to point to the beginning of the new packet within the first block. Next, a new packet must be found. The algorithm first checks the current Q, and if a waiting packet is found there, it is put in the unused portion of the first block in assembly. This new packet may fill (or overfill) the first block, in which case the block assembly algorithm will exit to point 1 to fill another block. If the new packet does not fill the first block in assembly, the algorithm looks again in the current Q for an awaiting packet. If none are found, the other queues Q1, Q2, QN are checked until a waiting packet is found. If a new packet is found in a particular queue Q1, Q2, QN, the current Q is updated to point to the queue in which the new packet was found and the new packet is loaded in the next block buffer 152 to complete assembly of the first block. If there are no packets waiting, the next block buffer 152 is filled instead with fill characters (as specified by the transmission block format), the current Q flag is set to idle (current Q=zero) to indicate that there are no packets are outstanding and the block assembly algorithm exits back to point 1 to proceed with the assembly of another block.



Referring now to FIG. 11B, there is illustrated a flow chart of a second portion of the block assembly algorithm carried out by the scheduler 150. This portion of the algorithm deals with the transmission of a new non-interrupting packet starting at point 6 in the block assembly algorithm. It will be recalled that at this particular point, the current Q indicates that the scheduler 150 was previously idle or that the interrupt level is zero at the time the first block is assembled.



When either one of these conditions occurs, the first block in assembly is assumed to be a first block for a new packet and not a continuation block. The algorithm sets the current Q number to the queue Q1, Q2, QN of the new packet. The first block header PUSI bit is set to 1 to indicate the start of the new packet in that block and the pointer field is set to point to the start of the new packet. The algorithm then checks to determine whether the new packet fills the first block in assembly. If the packet fills or overfills the first block, the assembled block is forwarded to the current block buffer 153 for transmission and the block assembly algorithm exits back to point 1 to proceed with the assembly of another block. If the new packet does not fill the first block, the algorithm jumps to point 7 to find another packet or series of packets to fill the lock.



The above has outlined the block assembly operation for filling blocks without any interruption. The block assembly operation for filling blocks with interrupting packets will now be described with reference to FIG. 11C and 11D. Referring first to FIG. 11C, there is illustrated a flow chart of a third portion of the block assembly algorithm carried out by the scheduler 150. This particular portion deals with the insertion of an interrupting packet.



At the top of the flow chart, point 2 is shown which, it will be recalled, is the point where the scheduler 150 is operating in an interrupt mode (interrupt.noteq.zero) to signal the presence of interrupting packets in the queues Q1, Q2, QN. At this point, an interrupting packet must be found. The algorithm first checks the current Q. If none are found, the lower priority queues Q1, Q2, QN are checked. This is done by setting the current Q number to the next lower priority and reducing the interrupt level by one.



If as a result, the interrupt level becomes zero, this indicates that there are no more interrupting packets to transmit and that transmission of the interrupted packet should resume. As such, the continuation field of the first block in assembly is set to zero and the assembly of the first block is completed with the interrupted packet. If the interrupted packet fills the first block, the block assembly algorithm exits back to point 1 to initiate the assembly of another block. If the interrupted packet does not fill the first block, the block is completed instead with fill characters. At this point, any awaiting packets must wait until the next block is assembled in order to be transmitted.



If, on reducing the interrupt level by one, the level has not reached zero, this indicates that there may be more interrupted interrupting packets waiting in the queues Q1, Q2, QN. The algorithm thus checks the current Q for awaiting packets and if there are none, reduces the current Q number to check the next queue Q1, Q2, QN. If there are packets in the current Q, the algorithm sets the continuation field to zero to indicate the resumption of an interrupted packet and fills the first block with the next packet in the current Q. If the block is not yet filled, another packet is searched for in the current Q or lower priority queues Q1, Q2, QN.



Referring back to point 2 of the algorithm execution, if a waiting interrupting packet is found in the current Q, it is put in the unused portion of the first block in assembly (see FIG. 11A) and as a result, the algorithm operates to set the continuation field of the first block in assembly to a non-zero value and complete the assembly of the first block with a new interrupting packet. If the interrupting packet fills (or overfills) the first block, the block assembly algorithm exits m back to point 1 after setting the block header PUSI bit of the first block to zero and ensuring that no pointer field is used. If the packet does not fill the first block, the algorithm must find another awaiting packet in a queue Q1, Q2, QN to complete the assembly of the first block and proceed with the assembly of another block.



Referring now to FIG. 11D, there is illustrated a flow chart of a fourth portion of the block assembly algorithm carried out by the scheduler 150. This portion of the algorithm deals with the insertion a new interrupting packet starting at point 3 of the block assembly execution. It will be recalled that at this particular point, an incoming packet is detected in a queue Q1, Q2, QN (the interrupted Q) but another packet of a higher priority is found in another queue Q1, Q2, QN. More specifically, at this particular point, the algorithm is about to fill the first block with a particular packet but has discovered another packet waiting that is in a queue Q1, Q2, QN of a higher priority than the current Q.



As the higher priority packet is detected, the algorithm first sets the interrupt level to a value equal to its current value summed with the difference between

PatentNumber=6691282,FIELD OF THE INVENTION



The invention relates to a method and apparatus for displaying and navigating containment hierarchies such as file folder containment hierarchies, and more particularly to a system and method facilitating on-screen navigation through a file folder hierarchy which has a substantial containment level and a large file folder size.



BACKGROUND OF THE INVENTION



Computers typically use directories or file folders to store files, thereby allowing files having some common characteristic to be stored together and accessed as a group. A top-level file folder may be considered as containing all the files on a given device, for example a hard disk or floppy drive. The top-level file folder then contains a containment hierarchy of file folders with each file folder containing file folders lower in the hierarchy, and/or files. A file folder which contains another file folder or file is referred to as a parent, while the file folders and/or files contained in a parent file folder are that file folder's children. Children files and file folders are each other's siblings. A file folder containing only files, and no file folders is a bottom-level file folder. The number of containments between a file in a bottom-level file folder and the top-level file folder is the containment depth for that file, and the number of files and file folders directly contained within a file folder is that file folder's size, also referred to as width or breadth.



Various graphical user interfaces have been adopted for navigating through the containment hierarchy of file folders, the most common being that used in MICROSOFT's Windows* based software such as File Manager and Windows Explorer. In these products, when a file folder having a "+" indicator (indicating it contains at least one file folder) is selected, a complete list of the file folder's children file folders is added to a displayed hierarchy in a left display window, and any children files contained in the file folder are displayed in a right display window. Other rules come into play when a device is selected. When a file folder from the list of children file folders is selected, a complete list of that file folder's children file folders contained in the selected file folder is added to the displayed hierarchy in the left display window, and so on. Windows provides various mechanisms for hiding the details of a file folder and for controlling somewhat what is displayed in the left window and the right window. These approaches work very well when the containment hierarchy has a small depth and a small breadth, but are cumbersome and inconvenient to use when one or both of these two characteristics are not true. This is because the containment hierarchy in combination with a large breadth (file folder size) may result in potentially relevant portions of the display being scrolled out of view, such that a user loses the ability to directly ascertain the containment or context of what is being displayed. More particularly, if the file folder of interest is in a large group of file folders at the same level in the hierarchy and contained within a single higher level parent file folder, Windows provides no way to focus on the file folder of interest to the exclusion of the others in the parent file folder. Suppose for example, the *Trademark file folder of interest is at the bottom of a list of one hundred file folders in a parent file folder, the hierarchy, or "context" of this parent file folder will scroll off the screen when a user moves down to the file folder of interest.



Another disadvantage of existing systems is that as the number of file folders opened increases, the display becomes cluttered making navigation to a new point in the hierarchy difficult. As a result the user is required to close up file folders when they want to navigate to new point.



It would be desirable to be able to navigate through a file folder containment hierarchy in a manner which allows the context of what is being observed to be continuously clear.



SUMMARY OF THE INVENTION



It is an object of the invention to obviate or mitigate one or more of the above identified disadvantages.



According to a broad aspect, the invention provides a method for use in a computer system for displaying a containment hierarchy such as a file folder hierarchy. The method displays a direct containment hierarchy for a selected containment group or file folder, and also displays a list of contents of one of the containment groups or file folders in the direct containment hierarchy. A direct containment hierarchy displays only file folders or containment groups which directly or indirectly contain the selected containment group or file folder. In this manner a large number of file folders or containment groups which do not ultimately contain the selected file folder or containment group are not displayed, thereby simplifying the display, and ensuring that the entire direct containment hierarchy can be shown on a single display screen without the need for scrolling in order to obtain or ascertain the context of the given file folder or containment group.



Preferably, the list of contents of the selected file folder or containment group is searchable to allow a user to quickly focus in upon files or file folders having names satisfying search criterion entered by the user.



Preferably, a pictorial representation of the selected file folder's position with the direct containment hierarchy is provided. A skilled user can then select files or file folders by using the pictorial representation rather than the textual representation, this in some cases allowing a quicker selection process to be realized.



In other embodiments of the invention, a computer system, a graphical user interface, an operating system, and a computer readable medium are respectively provided each of which have been adapted to implement one or more of the above discussed methods.



BRIEF DESCRIPTION OF THE DRAWINGS



Preferred embodiments of the invention will now be described with reference to the attached drawings in which:



FIG. 1 is an example of a containment hierarchy;



FIG. 2 is an example of how conventional products would display the hierarchy of a particular file in the example containment hierarchy of FIG. 1;



FIG. 3 is an example of a display of a file folder hierarchy of a particular file folder in the example containment hierarchy of FIG. 2 according to an embodiment of the invention;



FIGS. 4A through 4E are a sequence of figures illustrating how the display of FIG. 3 was arrived at;



FIG. 5 is an example of a containment hierarchy according to an embodiment of the invention in which the list of contents is scrollable;



FIG. 6 is an example of a containment hierarchy according to an embodiment of the invention in which a distinguishment has been made between various types of contents;



FIG. 7 is an example of another way of manipulating the containment hierarchy according to an embodiment of the invention;



FIG. 8 is an example of a containment hierarchy according to embodiments of the invention in which a pictorial representation is used to allow control over a list of contents; and



FIG. 9 is an example of a computer system for implementing methods provided by the invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



An example of a computer system by which embodiments of the invention may be provided or implemented is depicted in block diagram form in FIG. 9. A processing platform 10 such as a personal computer is shown connected to storage devices 12 (two shown), a display 14, a keyboard 16 and a mouse 18. The processing platform 10 has an operating system which is aware of or can ascertain the files stored on the storage devices 12 and knows their hierarchical containment.



Now, a few definitions will be given. FILE FOLDER: any mechanism for providing logical or physical containment of files; FILE: a logical or physical entity which does not have any containment; CONTAINMENT DEPTH: the term "containment depth" will be used to refer to a numeric value which identifies inclusively the number of containments between a file folder and a top-level file folder. Thus, a file folder with a containment depth of "3" with respect to the top-level file folder for example, is contained in another file folder which is contained in the top-level file folder. PARENT: a file folder which contains other file folders and/or files; CHILD,CHILDREN: files or file folders contained in a parent file folder; SIBLINGS: the name of files or file folders contained in the same parent, as they relate to each other.



A method displaying a file folder hierarchy according to an embodiment of the invention will be described by way of example for a particular arrangement of files and file folders which is illustrated graphically in FIG. 1. Indentation in FIG. 1 means containment. Thus, for example, "WORLD" contains "AFRICA", "ASIA", "AUSTRALIA", "EUROPE", "NORTH AMERICA" and "SOUTH AMERICA". In FIG. 1, file folders are indicated in bold, and regular files are not indicated in bold. Let us assume that we are interested in the contents of the file folder "TORONTO". For the sake of comparison, an example of the most concise hierarchy which might be displayed in conventional "Windows" based applications is illustrated in FIG. 2. The first thing one notices is that FIG. 2 includes the display of 34 file folders and files. Disadvantageously, there is no way to hide details of file folders contained in the same file folder as a file folder which contains directly or indirectly the file folder of interest. For example, although we are interested in "TORONTO", the display always includes file folders contained in "CENTRAL ONTARIO", in this case "BARRY", "HAMILTON", "MILTON", "OAKVILLE", "OSHAWA", and "SCARBOROUGH". This results in the lengthy display of FIG. 2, which when presented on a display screen, would likely result in the top portion of the hierarchy scrolling off the screen.



Referring now to FIG. 3, according to an embodiment of the invention, a computer system (for example the system of FIG. 9) is adapted to implement a method which displays the hierarchy for a selected file folder, (for example file folder "ONTARIO" in FIG. 1), by displaying a direct containment hierarchy 20 for that file folder, and by displaying a list of contents 22 of the selected file folder. In the illustrated example, the direct containment hierarchy 20 consists of the sequence of file folders "WORLD", "NORTH AMERICA", "CANADA", "ONTARIO", "CENTRAL ONTARIO", and "TORONTO". A direct containment hierarchy 20 consists of some top-level file folder, in this case "WORLD", and then a sequence of child file folders, one at each containment depth down to and including a lowest-selected file folder, in this case "TORONTO". As in this example, the sequence might end at a lowest-selected file folder which is a bottom-level file folder, but this need not be the case. The direct containment hierarchy 20 only includes the file folders which lead directly to the selected file folder. Thus, for the illustrated example, the child file folders contained by "WORLD" in addition to "NORTH AMERICA" are not displayed (as they are in prior art example of FIG. 2), the child file folders contained by "NORTH AMERICA" in addition to "CANADA" are not displayed (as they are in the prior art example of FIG. 2), the child file folders contained by "CANADA" other than "ONTARIO" are not displayed (as they are in the prior art example of FIG. 2), the child file folders contained by "ONTARIO" other than "CENTRAL ONTARIO" are not displayed (as they are in the prior art example of FIG. 2), and the child file folders contained by "CENTRAL ONTARIO" other than "TORONTO" are not displayed (as they are in the prior art example of FIG. 2). The result is a concise display of the hierarchy of the file folder "TORONTO" which can be immediately discerned directly from the display without the need to perform any scrolling.



To move to the next level in the hierarchy, a file folder from the list of contents 22 can be selected. A sequence of selections which results in the display of FIG. 3 is displayed in FIGS. 4A-4E. In FIG. 4A, the list of child file folders 30 contained in "WORLD" is displayed. Selection of the file folder "NORTH AMERICA" results in the display of FIG. 4B which is a list of child file folders 32 contained in "NORTH AMERICA". The selection of "CANADA" in FIG. 4B results in the display of FIG. 4C which is a list of child file folders 34 contained in "CANADA". The selection of "ONTARIO" in FIG. 4C results in the display of FIG. 4D which is a list of child file folders 36 contained in "ONTARIO". The selection of "CENTRAL ONTARIO" in FIG. 4D results in the display of FIG. 4E which is a list of child file folders 38 contained in "CENTRAL ONTARIO". The selection of "TORONTO" in FIG. 4E results in the display of previously described FIG. 3 which includes a list of files contained in "TORONTO". In each case, upon selection of a file folder in the list of contents previously displayed, the selected file folder is added to the display of the direct containment hierarchy, (or alternatively the direct containment hierarchy is redrawn to include the selected file folder) and the contents of the newly selected child file folder are displayed in place of the list of contents previously displayed for the previously selected file folder.



In a preferred embodiment, as in the illustrated examples, the direct containment hierarchy is displayed on a first window 40, and the list of contents is displayed in a second window 42. The two windows 40,42 are preferably displayed adjacent to each other, or with the second window partially overlapping the first. The display of the second window 42 has an arrow 44 pointing to the file folder in the direct containment hierarchy whose contents are listed in the list of contents 22.



In a preferred embodiment, the arrow 44 can be dragged or otherwise controlled with a user input device, for example a mouse, such that it points to any level in the displayed direct containment hierarchy 20. When such is done, the second window 42 moves up with the arrow 44, and the list of contents 22 is updated to show the contents of the file folder pointed to by the arrow at a given time. For example, in FIG. 7 after navigating down to the "TORONTO" file folder arrow 44 has been dragged up to point at "CANADA". The remainder of the direct containment hierarchy 20 below "CANADA" is still displayed. Should a user select one of the file folders in the list of contents 32, then the direct containment hierarchy 20 would be updated by adding this new entry below "CANADA", and by deleting the remainder of the direct containment hierarchy from the display. While an arrow 44 is shown as the mechanism for jumping up to a previously selected level in the direct containment hierarchy, it is to be understood that other mechanisms for achieving this may alternatively be employed. For example, by clicking within the direct containment hierarchy 20 with a mouse on the level of interest, by dragging the entire window 42, or any other suitable mechanism.



Preferably, upon temporary indication of a direct containment group in the direct containment hierarchy, for example by mousing over the direct containment group or by using the above described arrow mechanism, the contents of the temporarily selected containment group are temporarily displayed without updating the direct containment hierarchy. Upon actual selection of a direct containment group in the direct containment hierarchy, for example by double clicking on the direct containment group, the contents of the selected containment group are displayed and the direct containment hierarchy is updated such that the selected direct containment group is now the lowest-level containment group.



A search window 46 may be provided which allows a user to enter a textual search criterion. The system in response to such an entry performs a search of the file names in the currently displayed list of contents and displays any matching results. Any searching technique may be employed to this end including any one of many existing well known techniques.



Preferably, a pictorial representation of the contents of the selected file folder is provided. Referring again to FIG. 3, in this example, a pictorial representation 48 consisting of a map corresponding to the name of the selected file folder is provided as part of the second window 42. Thus, in FIG. 4A, a map 50 of the world is shown. In FIG. 4B, a map 52 of North America is shown. In FIG. 4C, a map 54 of Canada is shown. In FIG. 4D, a map 56 of Ontario is shown. In FIG. 4E, a map 58 of Central Ontario is shown, and in FIG. 3, a map 48 of Toronto is shown. This is particularly appropriate for the example at hand in which all of the file folders have names which have geographical connotations. However, it may also be suitable to perform such pictorial representations for other containment hierarchies. Preferably, the pictorial representation is done in a manner which allows the selection of a file or file folder from the list of contents by clicking on the pictorial representation. For example, Canada is displayed in FIG. 4C, and a user knowing where Ontario is could click directly on Ontario to select the file folder "ONTARIO". Preferably, it is user selectable to hide the pictorial representation and/or to hide the list of contents. In the illustrated example of FIG. 3, a "hide map" screen switch 47 is provided which when selected redraws the display without the map and shows a screen switch "show map" in place of the "hide map" screen switch. Similarly, a "hide list" screen switch 49 may be provided.



In a preferred embodiment, when a pictorial representation of the selected file folder is displayed as part of the second window, different pictorial elements in the pictorial representation will represent the list of contents 32. For example, in FIG. 8, the list of contents consists of a list of provinces, and the pictorial representation 48 is a map of Canada illustrating the different provinces. Preferably, by "mousing over" the pictorial representation, i.e. by moving a mouse over the pictorial representation but not clicking on anything, the name of the element currently being displayed is brought to the top of the list of contents 34. In the example of FIG. 8, as indicated by mouse pointer 100 a user has moused over the pictorial element for Quebec, namely the portion of the map of Canada 48 representing Quebec, with the result that Quebec has been brought to the top of the list of contents 34. Preferably, when a particular pictorial element has been moused over, a halo or other highlighting effect is added to the display to make it clear to a user which pictorial element is being moused over at a given time. Preferably, the listing which is brought to the top of the list of contents 34 is highlighted or otherwise distinguished from the remainder of the list.



In a preferred embodiment, the invention provides for a choice between different hierarchies for the same set of entities. For example, in a hierarchy of file folders and files, the only real physical entities are the files, while the file folders are just logical groupings. While these logical groupings may make sense for one user, they may not make sense for another user. According to the invention, a method is provided which permits a user to select between different containment hierarchies. For this embodiment, collectively somewhere in either the computer system, software, or storage devices, the various different hierarchies must be stored. Preferably, a screen switch is provided on the display which allows a user to switch between the different available containment hierarchies. Preferably, an option exists to switch between the display of different hierarchies for a given file entity. In the illustrated embodiment of FIG. 3, an area 80 of the display contains two screen switches 82,84 which are individually selectable with a mouse for example. Screen switch 82 selects that a "Region" containment hierarchy be used in displaying the direct containment hierarchy, and this has been selected for the examples. Screen switch 84 selects that a "Type" containment hierarchy be used in displaying the direct containment hierarchy.



In a preferred embodiment, the list of contents is displayed scrollably. An example of this is shown in FIG. 5 which is a version of FIG. 4E which illustrates a list of contents 38 displayed with scroll bars 60. Other methods of providing scrollability can be provided, such as configuring the arrow keys to move up and down through the list of contents for example.



In another preferred embodiment, the list of contents is displayed in a manner which distinguishes between various types of contents, for example to distinguish between file folders and files. An example of this is shown in FIG. 6 which is a version of FIG. 4E. The file folders in the list of contents 38 of FIG. 4E are indicated as such by including a small pictorial file folder 70 beside them. Any suitable icons or indicators could be used to identify other types of entities.



The above described embodiments have focused mainly on a method in a computer system for displaying a selected file folder. In addition, an embodiment of the invention also provides for a software program containing software which when run will implement one or more of the above discussed methods, stored on a computer readable medium. Another embodiment of the invention provides a computer system per se adapted to implement one or more of the above discussed methods. Furthermore, in another embodiment, a graphical user interface is provided which has been adapted to implement one or more of the above discussed methods. Furthermore, in another embodiment, an operating system is provided which has been adapted to implement one or more of the above discussed methods, the operating system preferably being a Windows-based operating system.



The above described embodiments have focussed on file folders and files. More generally the invention can be applied to any containment hierarchy having any type of containment groups and any type of containment entity. In this case, an embodiment of the invention displays a direct containment hierarchy of containment groups and a list of contents for the lowest-level containment group. For example, a containment hierarchy could be used to represent components in a network. In this case, each containment group would identify some type of grouping of other containment groups or of network elements per se. Other examples include way-finding tools, telephone directories and Internet site navigators to name a few.



Where the illustrated examples have featured the use of two windows, it is to be understood that more generally two areas of any suitable definition may be used.



Numerous modifications and variations of the present invention are possible in light of the above teachings. It is therefore to be understood that within the scope of the appended claims, the invention may be practised otherwise than as specifically described herein.

PatentNumber=7092934,FIELD OF THE INVENTION



The present invention relates to searching, and more particularly to methods and apparatus for scheduling and performing a search to associate information with an object in a file.



BACKGROUND OF THE INVENTION



With the proliferation of the Internet, a wide variety of search engines and search tools for locating information have become available. Typically, a user accesses a web page containing a search form from a search engine, inputs search terms into the form, and clicks on an icon labeled "search" or "start" for example, to transmit the search terms back to the search engine. The search engine then searches one or more databases for information containing the search terms, and accesses to the user one or more web pages containing the search results, typically represented by hyperlinks containing universal resource locators (URLs) identifying locations or addresses on the Internet where the information identified by the search engine may be found.



Disadvantageously, each time a user wishes to update a search he or she has previously performed, the user must usually return to the search engine's web page, complete the search form by inputting the same search terms as the previous search, then sift through the search results. Often, the user will have already seen most of the search results during the previous search. Accordingly, such updating is often a tedious and time-consuming process involving redundant effort, as the user has to repeatedly fill out the same search form and sift through the same results.



One recent search engine improvement involves a utility residing in a Windows system tray of a user's computer, which allows a user to manually initiate a search by pressing the Alt key then clicking on a word in an electronic document. The utility transmits the selected word over the Internet to a particular search engine, which then searches its databases for occurrences of the word. However, the search must still be manually initiated, and no apparent provision is made to eliminate redundant or old information that may have been previously retrieved. In addition, the user is required to first download and install the utility, which may not be feasible or permitted at a remote location such as a public access Internet kiosk, for example.



At the same time, electronic calendars such as desktop-based or web-based calendars are increasing in popularity. Many people, particularly business travelers, find it convenient to store a list of all of their scheduled meetings, appointments and tasks on a web-based calendar, to allow them to access this information from any computer terminal anywhere in the world which is connected to the Internet. Many such users would find it desirable to obtain up-to-date information about a person or company immediately prior to meeting with that person or company. However, meetings are often scheduled a week or more in advance, and accordingly, if a user performs a search at the time of scheduling, the search results may be out of date by the time the scheduled date of the meeting arrives. The user may intend to manually perform such a search shortly before the meeting, however, the user may be too hurried to interact with a search engine on the morning of a meeting, or may forget to do so.



Accordingly, there is a need for way to pre-schedule searches to be automatically conducted at a pre-scheduled time, such as several hours before a scheduled meeting, for example, and to conveniently provide the results of the search to a user.



SUMMARY OF THE INVENTION



The present invention addresses the above need by providing a method and apparatus for associating information with an object in a file. The method and apparatus cooperate to associate a search key with the object in the file and to schedule a search for information using the search key for further execution by a searching mechanism operable to execute scheduled searches.



For example, where the file is an electronic calendar and the object is the name of a person or other entity in a calendar entry, with whom a user of the calendar is scheduled to meet, the user may associate a search key designed to locate up-to-date information about that entity with the calendar entry. The user may design the search key so as to exclude information older than a certain date, or to otherwise refine the search. The user may schedule a search for information relating to the entity to be conducted at a pre-scheduled time prior to the meeting, such as three or four hours beforehand, for example. The search results may then be incorporated directly into the electronic calendar, so that when the user consults the calendar, the calendar contains hyperlinks to information relating to the entity, such as a recent news story relating to the entity, for example. The user may then simply click on a hyperlink in the user's calendar to access such information.



Additionally, if desired, the user may schedule recurring searches. For example, to obtain information on a topic relevant to monthly planning meetings, the user may schedule a recurring search to occur shortly before each meeting, and if desired, may combine such recurring searching with search refinements to exclude information more than a month old, for example.



More broadly, embodiments of the invention provide for such scheduled searching for information related to any object in any file, not merely an entity in a calendar entry of a calendar. Embodiments of the invention may be implemented in a variety of physical structures, such as a desktop computer, or may be entirely implemented in a web server such as a web-based calendar server, for example.



Associating a search key with the object may involve tagging the object and the object may be a string of text in a hypertext mark-up language (HTML) document, for example.



Scheduling the search may involve storing the search key in association with a time of execution at which the search is to be executed and in association with a tag identifying the object.



A method and apparatus according to another aspect of the invention involve initiating a pre-scheduled search for the information at a pre-scheduled time using the search key associated with the object and associating with the object a result of the search.



Initiating the search may involve invoking a search engine, which may involve addressing a universal resource locator (URL) associated with the pre-scheduled search. A program, subroutine, or scripts for example, may be run to populate search engine fields of the search engine to identify search parameters. A results URL produced by the search engine may be received by the apparatus and stored in association with the pre-scheduled search. A hyperlink may be associated with the object, the hyperlink pointing to the results URL to enable a user to quickly access information associated with the object.



In one embodiment, a table is produced, the table associating an object tag, the search key, the pre-scheduled time, the URL associated with the pre-scheduled search and the results URL with each other to identify the search.



The above methods may be executed by a processor circuit running under the direction of program codes which may be received from a computer readable medium such as a hard drive or a compact disc, for example, or which may be received as programmed code segments in a signal embodied in a carrier wave received through a wireless modem, or from the internet, for example.



Other aspects and features of the present invention will become apparent to those ordinarily skilled in the art upon review of the following description of specific embodiments of the invention in conjunction with the accompanying figures.



BRIEF DESCRIPTION OF THE DRAWINGS



In drawings which illustrate embodiments of the invention,



FIG. 1 is a block diagram of a system in which an apparatus for associating information with an object in a file according to a first embodiment of the invention is employed;



FIG. 2 is a schematic representation of a calendar user profile used and modified by the apparatus shown in FIG. 1;



FIG. 3 is a pictorial representation of a display produced on a monitor of the apparatus shown in FIG. 1;



FIG. 4 is a flow chart of a search scheduler routine executed by a processor of the apparatus shown in FIG. 1;



FIG. 5 is a tabular representation of a search table stored in memory of the apparatus; and



FIG. 6 is a flowchart of a search executor routine executed by the processor of the apparatus shown in FIG. 1.



DETAILED DESCRIPTION



Referring to FIG. 1, an apparatus for associating information with an object in a file according to a first embodiment of the invention is shown generally at 10. The apparatus includes a processor 12 and a memory 14 in which is stored an applet 16 including a first code segment 18 for directing the processor 12 to function as a search scheduler. The search scheduler includes an association component 20 for associating a search key with an object stored in a file 22 stored in a file memory 24 accessible by the processor 12. In addition, the search scheduler 18 has a scheduling component operable to schedule a search for information using the search key for automatic future execution of the search by a search executor implemented by a second code segment 26 running on the processor 12, to initiate scheduled searches.



In this embodiment, the applet 16 is run in connection with a browser 28 which directs the processor 12 to establish communications through a communications interface 30 and an internet 34 to a server 36. In this embodiment, the communications interface 30 includes a cable modem or other local area network in direct communication with the public Internet. Alternatively, the communications interface may include a modem in communication with the server 36 and the Internet 34 via the public switched telephone network 32. Alternatively, the communications interface may include a modem operable to communicate with the server 36 through a wireless network 33.



In this embodiment, the server 36 hosts a calendar application, which provides calendar functions to a user of the apparatus 10. Effectively, the calendar server 36 provides to the apparatus 10, a calendar user profile 38 best shown in FIG. 2.



Referring to FIGS. 1, 2 and 3, the calendar user profile 38 provided by the calendar server 36 shown in FIG. 1 includes a calendar format template 40 and calendar information 42 which is used to populate the calendar format template, with which the browser 28 shown in FIG. 1 interacts to produce a calendar display such as that shown at 44 in FIG. 3, on a monitor 46 controlled by the processor 12 in FIG. 1.



In this embodiment the calendar format template 40 and the calendar information 42 present to the browser 28 shown in FIG. 1 a hypertext markup language (HTML) file including various objects such as textual strings, graphics or other components for causing the browser 28 to direct the processor 12 to produce the calendar display 44 shown in FIG. 3. The string "Bell Atlantic" shown at 48 in FIG. 3 is an example of such an object in a file. The calendar server 36 further cooperates with the processor 12 to store a copy of this HTML file as the file 22 in the file memory 24 shown in FIG. 1.



Referring to FIGS. 1 and 3, effectively the association component 20 associates a search key with the object in the file, in this case the string "Bell Atlantic" 48, and the search scheduler 18 schedules a search for information using the search key for automatic future execution by the search executor 26.



The particular way in the particular search key is associated with the object is explained with reference to FIG. 4 which shows a flowchart of the search scheduler.



Referring to FIGS. 3 and 4, in this embodiment, a user of the file 22 may initiate the search scheduler 18 shown in FIG. 4, by highlighting or selecting the object 48, in this case the string "Bell Atlantic", within the calendar display 44, and then executing a hot key sequence on a user input device 50 shown in FIG. 1 to cause the processor 12 to invoke the search scheduler 18. In this embodiment, the search scheduler tags the object 48 with an icon or object tag 52 which is inserted in the HTML file to cause it to visually appear adjacent the object 48.



Referring to FIG. 4, block 54 of the search scheduler 18 then directs the browser 28 and processor 12 to display on the monitor 46 a dialog box as shown at 56 in FIG. 4. In this embodiment, the dialog box includes a search key field 58, a scheduled time field 60 and a search refinement field 62. A user of the device can then populate these fields 58 62 by actuating the user input device 50 shown in FIG. 1. It will be appreciated that the user input device may include a keyboard to enable the user to enter search strings, times and dates at which the search is to be performed and further search refinements. For example, the user may refine the search by adding to the refinement field 62 further text strings which must be found in either conjunction or disjunction with the contents of the search key field 58. Additionally, if permitted on the selected search engine, the user may refine the search by entering into the refinement field 62 a date restriction, for example, to exclude any search results dating more than a month before the calendar entry with which the object is associated, in order to obtain only the most recent information relating to the object.



Alternatively, the user may specify a template which extracts particular strings from the information provided by the calendar application for use in refining the search, for example.



Referring to FIGS. 4 and 5, block 64 then directs the browser 28 and processor 12 shown in FIG. 1 to store an identification of the object, the contents of the search key field, the contents of the scheduled time field and the contents of the search refinement field in corresponding fields 66, 68, 70 and 72 of a search record 74 in a search table 76 shown in FIG. 5. Referring to FIG. 2, the search table 76 is appended or otherwise associated with the calendar user profile produced by the calendar server 36 shown in FIG. 1.



Referring to FIG. 5, the search record 74 also includes a search URL field 78 and a results URL field 80. The search URL field is used to hold a universal resource locator identifying a search engine to be used to conduct the search. In this embodiment, the search URL field 78 is always populated with the same value, for example, a universal resource locator identifying the LYCOS (tm) search engine. It will be appreciated, however, that the dialog box shown in FIG. 4 may further include a field as shown in broken outline at 82, allowing the user to specify a particular search engine which is to be used to carry out the search. The user may enter the word GURU (tm) into the field 82 to identify the gurunet search engine, for example, which provides a reduced volume of search results, and a lookup table (not shown) may be used to specify the URL to be used to populate the corresponding search URL field 78 of the associated search record 74. Alternatively, a field of the dialog box may include a pull-down menu allowing a user to select one or more search engines from a list.



Referring back to FIG. 4, once the search tables have been populated, the search scheduler is completed.



Referring to FIGS. 1 and 6, the search executor 26 is run by the processor 12 as a background task and includes a first block 90 which directs the processor to scan the search table 76 shown in FIG. 5 to determine whether or not any of the search records 74 in the search table 76 has a scheduled time field 70 identifying a time prior to or equal to a time presently indicated by a clock 92 readable by the processor 12, and if so, whether the results URL field 80 of such a record is empty, indicating that the scheduled search has not yet been conducted. Upon finding such a search record 74, block 94 of the search executor directs the processor to obtain a search URL from the search URL field 78 of the search record 74 and to present the search URL to the browser 28. The browser then uses the contents of the search URL field 78 as a browser location address to cause the browser to establish communications with a search server 96 which in this embodiment is exemplified as LYCOS (tm). The search server 96 presents back to the browser 28 the usual template of search engine fields which a user would normally complete, to specify the parameters of the search, however, block 98 of the search executor directs the processor 12 to run a program, routine, or scripts 100, for example, associated with the applet 16 to populate the search engine fields with the contents of the search key field 58 and the search refinements field 62 of the search record 74 shown in FIG. 5. Also, the program, routine or scripts cause the search to be launched at the search server 96.



The search server 96 performs its search and provides back to the processor and browser, at least one results URL which identifies a location at which the search results may be obtained. Block 102 of the search executor directs the processor 12 to receive the results URL or URLs and block 104 directs the processor to store any such URLs in the results URL field 80 of the search record 74. Thus, the results URL is stored in association with the object tag identified in the object tag field 66 which is associated with the object, hence the results URL is stored in association with the object.



In this embodiment, the results URL includes a URL pointing to a "search results" web-page such as that produced by many search engines, the search results page in turn including a plurality of hyperlinks containing URLs identifying IP addresses of other web sites where information relevant to the search is located. Alternatively, however, a results URL may directly identify an IP address where relevant information is stored, rather than identifying an intermediate IP address where further URLs pointing to the information are stored. If the selected search engine is not capable of providing such a "direct" results URL, block 102 may be further modified to direct the processor to access a search results web-page identified by the supplied URL, and to copy the first five or ten URLs listed therein, for example, into the results URL field 80 of the search table 76.



Block 106 then directs the processor to convert the object tag 52 shown in FIG. 3 into a hyperlink pointing to the URL specified by the contents of the results URL field 80 in the associated search record 74 shown in FIG. 5. Block 106 further directs the processor to modify the HTML file 22 stored in the file memory 24 shown in FIG. 1 by inserting this hyperlink into the file, so that the hyperlinked object tag 52 will be displayed in the user's calendar display 44.



Consequently, referring to FIG. 3, when a user clicks on the object tag 52, a separate frame 108 is produced, and in the separate frame, any information stored at the URL specified by the results URL is displayed. Alternatively, where a plurality of "direct" results URLs are stored in the results URL field 80, block 106 may direct the processor to insert a plurality of respective object tags 52 into the file, each such object tag hyperlinked to a respective results URL. Or, as a further alternative, block 106 may convert the object tag 52 into an embedded menu of hyperlinks to respective results URLs, so that when the user hovers a mouse over the displayed object tag, a small pop-up menu displaying the respective results URLs appears.



Similarly, it will be appreciated that if more than one search URL is stored in the search URL field 78 of the search record 74 shown in FIG. 5, blocks 94, 98, 102, 104 and 106 may be repeated for each such search URL to execute a plurality of searches on respective search engines, and to insert one or more respective object tags 52 hyperlinked to respective results URLs.



While the above embodiment has been described in connection with the use of an HTML file initially prepared by a calendar application, it will be appreciated that the present invention may be used in connection with any file having objects with which resource locators may be associated in order to direct a user to a resource for further information. The resource may be local, such as in memory accessible directly by the processor 12 or accessible by the processor through a network connection, wireless connection, the public switched telephone network or in general any database of information which can be placed in communication with the processor 12.



The ability to schedule the date and time of execution of the search, as indicated in FIG. 4 at the date and time field 60 permits a user to specify that the search is to be performed just before an event, such as a meeting, for example, to provide the user with the latest available information just before going into the meeting, for example. Thus, the present embodiment provides a way of allowing users be automatically kept up to date in respect of matters they specify. To complement this feature, the user may further select search engines which permit searching by date range and may use the search refinements field 62 of the dialog box 56 shown in FIG. 4, to enter appropriate date restrictions into the refinements field 72 shown in FIG. 5, to exclude information dated more than a week or a month ago, for example, to obtain only the most recent "news" relating to the object. More generally, the contents of the refinements field 72 may be used to further refine a search as necessary to focus the search on particular aspects important to the user.



Also, it will be appreciated that the search table shown at 76 in FIG. 5 may include a plurality of search records 74 and that more than one record may be associated with the same object tag to cause searching, for example, to be done at more than one time, for the same information.



It will further be appreciated that the search executor may be extended to include a further block of codes 110 shown in broken outline in FIG. 6, which directs the processor 12 shown in FIG. 1 to reschedule a search by producing a new search record 74 having a different, later time value entered into the scheduled time field 70 to automatically cause a new search to be re-executed at a later time. In this manner, the user can be kept up to date so that whenever the user clicks on the icon or object tag 52 shown in FIG. 3, the information obtained from the last performed search is made available to the user. This feature may be particularly useful for scheduling recurring searches for information relevant to recurring monthly or weekly meetings, for example.



Although the embodiment described above involved storage of the file and user profile information locally at a user's computer, it will be appreciated that the precise location of such information, or of the location from which the search is initiated, is not important. For example, the present invention may alternatively be implemented in an entirely web-based manner. A file, such as a calendar file for example, as well as the full user profile information described above in connection with FIGS. 2 and 5, may be stored entirely at the server 36. The user may access his or her calendar on-line by simply entering an identification such as a username and/or password, for example. The user may then modify his calendar and right-click or strike a hot key sequence to cause the server 36 to download and execute an applet on the user's computer, the applet serving merely to allow the user to interact with a dialog box to enter the contents of the search table 76 into a storage medium at the server 36. At the pre-scheduled time, the server 36 will initiate the search as described above, and modify the contents of the user's calendar file by inserting one or more links to the search results into the calendar file. The user may then remotely access the server 36 to view the modified calendar file stored therein and to access the links to the search results. The user may thus pre-schedule a search to be executed entirely by the server 36, which does not require the user's computer to be turned on at the time when the search is to be performed. Such an embodiment is particularly advantageous for business travellers, who may be away from their home or office computers at the times when the search is to be performed and when they will need to access the search results. Such travellers would thus be able to schedule searches and access results from laptops, or even from public access internet terminals or kiosks located at business conference centres, for example.



While specific embodiments of the invention have been described and illustrated, such embodiments should be considered illustrative of the invention only and not as limiting the invention as construed in accordance with the accompanying claims.

PatentNumber=7127526,FIELD OF THE INVENTION



The present invention relates to network device configuration and monitoring, and more particularly, to a method and apparatus for dynamically loading and managing software services on an embedded device.



BACKGROUND OF THE INVENTION



Computer networks continue to proliferate. As they do so, they become increasingly complex and difficult to manage. This problem is exacerbated when a variety of network devices, computers, and software are combined together to integrate large intranets with the Internet.



As shown in FIG. 1, a conventional network 100 includes one or more network devices 102 such as switches, routers, hubs, multiplexers and similar devices capable of processing fixed-length or variable-length packets in a network. Network devices 102 may further communicate with hosts 104 via a local area network, for example. Network manager 106 also communicates with network devices 102 via the network 100.



To manage the network 100, network manager 106 generally polls network devices 102 using protocols such as SNMP to access information in the device's management information base (MIB). The manager 106 thus needs to know all the MIBs supported by each device, which is especially problematic if the network includes devices of various different types or from various different manufacturers. Further, polling requires that the network manager send many messages of the same type to each device and continually over a period of time. This floods the network and can downgrade the network's performance, as well as burdening the network manager 106 with highly repetitive and duplicative tasks.



Moreover, the forwarding and control capabilities of conventional network device 102 are also statically constrained by the routing software and control software pre-loaded on the device 102. Although many conventional devices include means for effecting software updates (for example, by downloading software via FTP), such updates must be carefully performed and monitored for each device in the network, usually manually by the network manager 106. Such updates require much manager intervention, are risky to perform, require de-commissioning the device during updating, and require a period of verification after updating, thus making network management and performance even more problematic. Further, although some updates may only affect certain individual modules, generally the whole code has to be swapped out to install the updated modules, rather than just the updated modules themselves.



SUMMARY OF THE INVENTION



The present invention relates to an apparatus and method for dynamically loading and managing software services on a network device. A service environment ported to the network device includes a service environment kernel and a virtual machine. The service environment kernel continually operates on the network device and manages the downloading of services from a remote location onto the network device. In accordance with a request from a remote client such as a network manager, the service environment kernel causes instructions corresponding to the downloaded service to be provided to the virtual machine for execution on the network device. Associated with the service are service relationships. The service environment kernel manages these relationships by maintaining a registry of services and their dependencies on other services. The service environment kernel also controls the execution of services in accordance with the service relationships so as to guarantee the modular and effective alteration of the behavior of the network device.



In accordance with one aspect of the invention, a method for performing a service on a network device, comprising the steps of installing the service on the network device from another location, the service having a corresponding set of service relationships, checking the service relationships of the loaded service against a stored registry of relationships, and causing the service to be executed on the network device if the service relationships can be resolved.



In accordance with another aspect of the invention, a network device for locally performing a service, comprises means for installing the service on the network device from another location, the service having a corresponding set of service relationships, means for checking the service relationships of the loaded service against a stored registry of relationships, and means for causing the service to be executed on the network device if the service relationships can be resolved.



In accordance with another aspect of the invention, a network device for locally performing a service, comprises a network interface adapted to install the service on the network device from another location, the service having a corresponding set of service relationships, a registry of service relationships, a service manager coupled to the network interface and the registry that is adapted to check the service relationships of the loaded service against the registry, and a service launcher coupled to the service manager that is adapted to cause the service to be executed on the network device if the service relationships can be resolved.



BRIEF DESCRIPTION OF THE DRAWINGS



The foregoing and other features, aspects, and advantages of the present invention will become more apparent from the following detailed description when read in conjunction with the following drawings, wherein:



FIG. 1 is a block diagram illustrating how network devices are managed in a conventional network;



FIG. 2 is a block diagram illustrating how network devices are managed in a network in accordance with an embodiment of the present invention;



FIG. 3 is a structural block diagram illustrating an example of a network device in accordance with an embodiment of the present invention;



FIG. 4 is a functional block diagram illustrating an example of a service environment in a network device such as that illustrated in FIG. 3 in accordance with an embodiment of the present invention;



FIG. 5 is a functional block diagram illustrating an example of a service environment kernel that can be included in a service environment such as that illustrated in FIG. 4 in accordance with an embodiment of the present invention;



FIG. 6 is a flowchart illustrating an example of a method for locally performing a service on a network device in accordance with an embodiment of the present invention; and



FIG. 7 is a block diagram illustrating an example of a network device in accordance with an embodiment of the present invention.



DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS



The present invention will now be described in detail with reference to the accompanying drawings, which are provided as illustrative examples of preferred embodiments of the present invention. Notably, the implementation of certain elements of the present invention may be accomplished using software, hardware or any combination thereof, as would be apparent to those of ordinary skill in the art, and the figures and examples below are not meant to limit the scope of the present invention. Moreover, where certain elements of the present invention can be partially or fully implemented using known components, only those portions of such known components that are necessary for an understanding of the present invention will be described, and detailed descriptions of other portions of such known components will be omitted so as not to obscure the invention. Further, the present invention encompasses present and future known equivalents to the known components referred to herein by way of illustration.



FIG. 2 illustrates an example of a network 200 configured in accordance with an embodiment of the present invention.



As shown in FIG. 2, network devices 202 communicate with an application server 204 and network manager 206. As in the conventional network 100, network devices 202 may further communicate with hosts 104 via a local area network, for example.



Generally, the present invention allows for the downloading of services from application server 204 that can be dynamically executed on network devices 202, either automatically or under the direction of manager 206. Such services enhance the functionality of conventional network devices 102 and can include traffic monitoring and performance guarantees (e.g. QOS, uniform latency), intrusion detection, active networking, accounting and billing, closed-loop feedback, error detection, diagnosis, and remediation. Such services can further alter the functionality in the network device to make it available for use in ways previously unavailable, such as turning a router into a load balancing switch, turning a network database into a web server, and adding proxy, load balancing, caching, better security (e.g. VPN), bandwidth allocation, VoIP and unified communications support to ordinary network devices. It should be apparent that even further capabilities and applications of the present invention are possible, such as mobile agents, e-market supply chains and distributed processing applications.



Although only one application server 204 and network manager 206 are shown, it should be noted that there can be several of each, or the server 204 functionality can be provided together with another network component or combined with the functionality of manager 306, or perhaps not included in the same network. Alternatively, a server 204 may actually be another network device 202 that has been enhanced with server capabilities with dynamic services in accordance with the present invention. Many other alternatives are possible, and such should become apparent after those skilled in the art are taught by the present disclosure.



An advantage of the network 202 configured in accordance with the invention is that network management services can be performed on the network devices themselves, thus freeing the network manager 206 of duplicative and repetitive tasks, and reducing the number of network management messages that may need to be communicated across the network. For example, a network management service downloaded to a network device 202 may cause the network device 202 to periodically report on a device variable relating to network traffic. Thus, instead of network manager 206 having to periodically send a report request message to each device 202, network manager 206 simply once causes the service to be executed on the network devices of interest, and then receives all the responses at the desired periods. Many other alternative network management services and advantages are possible and should become apparent to those skilled in the art after being taught by the present disclosure.



FIG. 3 further is a structural block diagram illustrating an example of a network device 202 in accordance with an embodiment of the present invention.



As shown, network device 202 includes a CPU 302, switch fabric 304, storage 308, network port 310 and memory 312 all communicating via a bus 314. Switch fabric 304 further communicates with switch ports 306, which ports are capable of communicating packets with a network using network protocols such as TCP/IP and Novell Netware, for example. Storage 308 can comprise memory for storing program and device data and can comprise a variety of storage media such as RAM, ROM, flash memory, and magnetic or optical storage media. Network port 310 can provide a loopback address for access by services and other network management applications. During operation of network device 302, memory 312 includes code for execution by CPU 310 such as an operating system 316, device code 318, APIs 320, service environment 322 and services 324. This example network device architecture is intended to be illustrative rather than limiting, and it should be apparent that additional or fewer components can be included in a network device while remaining within the spirit of the present invention.



In accordance with the present invention, service environment 322 provides an execution platform through which services 324 are performed using CPU 302. Service environment 322 also facilitates the downloading from application server 204 and installation onto device 202 of services 324 and manages their execution on CPU 302. Network manager 206 can communicate with device 202 to request device 202 to execute one or more of the services 324.



It should be noted that components corresponding to CPU 302, switch fabric 304, switch ports 306, storage 308, network port 310, memory 312 (including operating system 316, device code 318 and possibly some of APIs 318) and bus 314 may also be provided in a conventional network device 102, or are otherwise well understood by those skilled in the art. Accordingly, such elements will not be described here in detail so as not to obscure the invention. Moreover, as should be further apparent from FIG. 3, adapting a conventional network device 102 in accordance with the invention may merely require updating memory 312 to include executable software having functionality corresponding to the services 324 and service environment 322 of the invention (possibly as well as some of APIs 504) as will be described in more detail below.



It should be further noted that, although an implementation of the present invention in network devices 202 including a switch fabric (e.g., switches, routers and hubs) is considered particularly advantageous, other implementations of the present invention are possible. Generally, a network device 202 in accordance with the invention can be considered as any device stationed on the network having an embedded processor. Accordingly, such devices may further include database servers, video servers, wireless access points, firewalls, load balancing switches for a farm of routers, access routers, etc. A useful application includes the provision of the functionalities of the present invention in network devices 202 that are located at "impedance mismatch" points in the network where network management is a special concern and where frequent, short-lived adjustment to the behavior of the device is desired.



FIG. 4 illustrates an example of a service environment 322 in accordance with an embodiment of the present invention.



As shown in FIG. 4, service environment 322 includes a service environment kernel 402, a Virtual Machine (VM) 404 and device API extensions 406. Service environment kernel 402 will be described in more detail below. Although the implementation of VM 404 and device API extensions 406 depends on the capabilities and functionalities of device 202, it is intended that they commonly provide a platform-independent interface so that code comprising service environment kernel 402 and services 324 can execute on any device 202. In one example of the invention, VM 404 includes a Java Virtual Machine (JVM) and the Java foundation classes. The Java Virtual Machine is one type of virtual machine that provides for platform independent computing using the Java programming language. Those skilled in the art will understand how to implement JVM 404 depending on the network device CPU 302, operating system 316 and device-level code 318, because JVMs are, by their nature, intended to be portable to different executing platforms.



It should be further noted that device API extensions 406 may or may not be necessary depending on the existing APIs of the device and the types of services 324 that are desired to be executed on the device. For example, where the device 202 includes a standard MIB interface, and a downloaded service 324 includes functionality for getting and reporting on MIB variables, a device API extension 406 may be provided on the device for interoperating with the device code 318 that implements the MIB interface and for providing a standard programming interface for programs written in the language of service 324. Device API extensions 406 are shown here so that those skilled in the art will understand how to practice the invention, though illustrations and details of particular API extensions are not necessary to understand the invention.



In operation, the service environment kernel 402 and VM 404 are preferably launched as part of the device's boot image. One or more services 324 may be launched automatically by service environment 322, or certain services 324 may be launched only upon request from a network manager. Apart from the functionalities illustrated in FIG. 4, service environment 322 may include some device-specific code that enables the service environment to be executed as a task under the device's existing operating system and to launch the VM and service environment kernel. In such an example, service environment 322 can comprise a single executable with linked modules 402, 404 and 406, along with some housekeeping code.



As should be apparent from the above, in the example of the invention wherein VM 404 includes a Java Virtual Machine, services 406 are written in the Java programming language. However, the invention is not limited to this example and those skilled in the art will understand how to implement the invention using other programming languages. Generally, service environment kernel 402 receives service module code in object form and presents it to the VM for incorporation into the runtime environment of the device. In the Java programming example, service environment kernel 402 receives Java byte codes from services 324 and provides them to run on the Java VM 404.



As further shown in FIG. 4, service environment kernel 322 interoperates with services 324, which may further interoperate with each other. As shown, a service module 408 may include one or more of services 324. The service environment 322 preferably provides a registry so that services can locate one another. When a service is started it is added to a registry, and when it is stopped it is removed from the registry. When a service uses another service, a dependency exists between the service module and the other service. The service environment 322 manages these dependencies and ensures that they are satisfied. If dependencies cannot be satisfied, the dependent service cannot be started. If a running service depends on a service that is stopped, the dependent service must also be stopped.



The following describes an example implementation of services 324 in accordance with this example of the invention using the Java programming language.



In one example of the invention, services 324 are grouped in one or more service modules 408 which are packaged in Java Archive (JAR) files. The JAR file contains the classes that implement the services 324 and any auxiliary resources that they require, such as data files and images. The JAR file can also contain subsidiary JAR files to help organize these resources. The JAR manifest contains signature information that is used to authenticate the JAR and verify its integrity as part of the service environment's security mechanism. Additional service environment-specific information is placed in the JAR manifest to represent meta-data such as the dependencies the JAR has, and declarations for the services that it provides.



Once the services are packaged, the JAR file corresponding to service module 408 can be downloaded across the network from a server such as server 204 to the network device 202 hosting the service environment.



A service module in accordance with the invention is declared by providing a service module header in the manifest. This header gives the fully qualified name of a class in the JAR file that implements a standard interface. The service environment 322 can use this class to discover dependencies the service module has on other services, manage the lifecycle of the service module, discover any auxiliary resources and check version information.



Below is an example of the manifest headers for a simple service module based on the standard interface: Module: mypackage.MyModule Services: mypackage.MyService(implemtationID) Dependencies: otherpackage.OtherService



This declares that the service module contains the standard interface class with the fully qualified name mypackage.MyModule which provides a service with the fully qualified name mypackage.MyService. In addition, this service module uses facilities from the otherpackage.OtherService service provided by another service module. This means that this service module has a dependency on otherpackage.OtherService.



Below is an example of a standard interface in accordance with an embodiment of the present invention.



public interface Service



{



/** Performs any service-specific operations when the service is



* installed. This method is called before the service is fully



* resolved. This means that it can make use of any classes and



* resources that are in the service itself, but it must not use any



* of the services from other services that it depends upon. Simply



* declaring a variable with a type provided by another service



* constitutes a use of the service.



*



* @param context the service that is being installed



* @exception ServiceException if the service cannot be installed



*/



void install(ServiceContext context) throws ServiceException;



/** Performs any service-specific operations when the service is



* started. The service's dependencies are resolved before this



* method is called, so it can use classes and services provided



* by services from other services.



*



* @param context the service that is being started



* @exception ServiceException if the service cannot be started



*/



void start(ServiceContext context) throws ServiceException;



/** Performs any service-specific operations when the service is



* stopped. The service's dependencies are resolved before this



* method is called, so it can use classes and services provided



* by services from other services. The service's dependencies are



* set to the unresolved state after this method returns.



*



* @param context the service that is being started



* @exception ServiceException if the service cannot be started



*/



void stop(ServiceContext context) throws ServiceException;



/** Performs any service-specific operations when the service is



* uninstalled. This method is called after the service is stopped



* (if it had been started), and before any of the service's



* resources are removed. The service's dependencies are not



* resolved when this method is called, so it cannot make use of



* classes and services provided by services from other services.



*



* @param context the service being uninstalled



* @exception ServiceException if an error occurs during execution



*/



void uninstall(ServiceContext context) throws ServiceException;



/** Gets an array of all the services that the service is declared



* to depend on. The service environment uses this information to



* resolve dependencies before starting the service.



*



* @param context the service



* @return the services that the service depends upon;



*<code>null</code> if the service doesn't depend on any



*/



ServiceDescription[ ] getRequiredServices(ServiceContext context);



/** Gets an array of all of the JAR files that the service has



* declared a dependency on. These JAR files are added to the



* service's class path. If a specified JAR file cannot be found in



* the service's underlying JAR file, it is is silently ignored.



This method returns <code>null</code> if there are no JAR file



* dependencies. The service environment uses this information to



* resolve dependencies before starting the service.



*



* @param context the service



* @return the names of the JAR files; or <code>null</code> if



* there are no JAR file dependencies



*/



String[ ] getJarFiles(ServiceContext context);



/** Gets information about this service.



*



* @param context the service



ServiceInfo getServiceInfo(ServiceContext context);



/** Gets information about a service provided by this service.



*



* @param context the service



**/



ServiceInfo getServiceInfo(ServiceContext context, ServiceDescription desc);



In one example of the invention, in addition to service-specific code, services 324 include code that declares an interface which extends or implements a standard defined interface class for all services, and provides an object that implements that interface. The service module preferably further includes code which defines how the services are started and stopped (e.g. start and stop methods, which may be part of the standard interface as shown above). After the service is started, it is added to a registry maintained by the service environment, and before it stops it is unregistered. Services can export their functionality to other service modules running on the network device, and they can also make use of services provided by other service modules.



Services are identified with a service description. As shown above, these descriptions (e.g. mypackage.MyService(implementationID)) are comprised of two parts: the fully qualified name of the interface that declares the service (e.g. mypackage.MyService) and a service-specific name that lets a client such as network manager 206 distinguish between multiple implementations of the service (e.g. implementationID). For example, a service module that provides logging services might declare an interface myUtils.MyLogger, and then provide one implementation that writes the log to local persistent storage, and another implementation that transmits the log messages across the network to a server. In this case, the service module provides two different service objects that implement that myUtils.MyLogger interface. These objects would be registered using different service descriptions. Both service descriptions would use the myUtils.MyLogger interface name, but they would have different service-specific names (e.g. myUtils.MyLogger(local) and myUtils.MyLogger(remote)).



There is no requirement that the service module that provides the service interface be the only one that can provide an implementation of it. Two service modules may both register an implementation of a service, each with different service-specific names. For this to be possible, the service module that does not contain the interface definition declares a dependency on that service.



FIG. 5 further illustrates an example of a service environment kernel 402 in accordance with an embodiment of the present invention.



As shown in FIG. 5, service environment kernel 402 includes a service store 502, a service uninstaller 504, a service installer 506, a service launcher 508, a network interface 510, a service manager 512 and a service registry 514. The division of functionalities among these blocks is intended to be illustrative rather than limiting. It should be apparent that these functionalities may be grouped and divided in various alternative implementations while remaining within the spirit of the invention. Moreover, there exist other alternative embodiments that may include more or less functionality than described in this example, and such alternative embodiments are also within the scope of the invention.



Generally, in operation, service manager 512 sends and responds to messages from the network through network interface 510 and coordinates the downloading, management and execution of services via service installer 506, service launcher 508 and service uninstaller 504, in the process managing the contents of service registry 514. In one example of the invention, services 324, service manager 512, network interface 510, service installer 506, service launcher 508 and service uninstaller 504 are implemented using the Java programming language. Accordingly, execution of the functionalities of these elements involves providing instructions to the Java VM 404 and interfacing with API extensions 406, with both the Java VM 404 and extensions 406 being written in the native programming language. In this way, the service environment kernel 402 of the present invention can be made portable to any network device platform to which can be ported a Java VM, thus dramatically enhancing network management capabilities, particularly in networks comprising disparate types of network devices.



In one example of the invention, service environment 322 is a single executable that is launched as a task under the device operating system when the device 202 is booted, including service environment kernel 402, Virtual Machine 404 and Device API extensions 406. The service manager 512 is the main procedure of the service environment kernel 402 and calls the other procedures in the service environment 322, as well as the other modules in the service environment kernel 402. Service manager 512 first executes a start sequence that initializes the set of services operating on the device 202. Network interface 510 and certain of the other modules in kernel 402 can be implemented as part of the initial services included in the initial set. Further, the start sequence may also be a service itself that is located in service store 502 or on another device such as application server 204.



The start sequence may specify a list of the URLs corresponding to other initial service modules that should be installed and started on the device at boot time (including network interface 510 and other modules in kernel 402). Such initial services can further include basic services that can be called by other services such as logging services. The URLs may specify JAR files corresponding to service modules that are located on the device 202, or they may be located on application server 204. For those URLs referring to JAR files on server 204, service manager 512 may interoperate with network interface 510 and service installer 506 to retrieve, download and store the service modules encapsulated in those JAR files.



As service modules are loaded and installed on the device 202, service manager 512 updates the service registry 514. Thereafter, as additional service modules are downloaded, executed or uninstalled, either by operation of service manager 512, or in response to other network elements such as network manager 206, service manager 512 manages the operations of service installer 506, service launcher 508 and service uninstaller 504 to perform such downloading, execution or uninstallation, in accordance with service relationships defined in the service registry 514 that service manager 512 maintains.



In one example of the invention, service store 502 keeps the class and other files corresponding to the service modules 408 accessible to the network device. Alternatively, service store 502 could be implemented as the part of the VM that stores the byte codes corresponding to the service modules resident on the device. In the alternative example, it should be further noted that the class and other files associated with the service modules may be accessed by the VM with a path to a directory structure on application server 204 using a URL and a HTTP server, for example.



Network interface 510 provides functionality for communicating with other network components such as network manager 206 and application server 204 for the downloading and execution of services 324. In one example of the invention, the network interface 510 comprises an HTTP server. Network interface 510 can also comprise a command line interface such as a Telnet interface. Some initial set of commands that can be implemented are: install (allowing a remote device to download and install a service module on the device 202, such as by specifying a URL of a JAR file corresponding to the service module); start (allowing a remote device to launch a service module for execution on device 202); stop (allowing a remote device to stop a service module executing on device 202); uninstall (allowing a remote device to uninstall a service module loaded on device 202); load (allowing a remote device to load and launch a service module on device 202); unload (allowing a remote device to stop and uninstall a service module executing on device 202); modules (allowing a remote to device to view a list of the currently installed service modules on device 202); services (allowing a remote device to view a list of the currently running services on device 202).



Service installer 506 loads the service module JAR file from the location specified (which can be local to the device 202 itself or accessed via a URL on a remote device, for example), and checks to ensure that it has a valid manifest and that it contains a service implementation. Service installer 506 calls the service module's install method to allow it to perform any special processing. The service module's dependencies are not resolved at this time. Specifically, while the service module's dependencies on another service module are unresolved, the service module cannot use any services provided by that other service module. Any attempt to do so will result in a java.lang.NoClassDefFoundError exception. Services provided by the service module are not started yet; however, objects corresponding to each of the class files in the service module are instantiated.



The result of installing a service module is a service module context. A ServiceModuleContext is an object that encapsulates the runtime representation of a service module. Most module management methods require a ServiceModuleContext as one of their arguments.



Once a service module has been installed it can be started by service launcher 508. Service launcher 508 calls the service module's start method to allow the service module to start the services that it provides. Before making this call, the service manager resolves the service module's dependencies. To do this, the service manager checks in service registry 514 that all of the services that the service module depends on (as provided in the service module's manifest) are available. If any of these services are not available, the service module generates a runtime error, which may or may not result in a report back to the requesting client. A service module can also declare a dependency on JAR files that it provides. When the service manager resolves the service module's dependencies. the contents of these JAR files are also available for use by the service module. A service module's main task when it is started is to create, start, and register its services via service manager 514. The service environment places no constraints on the interface between the service module and its services. To ensure that only the service module can create and start and stop the services it is preferable that the service's constructors and the other administration methods have package access, not public access. Once a service has been created and started it can be registered in the service registry. This makes it available for use by other service modules. The service module start method should call the service manager 512 to perform the registration.



Some services will execute to perform a dedicated task and then stop. Alternatively, a service module can also stopped by service launcher, such as by calling the service's stop method. If one of the executing service module's services has been acquired by another service module, and has not been released yet, the service manager generates a runtime exception, and the service module is not stopped. To force a service module to be stopped even if it is still in use, service launcher kills any dependent service modules, then stops this service module. The service module's main tasks when it is stopped are to discard any references to objects from other service modules, release any services that is has acquired, and to unregister any services that it has provided.



Service uninstaller 504 uninstalls a service module by relinquishing any references it has to the service module's objects and enabling the JVM to garbage collect the service module.



Service manager 512 maintains service registry 512 and manages the loading and installation of service modules by service installer 506, the execution of services via service launcher 508, and the removal of service modules by service uninstaller 504.



When a service module uses a service provided by a different service module, it creates a dependency on that service. This means that another service module providing that service must be installed and started before this service module can be started. The service environment 322 tracks which services are currently running, and checks that the dependencies declared by the service module are satisfied when it is started. The service environment also gives each service module its own name space to protect it from inadvertent name clashes. When a dependency is created, the service environment connects the name space of the service module providing the service to the dependent service module. This breaks down the insulation between the two service modules and enables the dependent service module to use classes and methods in the service. When the dependency is removed, access to the names provided in the other service module is also removed.



FIG. 6 illustrates a method of loading and managing a service for execution on a network device in accordance with an embodiment of the present invention.



As shown in FIG. 6, network device 202 (preferably at boot time) launches the service environment 322 (S602). When launched, the service environment 322 executes a start sequence that initializes the set of services operating on the device 202. The start sequence may include a list of the URLs of initial service modules that should be installed and started on the device at boot time. The URLs may specify JAR files corresponding to service modules that are located on the device 202, or they may be located on application server 204. For those URLs referring to JAR files on server 204, service environment 322 downloads the service modules encapsulated in those JAR files onto network device 202 (S604). As service modules are installed and started on the device 202, the service environment updates and maintains a service registry (S606).



When a new service is requested to be executed on the network device (S608), for example by network manager 206, service environment 324 determines whether the service exists on the device or needs to be downloaded. If it needs to be downloaded from a remote location such as server 204 (determined in block S610), the service is downloaded to device 202 (S612). Service environment 324 then determines whether all service relationships defined in the service registry 514 are satisfied for the new service (S614). If not, service environment checks whether the relationships can be resolved, for example by starting services that the new service is dependent upon (S616). If not, the service environment issues an error report (S618). Otherwise, or if service relationships are already satisfied, the new service is executed and the device registry is updated with information corresponding to the new service (S620).



FIG. 7 illustrates an example of a network device 202 that has been adapted for dynamically loading and managing services in accordance with an embodiment of the present invention.



As shown in FIG. 7, network device 700 includes a separated control plane 702 and forwarding plane 704. Generally, packet forwarding between ports of the device is handled in the forwarding plane 704 by switching fabric 712 and switch modules 714 at wire speed, whereas control tasks can be simultaneously handled in the control plane 702 without affecting packet forwarding performance. The control plane 702 may interact with the forwarding plane 704, however, to adjust forwarding rules and retrieve statistics for example.



As further shown in FIG. 7, control plane 702 includes CPU system 710, on top of which executes service environment 322. Service environment 322 facilitates the dynamic loading, management and execution of dynamic services 324 as explained in more detail above. Dynamic services 324 enhance the performance of device 700 above and beyond that of conventional device 102.



In one example of the invention, CPU system 710, switching fabric 712 and switch modules of device 700 can be together implemented in a Nortel Accelar/Passport family of router switches. Such an implementation is preferred due to the separate control plane 702 and forwarding plane 704 of the Nortel Accelar/Passport family. However, it should be apparent that equivalent devices can be used to implement these elements of the present invention. Moreover, it should be understood that the invention is applicable to network devices that do not have a separate control plane and forwarding plane, and even to devices that do not have a packet forwarding architecture at all, and thus is not limited to the device illustrated in FIG. 7. In the Nortel Accelar/Passport implementation, switching fabric 712 and switch modules 714 are comprised of hardware integrated circuits such as ASICs. This allows packets to be forwarded between switch ports at wire speed.



Generally, packets arriving at the ports of the device 700 are processed by forwarding processor 718 of switch modules 714 in accordance with forwarding rules 716. Forwarding processor 718 also maintains statistics and monitors 720 for its associated ports. Normal network traffic is forwarded between ports by switch modules 714 through switching fabric 712. Packets addressed to the device 700 itself (such as ARP and SNMP messages, for example) are forwarded by the switch modules 714 to CPU system 710 via switching fabric 712.



As set forth in more detail above, in accordance with the present invention, service environment 322 provides an execution platform through which services 324 are performed using CPU system 710. Service environment 322 also facilitates the downloading from application server 204 and installation onto device 202 of new services 324' and manages their execution on CPU system 710. As set forth above, network manager 206 can communicate with device 700 to request device 202 to execute one or more of the services 324.



An advantage of the embodiment of the invention illustrated in FIG. 7 is the ability of services to be downloaded and managed without affect wire-speed packet forwarding performance. With the separation of the control and forwarding operations, and the provision of the services environment in the control plane, the CPU processing consumed by service environment 322 that is required to download and manage services can be performed without any impact on the normal packet forwarding operations of the device 700. Moreover, services can be downloaded that can alter the wire-speed packet forwarding operations. For example, a network manager may desire that certain types of packet flows should receive a preferred quality or class of service for a certain period of time (i.e. QOS). The network manager can then download a service 324 to the device 700 which is managed and executed by service environment 322. The downloaded service 324 can interface with APIs that interact with native device control software that causes the forwarding rules 716 in switch modules 714 to be updated in accordance with the desired QOS for the certain packet flows. The packets belonging to the identified certain flows can then be forwarded at wire-speed in accordance with the desired QOS. Many other types of dynamic services, including dynamic services that can leverage the capabilities of the separated control and forwarding plane of the present embodiment are possible.



Although the present invention has been particularly described with reference to the preferred embodiments, it should be readily apparent to those of ordinary skill in the art that changes and modifications in the form and details may be made without departing from the spirit and scope of the invention. It is intended that the appended claims include such changes and modifications.

PatentNumber=7308279,FIELD OF THE INVENTION



The present invention relates to the field of networking. In particular, this invention relates to a technique for minimizing signal interference within a wireless local area network through power level control.



BACKGROUND OF THE INVENTION



The ability of users to access programs and share data over local area networks (referred to as "LANs") has become a necessity for most working environments. To improve efficiency and ease of use, certain enhancements may be added to a LAN such as remote wireless access. By providing wireless access, a wireless LAN (WLAN) is formed.



As described in U.S. Pat. No. 5,987,062 issued to Netwave Technologies, Inc., now owned by Nortel Networks Limited, one type of WLAN employs dedicated stations, which are referred to as access points (APs). Therein, each AP is a relay station that includes a radio frequency (RF) transceiver that receives (and transmits) radio data packets over a communication channel from (and to) mobile units within a predetermined, non-adjustable coverage distance. The level of effective isotropic radiated power used by the RF transceiver determines the coverage distance. An example of this AP is a BAYSTACK.TM. 650 Wireless Access Point produced by Nortel Networks Limited.



Hence, depending on the coverage distance, an AP can share its communication channel with tens or even hundreds of mobile units. This reduces the aggregate amount of data throughput to the mobile units. To improve data throughput, one proposed solution is to implement additional APs within the WLAN. However, this proposed solution may not be applicable, depending on the operating environment.



For example, in order to effectively reuse communication channel frequencies within a WLAN, each additional AP must be placed outside a pollution range associated with its neighboring AP. This "pollution range" is the coverage area determined by both the coverage distance of the AP as well as the coverage distance of any of its mobile units because they communicate on the same communication channel. For a worst case scenario, where the level of effective isotropic radiated power used by the mobile unit is equivalent to the level of effective isotropic radiated power used by the AP, the pollution range is twice the coverage distance, and thus, a maximum of four times the coverage area of the AP. Hence, the additional placement of APs may not be a legitimate solution to data rate throughput problems for a WLAN when there is a high concentration of mobile units within a small area.



SUMMARY OF THE INVENTION



The invention relates to adjustments in the level of effective isotropic radiated power of one or more wireless devices within a wireless network system, such as an access point (AP) and/or a wireless unit (WU) for example. A reduction in the power level reduces the coverage range of a radiated signal. By adjusting the power level, in certain situations, greater aggregate data throughput can be realized by the wireless devices.



Other aspects and features of the present invention will become apparent to those ordinarily skilled in the art upon review of the following description of specific embodiments of the invention in conjunction with the accompanying claims and figures.



BRIEF DESCRIPTION OF THE DRAWINGS



The features and advantages of the present invention will become apparent from the following detailed description of the present invention in which:



FIG. 1 is a first exemplary embodiment of a wireless network system.



FIG. 2 is an exemplary embodiment of an access point (AP) employed in a wireless network system.



FIG. 3 is a second exemplary embodiment of a wireless network system.



FIG. 4 is a third exemplary embodiment of a wireless network system.



FIG. 5 is a first exemplary embodiment of the protocol to manually adjust the coverage distance of a device employed in one of the wireless networks systems described in FIGS. 2-4.



FIG. 6 is a second exemplary embodiment of a protocol to automatically adjust the coverage distance of a device employed in one of the wireless networks systems described in FIGS. 2-4.



FIG. 7 is a third exemplary embodiment of a protocol to dynamically adjust the coverage distance of a device employed in one of the wireless networks systems described in FIGS. 2-4.



FIG. 8 is a fourth exemplary embodiment of a protocol to adjust the coverage distance of an access point (AP) employed in one of the wireless networks systems described in FIGS. 2-4.



DETAILED DESCRIPTION OF THE INVENTION



Herein, the exemplary embodiments of the present invention relate to a technique for minimizing signal interference within a wireless local area network (WLAN), such as by power level control for example. The WLAN may be configured in accordance with Institute of Electrical and Electronics Engineers (IEEE) 802.11 standard. These embodiments are not exclusive; rather, they merely provide a thorough understanding of the present invention. Well-known circuits are not set forth in detail in order to avoid unnecessarily obscuring the present invention.



In the following description, certain terminology is used to describe features of the present invention. For example, "logic" includes hardware and/or software module(s) that perform a certain function on incoming information. A "software module" is executable code such as an operating system, an application or an applet for example. This module may be stored in a storage medium such as a hard disk, memory (non-volatile and/or volatile), CD-ROM, tape, etc. The term "information" is defined as data, address, and/or control. For transmission, the information may be placed in a frame featuring a single data packet or a series of data packets.



In addition, a "link" is broadly defined as one or more information-carrying mediums to establish a communication pathway. Examples of the medium include a physical medium (e.g., electrical wire, optical fiber, cable, bus traces, etc.) or a wireless medium (e.g., air in combination with wireless signaling technology).



Referring to FIG. 1, a first exemplary embodiment of a wireless network system 100 in accordance with the invention is illustrated. The wireless network system 100 comprises a link 101 based on a physical medium. Herein, the link 101 is part of a wired backbone network 102 that includes network resources 104 available for users of the system 100. The wireless network system 100 further includes one or more access points (APs) 106a-106d that communicate via a wireless link with one or more wireless units (WUs) 108a-108f. For this embodiment, four (4) APs 106a-106d communicate with six (6) WUs 108a-108f.



Users using the WUs 108a-108f can access the network resources 104 via any of the APs 106a-106d, which are generally transparent bridges that link a wireless network defined by one or more WUs 108a-108f with the wired backbone network 102. The WUs 108a-108f communicate with the APs 106a-106d typically using a standardized protocol, such as the IEEE 802.11 protocol.



A "wireless unit" (WU) is defined herein as any electronic device comprising processing logic (e.g., a processor, microcontroller, state machine, etc.) and a wireless transceiver for receiving/transmitting information from/to an access point (AP) or another wireless unit (WU). Examples of a WU include a computer (e.g., desktop computer, laptop computer, hand-held computer such as a personal digital assistant "PDA", etc.), communications equipment (e.g., pager, telephone, facsimile machine, etc.), a television set-top box, or appliances such as refrigerator pads, electronic picture frames, alarm detectors, water detectors, and the like. As an option, a WU is loaded with logic to reduce the level of effective isotropic radiated power (hereinafter referred to as "power level") utilized by its wireless transceiver as described below.



An "access point" (AP) is a device that provides a bi-directional connection between one or more WUs and a network such as the wired backbone network 102. However, an AP could also have a wireless connection back to the backbone network 102, such as AP 106d, which has a wireless link to the backbone network 102 via another AP 106c. The wired backbone network can be of any type, including an Ethernet, a token ring, and an asynchronous transfer mode (ATM) network.



Referring now to FIG. 2, an exemplary embodiment of an access point (AP) is shown. For illustrative purposes, the access point is represented by AP 106b and differs in function from the access points described in U.S. Pat. No. 5,987,062. As shown, AP 106b comprises logic 200 and 202, an address table 204, a device management logic 206, and a wireless transceiver 208 including a power amplifier 209 and an antenna 210.



In particular, the logic 200 is used to determine whether certain information from the wired backbone network 102 is destined for one or more of the WUs. The address table 204 includes Medium Access Control (MAC) addresses for all of the wireless units associated with the AP 106b such as WUs 108c and 108d of FIG. 1. In the special case of all broadcast or some multicast packets, the packets are addressed to all or some of the wireless units (WUs) associated with the access point (AP) on a "best effort" basis.



Similarly, as information from the wireless units (WU) is received by the wireless transceiver 208, the logic 202 monitors addresses within this information against the contents of the address table 204. One reason is that only information from authenticated and associated wireless units (e.g., WUs 108c and 108d) is accepted. Hence, if a non-authenticated wireless unit transmits packets, these packets will not be forwarded to the wired backbone network 102 of FIG. 1. The logic 202 subsequently transmits the information to the logic 200 for routing to the wired backbone network 102.



In the event that the fixed backbone network 102 of FIG. 1 has a substantially larger data rate than the wireless network, content addressable memory (CAM) 212 and a hardware address filter (HAF) 214 may be employed within the AP 106b. The CAM 212 and HAF 214 are in communication with the fixed backbone network 102 and collectively filter information at the hardware level so that the logic 200 processes only that portion of the information routed over the wired backbone network 102 is addressed to associated WUs.



The device management logic 206 provides a mechanism for adjusting the various parameters and controlling the functionality of the AP 106b. For example, the device management logic 206 is responsible for adjusting the level of effective isotropic radiated power through adjusting current levels to the power amplifier 209. This reduces or increases the coverage area for the antenna 210. The adjustment in the power level may be (i) in small incremental changes (e.g., one milliwatt "mW" at a time), (ii) in accordance with preset levels and the like. For example, a first preset (low) level may set the power amplifier 209 to provide 5 mW while a second (medium) and third (high) level may set the power amplifier to provide 25 mW and 100 mW, respectively.



It is contemplated that a user can manually adjust the power levels via a port interface 216 within the AP 106b. The port interface 216 provides a direct connection to the AP 106b. Other mechanisms include (1) Simple Network Management Protocol (SNMP) management tools such as OPTIVITY.RTM. by Nortel Networks Limited of Montreal, Canada, (2) TELNET, or (3) web-based management software.



Referring back to FIG. 1, in the typical scenario, a WU associates itself with one of the APs to communicate with the wired backbone network 102. For instance, in the example shown in FIG. 1, WUs 108a and 108b are associated with AP 106a, WUs 108c and 108d are associated with AP 106b, WU 108e is associated with AP 106c, and WU 108f is associated with wireless AP 106d. Which access point (AP) a wireless unit (WU) is associated with can depend on many factors, including signal quality, load balancing, restricted links and other factors. The AP that a particular WU is associated with can change, such as when the WU "roams" from the coverage area of a particular AP to a coverage area of another AP. From the standpoint of the user using the WU, this change in associated AP is transparent.



Referring to FIG. 3, a second exemplary embodiment of a wireless network system 300 in accordance with the invention is shown. The wireless network system 300 comprises two or more sub-networks 302a and 302b, which communicate with each other by way of a router 304. The sub-networks 302a and 302b can be any wired backbone network, including Ethernet, token ring, and an asynchronous transfer mode (ATM) network. The sub-networks 302a and 302b need not be of the same type, for instance, sub-network 302a can be an Ethernet, and sub-network 302b can be a token ring. Each sub-network 302a and 302b has one or more APs for communicating with the WU. For instance, sub-network 302a includes APs 306a-1, 306a-2, 306a-3 for communicating respectively with WUs 308a-1, 308a-2, and 308a-3. Sub-network 302b includes APs 306b-1 and 306b-2 for communicating respectively with WUs 308b-1 and 308b-2. In this system, a WU associated with an AP on a particular sub-network (e.g. sub-network 302a) can also change its association to an AP on another sub-network (e.g. sub-network 302b) by roaming as discussed above or other circumstances.



Referring to FIG. 4, an third exemplary embodiment another wireless network system 400 in accordance with the invention is shown. The wireless network system 400 comprises two or more wireless units (WUs) that can communicate with each other via a wireless link. In this example, four WUs 402, 404, 406 and 408 are shown, each of which can communicate with the remaining units via the wireless link. In contrast to the wireless network systems of FIGS. 1 and 3, this wireless network system 400 does not use a wired backbone network or APs. This type of system 400 is known in the relevant art as an "ad hoc" wireless network system.



Referring now to FIG. 5, a first exemplary embodiment of the protocol followed to manually adjust the coverage distance of a device by a site survey is shown. The "device" may include either an AP or a WU. Herein, for this embodiment, the device includes logic to produce a control setting displayed on a monitor integrated with the device or attached thereto (block 500). The control setting may be represented as alphanumeric information or an object. This enables a system administrator and/or a user to adjust the coverage distance for the device through adjustment of the power level via the control settings (blocks 510 and 520). For improved results, any reduction of the power level may be accomplished in accordance with a logarithmic function while any increase in the power level may be accomplished at a constant, incremental change.



Referring now to FIG. 6, a second exemplary embodiment of the protocol followed to automatically adjust the coverage distance during communications between an AP and a wireless unit (WU) is shown. Herein, the AP monitors the signal strength of messages provided by the WU to determine whether the power level of the AP should be reduced for communications with the WU. Such determination may be accomplished through a conversion table. Loaded into persistent storage on the AP, the conversion table includes (1) a plurality of entries associated with determined power levels, and (2) a corresponding plurality of entries associated with suggested power levels. If no change of power level is needed, the suggested power level is set to be equal to its corresponding determined power level.



More specifically, when the AP receives a message from the WU, it determines the power level of the received message and accesses the conversion table (blocks 600, 610 and 620). Upon accessing the conversion table, the AP compares the determined power level to power levels within the first group of entries (block 630). If a match is detected, the power level of the AP used to transmit to that WU is adjusted based on the contents in the suggested power level entry (block 640). Of course, the WU may perform a complimentary adjustment in a similar manner as the AP described above.



Also, both the WU and AP may collectively reduce broadcast coverage by synchronizing their power adjustment operations. For example, when the WU associates with the AP, both the AP and the WU transmit at full power while listening to each other. At that point, mutual power level adjustments by one or both devices may be determined.



Referring now to FIG. 7, a third exemplary embodiment of the protocol followed to dynamically adjust the coverage distance during communications between multiple devices is shown. The device conducts the dynamic adjustment(s) of coverage distance through periodic reassessment of its power level setting. Herein, the device transmits a message to another device (block 700). If the device receives a response to that message within a certain time period, the device reduces the power level of the wireless transceiver and monitors whether a response is obtained for the next message (block 710 and 720). In addition, the count value (N) of the retry counter may be reset to zero (block 730).



Alternatively, if the device fails to receive a response after a specific number (N) of retries, normally "N" being greater than one, the device increases the power level of the wireless transceiver (blocks 740, 750 and 760). Thereafter, the device continues to monitor for a response to the message. Once the response is received, the power level is maintained for subsequent communications with the wireless unit.



Referring now to FIG. 8, a fourth exemplary embodiment of the protocol followed to adjust the communication range of an AP is shown. Herein, the AP monitors beacons produced by other APs on the same communication channel or an adjacent communication channel (block 800). If the AP detects a beacon with a substantial power level (e.g., greater than a predetermined power level threshold such as 25 mW), it is determined that another AP is in close proximity (block 810). In response, the AP reduces its power level to account for the presence of the other AP (block 820).



Of course, one problem is that once one AP reduces its power, the other AP(s) will not detect the presence of the AP. Thus, the other AP(s) will not reduce their power levels. Thus, it may be necessary to keep track of the maximum power of received beacons from other APs and to periodically send some beacons at full power (or a designated power level). These periodic beacons allow other AP(s) to assess channel conditions.



While certain exemplary embodiments have been described and shown in the accompanying drawings, it is to be understood that such embodiments are merely illustrative of and not restrictive on the broad invention, and that this invention not be limited to the specific constructions and arrangements shown and described, since various other modifications may occur to those ordinarily skilled in the art.

PatentNumber=7339892,FIELD OF THE INVENTION



The present invention relates to the field of networking. In particular, the invention relates to a system and method in a wireless network system for dynamically controlling a data packet fragmentation threshold in response to changes in network environment conditions, including radio frequency (RF) interference and/or data rate changes. In addition, the invention relates to a system and method for sending a control signal to wireless units to enable request to send (RTS)/clear to send (CTS) and/or fragmentation modes of operations.



BACKGROUND OF THE INVENTION



The ability of users to access programs and share data over local area networks (referred to as "LANs") has become a necessity for most working environments. To improve efficiency and ease of use, certain enhancements may be added to a LAN such as remote wireless access. By providing remote wireless access, a wireless LAN (WLAN) is formed.



As described in U.S. Pat. No. 5,987,062 issued to Netwave Technologies, Inc., now owned by Nortel Networks Limited of Ontario, Canada, one type of WLAN employs dedicated stations, which are referred to as access points (APs). Therein, each AP is a relay station that includes a radio frequency (RF) transceiver that receives radio data packets from a mobile unit (MU) such as a notebook-type computer with a suitable adapter card as described in U.S. Pat. No. 5,987,062. Thereafter, the AP transmits the data packets to the fixed backbone network. Of course, the AP may receive data from the fixed backbone network and transmit it to one or more mobile units.



Before data transmission can occur between the fixed backbone network and an MU by way of an AP, the AP must first authenticate MU. The authentication is accomplished by the MU transmitting a request for authentication message to the AP, and the AP sending back a successful authentication message back to the MU. Once the MU has been authenticated, the MU has to associate itself with the AP. The association is accomplishes by the MU transmitting a request for association message to the AP, and the AP sending back in a successful association message. The authentication and association transmission are specified in the Institute of Electrical and Electronics Engineers (IEEE) 802.11 standard. Once the MU has been properly authenticated and associated with the AP, then data transmission between the MU and the fixed backbone network can occur.



A problem with current wireless networks deals with the situation where there is significant RF interference in the wireless communications link coupling an AP with the associated MU(s). Typical sources of significant RF interference for wireless network systems includes Blue Tooth devices, cellular telephones, microwave ovens, and other devices that transmit RF signals. When significant RF interference is present in the wireless medium of a wireless network system, generally more errors occur in the transmission of data between an AP and the associated MU(s).



The data error of the transmission is not only a function of the RF interference present in the wireless medium, but also of the size of the data packets. In an RF interference free environment, the wireless medium can support the transmission of data packets having relatively long data length without substantial transmission errors occurring. Thus, in an RF interference free environment, the optimal data throughput for the wireless medium occurs when the data packets are at maximum data size, which in a 802.11 compliant wireless network system is 2304 bytes. When RF interference increases in the wireless medium, more transmission data errors occur for the same data packet size. However, if the data packet size is reduced, the transmission data errors can be substantially reduced. Thus, in an RF interference environment, generally there is an optimal data packet size (less than the maximum data packet size) where the data throughput is maximum.



In prior art wireless network systems, a network system administrator occasionally gauges the RF interference present in a wireless network system in order to manually determine the optimal data packet size. This is accomplished by the system administrator causing an AP to send many tested patterns to a designated MU with varying data packet sizes, and then measuring the data throughput for each of the data packet sizes. Using this technique, the system administrator can determine the optimal data packet size.



Then, the system administrator manually sets the fragmentation threshold for each AP and MU of the wireless network system above the optimal data packet size. The fragmentation threshold sets the upper limit of the data portion of a packet. That is, if the payload size of a packet is greater than the fragmentation threshold, the data packet is fragmented so that each fragment transmitted has a payload that is less than the threshold. If the payload size of the packet is less than the fragmentation threshold, the packet is not fragmented, and simply transmitted.



The problem with this technique is that RF interference in a wireless environment is typically very dynamic, and therefore, a system administrator cannot practically determine and adjust for the optimal fragmentation threshold for every change in the wireless environment. For example, a person in a business office or a home can turn on the microwave oven for 30 seconds. During that 30-second period, the RF interference in the wireless medium increases. However, it would be impractical or even impossible for a system administrator to gauge the wireless environment for the purpose of determining the optimal fragmentation threshold each time a person turns on a microwave oven or some other RF interference source.



Another problem with current wireless network systems deals with fragmentation threshold as described above, and data transmission using request to send (RTS)/clear to send (CTS). In a 802.11 compliant wireless network system, the AP and the associated MUs are all able to use the wireless medium using carrier sense multiple access with collision avoidance, referred to as CSMA/CA. Using CSMA/CA, an MU first determines if the wireless medium is either idle or busy. If it is idle (i.e. the medium is available for transmission), the MU simply transmits the data packet to the AP, and the AP responds by sending an acknowledgement packet back to the AP if the data packet was successfully received. If the wireless medium is busy, the MU will backoff from sending the data packet for a random time period. After this period, the MU checks the wireless medium again to determine if it is idle or busy.



A problem with CSMA/CA may occur when MUs are within the range of an associated AP, but are outside of each others' ranges. In this case, when the first MU transmits a data packet to the associated AP, the second MU fails to hear that transmission. As a consequences, the second MU may falsely detect that the wireless medium is idle, and transmit its data to the AP, resulting in a collision of the data. The likelihood of this occurring increases when there is a relatively high count of MUs associated with an AP. A system administrator can correct or ameliorate this problem by employing request to send (RTS)/clear to send (CTS) transmissions throughput the wireless network system or at least throughout the sub-system comprising the AP and its associated MUs.



Using request to send (RTS)/clear to send (CTS) transmissions, an MU first sends a request to send (RTS) packet to he associated AP. If the following time slot is already reserved by another MU for transmission of a data packet, the AP simply does not send back a CTS packet. However, if the following time slot has not been reserved for transmission, the AP sends a clear to send (CTS) packet to the transmitting MU indicating that a following time slot is reserved for transmission by the transmitting MU. All other associated MU(s) detecting the CTS packet know that the following time slot is already reserved for transmission by the transmitting MU. Thus, this avoids the problem of MUs being outside the range of each other since the associated MUs will detect the CTS packet sent by the AP.



Typically, request to send (RTS)/clear to send (CTS) transmission are used when there is a relatively high number of MUs associated with an AP. So that request to send (RTS)/clear to send (CTS) transmissions is effective to avoid collisions, it should be enabled for all MUs and associated AP of an AP/MU cluster. However, as alluded to above, a problem with current wireless network systems is that the system administrator has to manually enable each AP and MU when RTS/CTS transmission is desired. Likewise, a system administrator has to enable each AP and MU when fragmentation is desired. Since there can be many APs and MUs in a wireless network system, having a system administrator go around to all of these units to enable RTS/CTS transmissions and/or fragmentation is cumbersome, costly and time-consuming.



Thus, there is a need for a system and method for dynamically controlling a data packet fragmentation threshold in response to changes in network environment conditions, including radio frequency (RF) interference and/or other parameters in a wireless network system. There is also a need for a system and method of globally controlling all MUs (referred to in this application as wireless units (WUs) since they need not be mobile) associated with an AP to enable RTS/CTS transmissions and/or data packet fragmentation. Such systems and methods are provided herein in accordance with the invention.



SUMMARY OF THE INVENTION



An aspect of the invention relates to a method of automatically adjusting a fragmentation threshold for data transmissions between an access point and one or more associated wireless units via a wireless medium associated with a wireless network system. The method comprises determining a transmission error factor indicative of errors occurring in the transmission of one or more data packets between the access point and the one or more associated wireless units, and automatically adjusting the fragmentation threshold based on the transmission error factor.



The transmission error factor can be determined by transmitting one or more data packets, and determining the transmission error factor based on the number of acknowledgement packets received in response to the transmitted one or more data packets. The transmission error factor can depend on the number of errors occurring in the transmission of the one or more data packets for a given time period. Also, the transmission data error can depend greater on transmission errors occurring successively (i.e. clusters of transmission errors) than on errors occurring sporadically.



The automatic adjusting of the fragmentation threshold can be accomplished by comparing the transmission error factor to an upper threshold and decreasing the fragmentation threshold if the transmission error factor is above the upper threshold. In the other direction, the fragmentation threshold is adjusted by comparing the transmission error factor to a lower threshold, and increasing the fragmentation threshold if the transmission error factor is below the lower threshold. The changes in the fragmentation threshold can be by a fixed quantity each time the fragmentation threshold is adjusted, or by a divisional factor, wherein the fragmentation threshold is equal to a pre-determined fragmentation threshold divided by the divisional factor. This pre-determined fragmentation threshold can be the maximum data packet size for transmission over the wired backbone network, or the maximum data packet size for transmission over the wireless medium.



The above method can be performed by an access point, a wireless unit, or other device in a wireless network system. The above method can also be embodied in a software routine stored on a machine readable medium.



Another aspect of the invention relates to a method of automatically adjusting a fragmentation threshold for data transmissions between an access point and one or more associated wireless units via a wireless medium associated with a wireless network system. The method comprises determining a transmission error factor indicative of errors occurring in the transmission of one or more data packets between the access point and the one or more associated wireless units; automatically adjusting the fragmentation threshold based on the transmission error factor, wherein the one or more data packets each have a finite time duration; changing a data rate of the transmissions of the one or more data packets; and automatically adjusting the fragmentation threshold in response to the data rate change so that the finite time during for the one or more data packets remains substantially the same.



This method can also be performed by an access point, a wireless unit, or other device in a wireless network system. And, the method can also be embodied in a software routine stored on a machine readable medium.



Yet another aspect of the invention relates to a wireless network system comprising a wired backbone network, an access point, and one or more associated wireless unit data coupled to the access point by way of a wireless transmission medium. In particular, this aspect of the invention is a method of enabling fragmentation of data packet above a fragmentation threshold in one or more wireless units, comprising transmitting a message to the one or more wireless unit having a first control data that causes the one or more wireless units to implement fragmentation threshold in transmitting data packets to the access point. The message is preferably a multicast data packet intended for the one or more associated wireless units. The message may further include a specified fragmentation to be used, and also another control signal for enabling request to send (RTS) and clear to send (CTS) transmission by the one or more wireless units.



Other aspects and features of the present invention will become apparent to those ordinarily skilled in the art upon review of the following description of specific embodiments of the invention in conjunction with the accompanying figures.



BRIEF DESCRIPTION OF THE DRAWINGS



FIG. 1 illustrates a block diagram an exemplary wireless network system in accordance with the invention;



FIG. 2 illustrates a block diagram of an exemplary access point (AP) in accordance with the invention;



FIG. 3 illustrates a block diagram of another wireless network system in accordance with the invention;



FIG. 4 illustrates a flow chart of an exemplary routine that an AP can perform to automatically adjust the fragmentation threshold;



FIG. 5 illustrates a table useful for explaining the relationship between the fragmentation threshold and the data rate; and



FIG. 6 illustrates a block diagram of an exemplary wireless unit (WU) for performing the various functions in accordance with the invention.



DETAILED DESCRIPTION OF THE INVENTION



Herein, the exemplary embodiments of the present invention relates to a wireless network that includes a field wired backbone network, one or more access point (AP) for providing wireless units access to the backbone network via a wireless communications link to the AP. The invention solves this problem by having an AP of a wireless network system automatically determine a factor indicative of the error(s) occurring in the transmissions of one or more data packets to the associated WU, and automatically adjust the fragmentation threshold in accordance with the transmission error factor. The AP adjusts the fragmentation threshold in a manner that the data throughput is increased. Since the AP automatically and periodically gauges the wireless medium for RF interference that can cause data transmission errors, the fragmentation threshold can be dynamically adjusted to respond to changes in the wireless medium, such as when a microwave oven is turned on, and/or when a Blue Tooth device is traversing the wireless medium, etc. This is much more effective than having a system administrator periodically gauge the wireless medium for the purpose of selecting the appropriate fragmentation threshold.



In the following description, certain terminology is used to describe features of the present invention. For example, "logic" includes hardware and/or software module(s) that perform a certain function on incoming information. A "software module" is executable code such as an operating system, an application or an applet for example. The term "information" is defined as data, address, and/or control. For transmission, the information may be placed in a frame featuring a single data packet or a series of data packets.



In addition, a "link" is broadly defined as one or more information-carrying mediums to establish a communications pathway. Examples of the medium include a physical medium (e.g., electrical wire, optical fiber, cable, bus traces, etc.) or a wireless medium (e.g., air in combination with wireless signaling technology).



Referring to FIG. 1, an exemplary first embodiment of a wireless network system 100 in accordance with the invention is illustrated. The wireless network system 100 comprises a link 101 based on a physical medium. Herein, the link 101 is part of a wired backbone network 102 that includes network resources 104 available for users of the system 100. The wireless network system 100 further includes one or more access points (APs) 106a-106d that communicate via a wireless link with one or more wireless units (WUs) 108a-108f. For this embodiment, four (4) APs 106a-106d communicate with six (6) WU 108a-108f.



Users using the WUs 108a-108f can access the network resources 104 via any of the APs 106a-106d, which are generally transparent bridges that link a wireless network defined by one or more WUs 108a-108f with the wired backbone network 102. The WUs 108a-108f communicate with the APs 106a-106d typically using a standardized protocol, such as the IEEE 802.11 protocol.



A "wireless unit" (WU) is defined herein as any electronic device comprising processing logic (e.g., a processor, microcontroller, state machine, etc.) and a wireless transceiver for receiving and transmitting data to an access point (AP) or another wireless unit (WU). Examples of a WU include a computer (e.g., desktop computer, laptop computer, hand-held computer such as a personal digital assistant "PDA", etc.), communications equipment (e.g., pagers, telephones, facsimile machine, etc.), a television set-top box, or appliances such as refrigerator pads, electronic picture frames, alarm detectors, water detractors, etc. The WU includes hardware and/or software to receive a notification from an assigned AP of a failed communications link between the associated AP and the wired backbone network 102. In addition, the WU also includes hardware and/or software to initiate a search for a new AP to associate with upon receiving such a notification of a failed communications link to the wired backbone network 102 from its associated AP.



An "access point" (AP) is a device that provides a bi-directional connection between one or more WUs and the wired backbone network 102. However, an AP could also have a wireless connection back to the backbone network 102, such as AP 106d, which has a wireless link to the backbone network 102 via another AP 106c. The wired backbone network can be of any type, including an Ethernet, a token ring, and an asynchronous transfer mode (ATM) network. The AP of the invention includes hardware and/or software to detect a failed communications link to the wired backbone network. The AP of the invention also includes hardware and/or software to notify associated WUs of the failed communication link so that the WUs take appropriate action to reestablish their line to the backbone network 102 by way of another AP.



Referring now to FIG. 2, an exemplary embodiment of an access point (A) is shown. For illustrative purposes, the access point is represented by AP 106b and differs in function from the access points described in U.S. Pat. No. 5,987,062. As shown, AP 106b comprises logic 200 and 202, an address table 204, a device management module 206, and a wireless transceiver interface 210. In particular, the logic 200 is used to determine whether certain information from the wired backbone network 102 is destined for one or more of the WUs. The address table 204 includes media access controller (MAC) addresses for all of the wireless units associated with the AP 106b such as WUs 108c-d of FIG. 1. In the special case of all broadcast or some multicast packets, the packets are addressed to all or some of the wireless units (WUs) associated with the access point (AP) on a "best efforts" basis.



Similarly, as information from wireless units (WU) is received by the wireless transceiver 210, the logic 202 monitors addresses within this information against the contents of the address table 204. One reason is that only information from authenticated and associated wireless units (e.g., WUs 108c-d) is accepted. Hence, if a non-authenticated wireless unit transmits packets, these packets will not be forwarded to the wired backbone network 102 of FIG. 1. The logic 202 subsequently transmits the information to the logic 200 for routing to the wired backbone network 102.



In the event that the fixed backbone network 102 of FIG. 1 has a substantially larger data rate than the wireless network, content addressable memory (CAM) 212 and a hardware address filter (HAF) 214 are employed within the AP 106b. The CAM 212 and HAF 214 are in communication with the fixed backbone network 102 and collectively filter information at the hardware level so that the logic 200 processes only a small portion of the information routed over the wired backbone network 102.



The device management module l206 provides a mechanism for adjusting the various parameters and controlling the functionality of the AP 106b. An example of one mechanism involves placement of a serial port 216 within the AP 106b. The serial port 216 provides a direct connection to the AP 106b. Other mechanisms include (1) Simple Network Management Protocol (SNMP) management tools such as OPTIVITY.RTM. by Nortel Networks Limited of Montreal, Canada, (2) TELNET, or (3) web-based management software.



Referring back to FIG. 1, in a typical scenario, a WU associates itself with one of the APs to communicate with the wired backbone network 102. For instance, in the example shown in FIG. 1, WUS 108a-b are associated with AP 106a, WUs 108c-d are associated with AP 106b, WU 108e is associated with AP 106c, and WU 108f is associated with wireless AP 106d. Which access point (AP) a wireless unit (WU) is associated with can depend on many factors, including signal quality, load balancing, restricted links and other factors. The APs associated with a particular WU can change, such as when the WU "roams" from the coverage area of a particular AP to a coverage area of another AP. From the standpoint of the user using the WU, this change in associated AP is transparent.



FIG. 3 illustrates an exemplary second embodiment of a wireless network system 300 in accordance with the invention. The wireless network system 300 comprises two or more sub-networks 302a-b, which communicate with each other by way of a router 304. The sub-networks 302a-b can be any wired backbone network, including Ethernet, token ring, and an asynchronous transfer mode (ATM) network. The sub-networks 302a-302b need not be of the same type, for instance, sub-network 302a can be an Ethernet, and sub-network 302b can be a token ring. Each sub-network 302a-b has one or more APs for communicating with associated WUs. For instance, sub-networked 302a includes APs 306a-1, 306a-2, 306a-3 for communicating respectively with WUs 308a-1, 308a-2, and 308a-3. Sub-network 302b includes APs 306b-1 and 306b-2 for communicating respectively with WUs 308b-1 and 308b-2. In this system, a WU associated with an AP on a particular sub-network (e.g. sub-network 302a) can also change its association to an AP on another sub-network (e.g. sub-network 302b) by roaming as discussed above or other circumstances.



As previously discussed, a problem with the current wireless network deals is that RF interference in a wireless environment is typically very dynamic, and therefore, a system administrator cannot practically determine and adjust the fragmentation threshold for every change in the wireless environment. For example, a person in an office or a home can turn on the microwave oven for 30 seconds. During that period, the RF interference in the wireless medium increases. However, it would be impractical or even impossible for a system administrator to gauge the wireless environment for the purposes of determining the optimal fragmentation threshold each time a person turns on a microwave oven or some other RF interference source.



The invention solves this problem by having an AP of a wireless network system automatically determine a factor indicative of the error(s) occurring in the transmissions of one or more data packets to the associated WU, and automatically adjust the fragmentation threshold in accordance with the transmission error factor. The AP adjusts the fragmentation threshold in a manner that the data throughput is increased. Since the AP automatically and periodically gauges the wireless medium for RF interference that can cause data transmission errors, the fragmentation threshold can be dynamically adjusted to respond to changes in the wireless medium, such as when a microwave oven is turned on, and/or when a Blue Tooth device is traversing the wireless medium, etc. This is much more effective than having a system administrator periodically gauge the wireless medium for the purpose of selecting the appropriate fragmentation threshold.



FIG. 4 illustrates a flow chart of an exemplary routine 400 that an AP can perform in automatically adjusting the fragmentation threshold to increase data throughput in the presence of significant RF interference. In step 402, the AP first transmits one or more data packets to one or more associated WU(s) in the normal course of sending data to the WU(s). In step 404, the AP determines a factor indicative of the error(s) that occurred in the transmission of the one or more data packets to the WU(s). Since the 802.11 wireless network system uses a positive acknowledgment protocol (i.e. the transmission of an acknowledge packet when a data packet is successfully received) for data that is transmitted via the wireless medium, the AP can determine the transmission error factor by the amount of acknowledgement packet(s) received in response to its transmissions of the one or more data packet(s).



In step 406, the AP compares the transmission error factor to a pre-determined upper threshold. The pre-determined upper threshold is a maximum transmission error factor that could be tolerated without having to decrease the fragmentation threshold. If the transmission error factor increases above the upper threshold as determined in step 406, this indicates that significant data transmission errors are occurring in the wireless medium requiring a decrease in the fragmentation threshold. Accordingly, in step 408 the fragmentation threshold is reduced, and the AP subsequently transmits one or more data packet(s) to the associated WU(s) using the new fragmentation threshold. If the transmission error factor is below the upper threshold as determined in step 406, this indicates that significant data transmission errors are not occurring in the wireless medium, and the routine proceeds to step 410.



In step 410, the AP compares the transmission error factor to a pre-determined lower threshold. The pre-determined lower threshold is a minimum transmission error factor for which an increase in the fragmentation threshold is not necessitated. If the transmission error factor falls below the lower threshold as determined in step 410, this indicates that fragmentation threshold can be increased in order to increase the data throughput through the wireless medium. Accordingly, in step 412 the fragmentation threshold is increased, and the AP subsequently transmits one or more data packet(s) to the associated WU(s) using the new fragmentation threshold. If the transmission error factor is above the lower threshold as determined in step 410, this indicates that there are some data transmission errors, not significant as to require a decrease in the fragmentation threshold, but significant enough not to increase it either. Thus, the current fragmentation threshold is maintained, and the AP subsequently transmits one or more data packet(s) to the associated WU(s) using the current fragmentation threshold.



With regard to step 404, there are many algorithms that an AP can use to determine the transmission error factor for the purpose of adjusting the fragmentation threshold. For instance, the transmission error factor can be a percentage of data transmission errors that occurred within a given time period. This method, however, may not be desirable because data transmission errors can be common in a system. A more effective method of determining a transmission error factor is to weigh transmission errors that occur successively (i.e. clusters of transmission errors) greater than those errors that occur sporadically. If transmission errors occur successively, this indicates that there may be a problem, such as a temporary increase in RF interference, in the wireless medium. Other methods of determining a transmission error factor can be based on an empirical modeling of the wireless channel. There are many other methods of determining a transmission error factor for the purpose of adjusting the fragmentation threshold.



With regard to steps 408 and 412 of reducing and increasing the fragmentation threshold, this can be accomplished in many ways. For instance, once it has been determined that the fragmentation threshold has to be reduced or increased in step 406 or 410, the AP can decrement or increment the fragmentation threshold by one or some other fixed quantity. Using this method, an repeating the routine 400 depicted in FIG. 4, a fragmentation threshold that provides optimal data throughput for the system can be achieved.



Another method of adjusting the fragmentation threshold is to use a divisional factor where the current fragmentation threshold is given by a maximum fragmentation threshold divided by the divisional factor. The maximum fragmentation threshold is preferably set at or above the maximum packet size specified by the wired backbone network protocol. If an Ethernet type network is used, the maximum data packet size is 1518 bytes. Thus, the maximum fragmentation threshold is set to 1581 bytes. If there is minimal RF interference in the wireless medium, the divisional factor is set to 1, thereby making the fragmentation threshold 1518 and consequently no fragmentation of data packets occur. When Rf interference initially occurs that causes the transmission error factor to increase above the upper threshold (See FIG. 4), the divisional factor is increased to 2, thereby reduction the fragmentation threshold to 759. If the transmission error factor is still above the upper threshold, the divisional factor is increased again to 3, thereby reducing the fragmentation threshold to 506, and so on. Similarly, the divisional factor is decreased when the transmission error factor falls below the lower threshold (See FIG. 4).



The advantage of using fixed steps to adjust the fragmentation threshold is that generally a fragmentation threshold is arrived that produces a more optimum data throughput. However, because the changes in the fragmentation threshold are by fixed steps, it takes a relatively long time to arrive at the optimum fragmentation threshold. The advantage of using the divisional factor to adjust the fragmentation threshold is that the change in the threshold is quick at the beginning to attack the problem faster, but changes slowly as the problem increases. This adjustment of the fragmentation threshold parallels how environment changes occur in networks. The only drawback with this method is that the optimal fragmentation threshold may lie at a value not capable of being reached because of the discrete step of the divisional factor. In any event, the above two methods of adjusting the fragmentation threshold are merely examples. There are many other ways to adjust the fragmentation threshold in response to changes in the wireless medium environment.



Another consideration is the time length of a data packet when data rates are changed and fragmentation of data is being performed to increase data throughput in the presence of significant RF interference. The time duration of data packet is given by the size of the packet divided by the data rate. Fragmenting a data packet (i.e. reducing the size of a data packet), therefore, makes its duration shorter. If a data packet has a relatively long duration, it is more prone to be adversely affected by RF interference. This is the reason why the data size of data packets are made smaller by fragmentation to reduce duration of the packets so that they are less vulnerable to RF interference. However, as previously stated, the duration of a data packet is not only a function of data size, but also of the data rate. So changes in the date rate should be taken into account when fragmentation is employed in order to maintain the desired duration for the packet.



FIG. 5 illustrates a table useful for explaining the relationship between the fragmentation threshold and the data rates. The left-most column lists divisional factor for four exemplary scenarios, with the maximum fragmentation threshold being 1500 for all the scenarios. The second column lists the data rates for the four exemplary scenarios. And, the right-most column is a time line of the data packet payloads and corresponding acknowledgement packets for the four exemplary scenarios.



In the first scenario, the divisional facto is 1, thereby making the fragmentation threshold 1500 bytes (i.e. the maximum fragmentation threshold of 1500 divided by the divisional factor of 1). The data rate for the first scenario is 11 Megabytes per second (Mbytes/s). Assuming the size of the payload of the data packet is the same as the fragmentation threshold, then the duration of the payload is 136 microseconds.



In the second scenario, significant RF interference is present in the wireless medium which causes the AP to reduce the fragmentation threshold by increasing the divisional factor from one to two. Thus, the fragmentation threshold is 750 bytes (i.e. the maximum fragmentation threshold of 1500 divided by the divisional factor of 2). The data rate for this scenario is maintained at 11 Mbytes/s. Assuming the size of the payload of the data packet is the same as the fragmentation threshold, then the duration of the payload has been shortened to 68 microseconds. This illustrates that the original data payload having a duration of 136 microseconds was too long that is was prone to adverse effects from the RF interference. By shortening the duration of the payload to 68 microseconds with fragmentation, the data packet is less prone to the RF interference.



In the third scenario, the data rate has been reduced to 5.5 Mbytes/s. This may be done by a system administrator for any number of reasons. In this scenario, the divisional factor of 2 is maintained the same, thereby the fragmentation threshold is again 750 bytes. Assuming the size of the payload of the data packet is the same as the fragmentation threshold, then the duration of the payload returns back to 136 microseconds due to the data rate change. However, it has already been determined that a duration of 136 microseconds for the payload makes the data packet prone to adverse effects from the RF interference. To correct this, the fragmentation threshold has to be reduced by half again to maintain the duration of the payload at 68 microseconds, where the data packet is less prone to adverse effects from RF interference.



Thus, in the fourth scenario, the divisional factor has been increased to 4, thereby making the fragmentation threshold 375 bytes (i.e. the maximum fragmentation threshold of 1500 divided by the divisional factor of 4). Again, the fragmentation threshold has been decreased to compensate for the decrease in the data rate from 11 to 5 Mbytes/s. Thus, the duration of the data payload is 68 microseconds, where the data packet is less prone to adverse effects from RF interference. This example illustrates the concept that if fragmentation is being used and there is a data rate change, the fragmentation threshold has to similarly change in order to maintain substantiality the same duration for the data packet.



As previously discussed, in order for fragmentation and/or RTS/CTS transmission to optimally work in a wireless network system, the AP as well as its associated WU(s) should all use fragmentation and/or RTS/CTS transmission. However, in current wireless network system, a system administrator has to manually enable each AP and associated WU(s) when fragmentation is desired. Likewise, a system administrator has to enable each AP and associated WU(s) when RTS/CTS transmission is desired. Since there can be many APs and WUs in a wireless network system, having a system administrator go around to all of these units to enable fragmentation and/or RTS/CTS is cumbersome, costly and time-consuming.



The invention solves this problem by having an AP transmit a multicast packet including a control signal that enables fragmentation and/or RTS/CTS transmissions in the associated WU(s). The multicast packet also includes the fragmentation threshold to be used. Thus, instead of a system administrator having to manually enable the AP and each of the associated WU(s) for fragmentation and/or RTS/CTS transmissions, with the use of the multicast packet, the AP automatically enables these functions for all the associated WU(s). This is a substantial saving in time and money, and is substantially less cumbersome.



In the preferred embodiment, the multicast data packet sent out by the APs conform to an Inter Access Point Protocol (IAPP) developed by Netwave Technologies, Inc., now owned by Nortel Networks Limited. The IAPP protocol is used for automated hop sequence between APs, handover notification when a WU roams from one AP to another AP, and for delivery of various AP information, such as the AP network protocol address and subnet mask as previously discussed. The IAPP uses an IEEE 802.3 frame format with the sub-network access protocol (SNAP). The IAPP broadcast packet includes a header defining various parameters such as destination address which is typically set to a multicast address, a source address set to the network protocol address of the transmitting AP, length of the packet, and other information, and a payload which includes informational elements such as the AP name, the number of associated WU(s) (i.e. the head count), a control signal for enabling fragmentation in the associated WU(s), the fragmentation threshold to be used, a control signal for enabling RTS/CTS transmissions in the associated WU(s), and other information.



Referring back to FIG. 2, the AP 106b of the invention includes a logic circuit, such as the device management module 206, for generating and transmitting to the associated WU(s), a multicast packet (e.g. the IAPP multicast packet described above) that includes a control signal for causing the associated WU(s) to fragment data packets if the payload is above a fragmentation threshold. The multicast packet also contains an information element of the desired fragmentation threshold. Along this line, the AP 106b of the invention includes a logic circuit, such as the device management module 206b, for determining when to employ fragmentation and at what fragmentation threshold based on a factor indicative of the data rate changes. Such a logic circuit can also determine the data transmission error factor based on many different algorithms such as the ones discussed above or others.



The AP106 of the invention also includes a logic circuit, such as the device management module 206, for generating and transmitting to the associated WU(s), a multicast packet (e.g. the IAPP multicast packet described above) that includes a control signal for causing the associate WU(s) to perform RTS/CTS transmissions. In addition, the logic circuit of AP 106b can also automatically determine when to employ RTS/CTS transmissions for itself and the associated WU(s) based upon such factors as the number of associated WUs (i.e. the head count), and/or the number of retry transmission counts, and/or the number of collisions.



FIG. 6 illustrates a block diagram of an exemplary wireless unit (WU) 600 for performing the various functions in accordance with the invention. As previously discussed, examples of a WU 600 includes a computer (e.g., desktop computer, laptop computer, hand-held computer such as a personal digital assistant "PDA", etc.), communications equipment (e.g., pagers, telephones, facsimile machine, etc.), a television set-top box, or appliances such as refrigerator pads, electronic picture frames, alarm detectors, water detectors, etc. The WU 600 comprises a wireless transceiver 602 for transmitting and receiving RF data packets to and from an AP, a logic circuit 604 for performing the various functions of the WU 600, a memory 606 for storing data and applications relating to the various functions of the WU 600, and a user interface 608 for receiving and presenting information from and to a user of the WU 600. Such user interface 608 can include a keyboard, pointing device (e.g. a mouse, a track ball, etc.), a microphone, display, speakers and other devices for conveying and receiving information to and from a user.



With regard to the invention, the logic circuit 604 of the WU 600 receives by way of the wireless transceiver 602 the multicast packet (e.g. the IAPP multicast packet described above) transmitted by the associated AP that includes the control signal for causing the WU 600 to fragment data packets if the payload is greater than a fragmentation threshold. The specified fragmentation threshold is also included in the multicast packet. The logic circuit 604 stores the specified fragmentation threshold in memory 606 and sets a flag for performing fragmentation. The logic circuit 604 will thereafter fragment each data packet whose payload is greater than the fragmentation threshold, and transmits the two or more fragments as individual packets to the associated AP by way of the wireless transceiver 602. If the payload of the data packet is less than the fragmentation threshold, the logic circuit 604 simply transmits the whole packet to the associated AP by way of the wireless transceiver 602.



Alternatively, the WU 600 an also determine on its own, without instructions from the associated AP, whether to perform fragmentation of data packets based on data transmission errors, data rate changes, and/or other factors. Specifically, the logic circuit 604 can make such a determination using the same one or more routines performed by an AP, as described with reference to FIGS. 4 and 5. If the logic circuit 604 determines that fragmentation is needed, it can determine the fragmentation threshold using the same one or more routines performed by an AP, as described with reference to FIGS. 4 and 5.



Also with regard to the invention, the logic circuit 604 of the WU 600 receives by way of the wireless transceiver 602 the multicast packet (e.g. the IAPP multicast packet described above) transmitted by the associated AP that includes the control signal for causing the WU 600 to perform RTS/CTS transmissions. In response to this control signal, the logic circuit 604 sets a flag that enables RTS/CTS transmissions. The logic circuit 604 will thereafter transmit an RTS packet prior to sending a data packet to the associated AP by way of the wireless transceiver 602, and wait a pre-determined time interval to receive a CTS packet from the associated AP. If the logic circuit 604 receives the CTS packet from the associated AP within the pre-determined time interval, then the logic circuit 604 transmits the corresponding data packet during the reserved time slot following the receipt of the CTS packet. If the logic circuit 604 does not receive the CTS packet within the pre-determined time interval, the logic circuit 604 retransmits another RTS packet and repeats the same process again.



Alternatively, the WU 600 can also determine on its own, without instructions from the associated AP, whether to perform RTS/CTS transmissions based on the amount of associated WUs, number of retry transmissions, number of collisions, and/or how proximate other associated WUs are by monitoring their signal strength on data. Specifically, the logic circuit 604 can make such a determination using the same one or more routines performed by an AP, as described with reference to FIGS. 4 and 5.



In the foregoing specification, the invention has been described with reference to specific embodiments thereof. It will, however, be evident that various modifications and changes may be made thereto departing from the broader spirit and scope of the invention. The specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.

